{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Import libraries<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bcolz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4e658de867cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mbcolz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bcolz'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as autograd\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import model_selection\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#drew inspiration from\n",
    "#https://github.com/dmesquita/understanding_pytorch_nn and\n",
    "#https://github.com/msahamed/yelp_comments_classification_nlp/blob/master/word_embeddings.ipynb\n",
    "#https://github.com/nyu-mll/DS-GA-1011-Fall2017/blob/master/week%20eight/Week%20Eight%20Solutions.ipynb\n",
    "#https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html\n",
    "#https://github.com/claravania/lstm-pytorch/blob/master/model.py\n",
    "#https://medium.com/@sonicboom8/sentiment-analysis-with-variable-length-sequences-in-pytorch-6241635ae130\n",
    "#https://github.com/hpanwar08/sentence-classification-pytorch/blob/master/Sentiment%20analysis%20pytorch.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://medium.com/@martinpella/how-to-use-pre-trained-word-embeddings-in-pytorch-71ca59249f76\n",
    "#https://github.com/Blosc/bcolz\n",
    "\n",
    "#used pip install -U blosc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://modelzoo.co/model/pytorch-nlp\n",
    "#http://anie.me/On-Torchtext/\n",
    "#https://readthedocs.org/projects/pytorchnlp/downloads/pdf/latest/\n",
    "\n",
    "#https://github.com/A-Jacobson/CNN_Sentence_Classification/blob/master/WordVectors.ipynb\n",
    "\n",
    "#https://pytorch.org/docs/master/nn.html#torch.nn.Embedding.from_pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torchnlp.word_to_vector import GloVe #glove is much smaller than fastext, so downloads faster"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vectors = GloVe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.2523\n",
       " 0.1018\n",
       "-0.6748\n",
       " 0.2112\n",
       " 0.4349\n",
       " 0.1654\n",
       " 0.4826\n",
       "-0.8122\n",
       " 0.0413\n",
       " 0.7850\n",
       "-0.0779\n",
       "-0.6632\n",
       " 0.1464\n",
       "-0.2929\n",
       "-0.2549\n",
       " 0.0193\n",
       "-0.2026\n",
       " 0.9823\n",
       " 0.0283\n",
       "-0.0813\n",
       "-0.1214\n",
       " 0.1313\n",
       "-0.1765\n",
       " 0.1356\n",
       "-0.1636\n",
       "-0.2257\n",
       " 0.0550\n",
       "-0.2031\n",
       " 0.2072\n",
       " 0.0958\n",
       " 0.2248\n",
       " 0.2154\n",
       "-0.3298\n",
       "-0.1224\n",
       "-0.4003\n",
       "-0.0794\n",
       "-0.1996\n",
       "-0.0151\n",
       "-0.0791\n",
       "-0.1813\n",
       " 0.2068\n",
       "-0.3620\n",
       "-0.3074\n",
       "-0.2442\n",
       "-0.2311\n",
       " 0.0980\n",
       " 0.1463\n",
       "-0.0627\n",
       " 0.4293\n",
       "-0.0780\n",
       "-0.1963\n",
       " 0.6509\n",
       "-0.2281\n",
       "-0.3031\n",
       "-0.1248\n",
       "-0.1757\n",
       "-0.1465\n",
       " 0.1536\n",
       "-0.2952\n",
       " 0.1510\n",
       "-0.5173\n",
       "-0.0336\n",
       "-0.2311\n",
       "-0.7833\n",
       " 0.0180\n",
       "-0.1572\n",
       " 0.0229\n",
       " 0.4964\n",
       " 0.0292\n",
       " 0.0567\n",
       " 0.1462\n",
       "-0.1919\n",
       " 0.1624\n",
       " 0.2390\n",
       " 0.3643\n",
       " 0.4526\n",
       " 0.2456\n",
       " 0.2380\n",
       " 0.3140\n",
       " 0.3487\n",
       "-0.0358\n",
       " 0.5611\n",
       "-0.2535\n",
       " 0.0520\n",
       "-0.1062\n",
       "-0.3096\n",
       " 1.0585\n",
       "-0.4202\n",
       " 0.1822\n",
       "-0.1126\n",
       " 0.4058\n",
       " 0.1178\n",
       "-0.1971\n",
       "-0.0753\n",
       " 0.0807\n",
       "-0.0278\n",
       "-0.1562\n",
       "-0.4468\n",
       "-0.1516\n",
       " 0.1692\n",
       " 0.0983\n",
       "-0.0319\n",
       " 0.0871\n",
       " 0.2608\n",
       " 0.0027\n",
       " 0.1319\n",
       " 0.3444\n",
       "-0.3789\n",
       "-0.4114\n",
       " 0.0816\n",
       "-0.1167\n",
       "-0.4371\n",
       " 0.0111\n",
       " 0.0994\n",
       " 0.2661\n",
       " 0.4002\n",
       " 0.1890\n",
       "-0.1844\n",
       "-0.3036\n",
       "-0.2725\n",
       " 0.2247\n",
       "-0.4061\n",
       " 0.1562\n",
       "-0.1604\n",
       " 0.4715\n",
       " 0.0080\n",
       " 0.5686\n",
       " 0.2193\n",
       "-0.1118\n",
       " 0.7993\n",
       " 0.1071\n",
       "-0.5015\n",
       " 0.0636\n",
       " 0.0695\n",
       " 0.1529\n",
       "-0.2747\n",
       "-0.2099\n",
       " 0.2074\n",
       "-0.1068\n",
       " 0.4065\n",
       "-2.6438\n",
       "-0.3114\n",
       "-0.3216\n",
       "-0.2646\n",
       "-0.3562\n",
       " 0.0700\n",
       "-0.1884\n",
       " 0.4877\n",
       "-0.2617\n",
       "-0.0208\n",
       " 0.1782\n",
       " 0.1576\n",
       "-0.1375\n",
       " 0.0565\n",
       " 0.3077\n",
       "-0.0661\n",
       " 0.4748\n",
       "-0.2734\n",
       " 0.0973\n",
       "-0.2083\n",
       " 0.0039\n",
       " 0.3460\n",
       "-0.0870\n",
       "-0.5492\n",
       "-0.1876\n",
       "-0.1717\n",
       " 0.0603\n",
       "-0.1352\n",
       " 0.1042\n",
       " 0.3016\n",
       " 0.0580\n",
       " 0.2187\n",
       "-0.0736\n",
       "-0.2042\n",
       "-0.2528\n",
       "-0.1047\n",
       "-0.3216\n",
       " 0.1252\n",
       "-0.3128\n",
       " 0.0097\n",
       "-0.2678\n",
       "-0.6112\n",
       "-0.1109\n",
       "-0.1365\n",
       " 0.0351\n",
       "-0.4939\n",
       " 0.0849\n",
       "-0.1549\n",
       "-0.0635\n",
       "-0.2394\n",
       " 0.2827\n",
       " 0.1085\n",
       "-0.3365\n",
       "-0.6076\n",
       " 0.3858\n",
       "-0.0095\n",
       " 0.1750\n",
       "-0.5272\n",
       " 0.6221\n",
       " 0.1954\n",
       "-0.4898\n",
       " 0.0366\n",
       "-0.1280\n",
       "-0.0168\n",
       " 0.2565\n",
       "-0.3170\n",
       " 0.4826\n",
       "-0.1418\n",
       " 0.1105\n",
       "-0.3098\n",
       "-0.6314\n",
       "-0.3727\n",
       " 0.2318\n",
       "-0.1427\n",
       "-0.0234\n",
       " 0.0223\n",
       "-0.0447\n",
       "-0.1640\n",
       "-0.2585\n",
       " 0.1629\n",
       " 0.0248\n",
       " 0.2335\n",
       " 0.2793\n",
       " 0.3900\n",
       "-0.0590\n",
       " 0.1135\n",
       " 0.1567\n",
       " 0.1858\n",
       "-0.1981\n",
       "-0.4812\n",
       "-0.0351\n",
       " 0.0785\n",
       "-0.4983\n",
       " 0.1085\n",
       "-0.2013\n",
       " 0.0529\n",
       "-0.1158\n",
       "-0.1601\n",
       " 0.1677\n",
       " 0.4236\n",
       "-0.2311\n",
       " 0.0825\n",
       " 0.2430\n",
       "-0.1679\n",
       " 0.0080\n",
       " 0.0859\n",
       " 0.3803\n",
       " 0.0730\n",
       " 0.1633\n",
       " 0.2470\n",
       "-0.1109\n",
       " 0.1512\n",
       "-0.2207\n",
       "-0.0619\n",
       "-0.0371\n",
       "-0.0879\n",
       "-0.2318\n",
       " 0.1504\n",
       "-0.1909\n",
       "-0.1911\n",
       "-0.1189\n",
       " 0.0949\n",
       "-0.0043\n",
       " 0.1536\n",
       "-0.4120\n",
       "-0.3073\n",
       " 0.1838\n",
       " 0.4021\n",
       "-0.0035\n",
       "-0.1092\n",
       "-0.6952\n",
       " 0.1016\n",
       "-0.0793\n",
       " 0.4033\n",
       " 0.2228\n",
       "-0.1937\n",
       "-0.1331\n",
       " 0.0732\n",
       " 0.0998\n",
       " 0.1169\n",
       "-0.2164\n",
       "-0.1108\n",
       " 0.1034\n",
       " 0.0973\n",
       " 0.1120\n",
       "-0.3894\n",
       "-0.0089\n",
       " 0.2881\n",
       "-0.1079\n",
       " 0.0288\n",
       " 0.3255\n",
       " 0.2605\n",
       "-0.0389\n",
       " 0.0752\n",
       " 0.4603\n",
       "-0.0629\n",
       " 0.2166\n",
       " 0.1787\n",
       "-0.5192\n",
       " 0.3359\n",
       "[torch.FloatTensor of size 300]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors['hello'] #it works! embedding length is 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b> Data Processing<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../train_nn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = ['CAPS', 'Obscenity', 'Threat', 'hatespeech', 'namecalling', 'negprejudice', 'noneng', 'porn', 'stereotypes']\n",
    "\n",
    "for label in labels:\n",
    "    cols = [label + str(x) for x in range(1,8)]\n",
    "    train[label + '_num_yes'] = train[cols].sum(axis = 1)\n",
    "    train[label] = pd.Series(train[label + '_num_yes'] >= 2).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = train.loc[train['clean_tweet'].isnull() == False,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab = Counter()\n",
    "\n",
    "for text in train.clean_tweet:\n",
    "    for word in text.split(' '):\n",
    "        vocab[word.lower()]+=1\n",
    "\n",
    "total_words = len(vocab)\n",
    "\n",
    "def get_word_2_index(vocab):\n",
    "    word2index = {}\n",
    "    index2word = {}\n",
    "    for i,word in enumerate(vocab):\n",
    "        word2index[word.lower()] = i+1\n",
    "        index2word[i+1] = word.lower()\n",
    "\n",
    "    return word2index, index2word\n",
    "\n",
    "word2index, index2word = get_word_2_index(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrix_len = len(target_vocab)\n",
    "weights_matrix = np.zeros((matrix_len, 50))\n",
    "words_found = 0\n",
    "\n",
    "for i, word in enumerate(target_vocab):\n",
    "    try: \n",
    "        weights_matrix[i] = glove[word]\n",
    "        words_found += 1\n",
    "    except KeyError:\n",
    "        weights_matrix[i] = np.random.normal(scale=0.6, size=(emb_dim, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word2index['PAD'] = 0\n",
    "index2word[0] = 'PAD'\n",
    "\n",
    "total_words = total_words + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pad_data(s, length):\n",
    "    padded = np.zeros((length,), dtype = np.int64)\n",
    "    if len(s) > length: \n",
    "        padded = s[:length]\n",
    "    else:\n",
    "        padded[:len(s)] = s\n",
    "    return np.array(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['seq_len'] = [len(x.split(' ')) for x in train['clean_tweet']]\n",
    "\n",
    "train['numeric'] = [[word2index[y] for y in x.split(' ')] for x in train['clean_tweet']]\n",
    "\n",
    "train['padded_tweet'] = [pad_data(x, 10) for x in train.numeric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#if we want validation accuracy to better resemble test accuracy, need to create vocab on training only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_sub, validation = model_selection.train_test_split(train, test_size = 0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# subclass the custom dataset class with torch.utils.data.Dataset\n",
    "# implement __len__ and __getitem__ function\n",
    "class VectorizeData(Dataset):\n",
    "    def __init__(self, df, label, maxlen=20):\n",
    "        self.df = df\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X = self.df.padded_tweet[idx]\n",
    "        y = self.df[self.label][idx]\n",
    "        lens = self.df.seq_len[idx]\n",
    "        return X,y,lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sub.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = VectorizeData(train_sub, label = 'hatespeech')\n",
    "\n",
    "dl = DataLoader(data, batch_size = 32, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_size, batch_size):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=1)\n",
    "        self.hidden2out = nn.Linear(hidden_dim, output_size)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "        self.dropout_layer = nn.Dropout(p=0.2)\n",
    "        self.batch_size = batch_size\n",
    "        #self.hidden = self.init_hidden(batch_size)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return(autograd.Variable(torch.randn(1, batch_size, self.hidden_dim)), \\\n",
    "               autograd.Variable(torch.randn(1, batch_size, self.hidden_dim)))\n",
    "\n",
    "    def forward(self, batch): #removed lengths\n",
    "        #should reinitalize hidden states before each batch?\n",
    "        self.hidden = self.init_hidden(batch_size)\n",
    "        embeds = self.embedding(batch)\n",
    "        #packed_input = pack_padded_sequence(embeds, lengths)\n",
    "        outputs, (ht, ct) = self.lstm(embeds, self.hidden)\n",
    "        # ht is the last hidden state of the sequences\n",
    "        # ht = (1 x batch_size x hidden_dim)\n",
    "        # ht[-1] = (batch_size x hidden_dim)\n",
    "        output = self.dropout_layer(ht[-1])\n",
    "        output = self.hidden2out(output)\n",
    "        output = self.softmax(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_size = 100 \n",
    "num_classes = 2\n",
    "learning_rate = 0.01\n",
    "num_epochs = 5\n",
    "batch_size = 32\n",
    "#momentum = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11059"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39.313131313131315"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3892/99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [4/124], Loss: 0.4466\n",
      "Epoch [1/5], Step [8/124], Loss: 1.1213\n",
      "Epoch [1/5], Step [12/124], Loss: 0.6024\n",
      "Epoch [1/5], Step [16/124], Loss: 0.2748\n",
      "Epoch [1/5], Step [20/124], Loss: 0.2060\n",
      "Epoch [1/5], Step [24/124], Loss: 2.5953\n",
      "Epoch [1/5], Step [28/124], Loss: 0.1384\n",
      "Epoch [1/5], Step [32/124], Loss: 0.1976\n",
      "Epoch [1/5], Step [36/124], Loss: 0.2812\n",
      "Epoch [1/5], Step [40/124], Loss: 0.7596\n",
      "Epoch [1/5], Step [44/124], Loss: 0.4808\n",
      "Epoch [1/5], Step [48/124], Loss: 0.6191\n",
      "Epoch [1/5], Step [52/124], Loss: 0.3943\n",
      "Epoch [1/5], Step [56/124], Loss: 0.4925\n",
      "Epoch [1/5], Step [60/124], Loss: 0.4077\n",
      "Epoch [1/5], Step [64/124], Loss: 0.3699\n",
      "Epoch [1/5], Step [68/124], Loss: 0.5234\n",
      "Epoch [1/5], Step [72/124], Loss: 0.8046\n",
      "Epoch [1/5], Step [76/124], Loss: 0.2968\n",
      "Epoch [1/5], Step [80/124], Loss: 0.9429\n",
      "Epoch [1/5], Step [84/124], Loss: 0.5835\n",
      "Epoch [1/5], Step [88/124], Loss: 0.6065\n",
      "Epoch [1/5], Step [92/124], Loss: 0.7848\n",
      "Epoch [1/5], Step [96/124], Loss: 0.9492\n",
      "Epoch [2/5], Step [4/124], Loss: 0.3558\n",
      "Epoch [2/5], Step [8/124], Loss: 0.1940\n",
      "Epoch [2/5], Step [12/124], Loss: 0.1153\n",
      "Epoch [2/5], Step [16/124], Loss: 0.0919\n",
      "Epoch [2/5], Step [20/124], Loss: 0.0967\n",
      "Epoch [2/5], Step [24/124], Loss: 0.1345\n",
      "Epoch [2/5], Step [28/124], Loss: 0.2197\n",
      "Epoch [2/5], Step [32/124], Loss: 0.1631\n",
      "Epoch [2/5], Step [36/124], Loss: 0.2953\n",
      "Epoch [2/5], Step [40/124], Loss: 0.2888\n",
      "Epoch [2/5], Step [44/124], Loss: 0.2050\n",
      "Epoch [2/5], Step [48/124], Loss: 0.0785\n",
      "Epoch [2/5], Step [52/124], Loss: 0.0629\n",
      "Epoch [2/5], Step [56/124], Loss: 0.1421\n",
      "Epoch [2/5], Step [60/124], Loss: 0.1270\n",
      "Epoch [2/5], Step [64/124], Loss: 0.1353\n",
      "Epoch [2/5], Step [68/124], Loss: 1.1554\n",
      "Epoch [2/5], Step [72/124], Loss: 1.2708\n",
      "Epoch [2/5], Step [76/124], Loss: 0.1078\n",
      "Epoch [2/5], Step [80/124], Loss: 0.1406\n",
      "Epoch [2/5], Step [84/124], Loss: 0.3013\n",
      "Epoch [2/5], Step [88/124], Loss: 0.2101\n",
      "Epoch [2/5], Step [92/124], Loss: 0.2120\n",
      "Epoch [2/5], Step [96/124], Loss: 0.2638\n",
      "Epoch [3/5], Step [4/124], Loss: 0.0266\n",
      "Epoch [3/5], Step [8/124], Loss: 0.0416\n",
      "Epoch [3/5], Step [12/124], Loss: 0.0823\n",
      "Epoch [3/5], Step [16/124], Loss: 0.0523\n",
      "Epoch [3/5], Step [20/124], Loss: 0.0139\n",
      "Epoch [3/5], Step [24/124], Loss: 0.1634\n",
      "Epoch [3/5], Step [28/124], Loss: 0.0245\n",
      "Epoch [3/5], Step [32/124], Loss: 0.5784\n",
      "Epoch [3/5], Step [36/124], Loss: 0.0385\n",
      "Epoch [3/5], Step [40/124], Loss: 0.0738\n",
      "Epoch [3/5], Step [44/124], Loss: 0.1332\n",
      "Epoch [3/5], Step [48/124], Loss: 0.0313\n",
      "Epoch [3/5], Step [52/124], Loss: 0.7754\n",
      "Epoch [3/5], Step [56/124], Loss: 0.0356\n",
      "Epoch [3/5], Step [60/124], Loss: 1.3322\n",
      "Epoch [3/5], Step [64/124], Loss: 0.0229\n",
      "Epoch [3/5], Step [68/124], Loss: 0.0656\n",
      "Epoch [3/5], Step [72/124], Loss: 0.0596\n",
      "Epoch [3/5], Step [76/124], Loss: 0.2645\n",
      "Epoch [3/5], Step [80/124], Loss: 0.1022\n",
      "Epoch [3/5], Step [84/124], Loss: 0.0245\n",
      "Epoch [3/5], Step [88/124], Loss: 0.0268\n",
      "Epoch [3/5], Step [92/124], Loss: 0.0346\n",
      "Epoch [3/5], Step [96/124], Loss: 0.1041\n",
      "Epoch [4/5], Step [4/124], Loss: 0.0116\n",
      "Epoch [4/5], Step [8/124], Loss: 0.0172\n",
      "Epoch [4/5], Step [12/124], Loss: 0.0186\n",
      "Epoch [4/5], Step [16/124], Loss: 0.0296\n",
      "Epoch [4/5], Step [20/124], Loss: 0.2280\n",
      "Epoch [4/5], Step [24/124], Loss: 0.0245\n",
      "Epoch [4/5], Step [28/124], Loss: 0.0102\n",
      "Epoch [4/5], Step [32/124], Loss: 0.0076\n",
      "Epoch [4/5], Step [36/124], Loss: 0.3469\n",
      "Epoch [4/5], Step [40/124], Loss: 0.0134\n",
      "Epoch [4/5], Step [44/124], Loss: 0.2585\n",
      "Epoch [4/5], Step [48/124], Loss: 0.0225\n",
      "Epoch [4/5], Step [52/124], Loss: 0.0261\n",
      "Epoch [4/5], Step [56/124], Loss: 0.0122\n",
      "Epoch [4/5], Step [60/124], Loss: 0.0086\n",
      "Epoch [4/5], Step [64/124], Loss: 0.0142\n",
      "Epoch [4/5], Step [68/124], Loss: 0.0190\n",
      "Epoch [4/5], Step [72/124], Loss: 0.0066\n",
      "Epoch [4/5], Step [76/124], Loss: 0.0248\n",
      "Epoch [4/5], Step [80/124], Loss: 0.4336\n",
      "Epoch [4/5], Step [84/124], Loss: 0.0195\n",
      "Epoch [4/5], Step [88/124], Loss: 0.3139\n",
      "Epoch [4/5], Step [92/124], Loss: 0.0446\n",
      "Epoch [4/5], Step [96/124], Loss: 0.0172\n",
      "Epoch [5/5], Step [4/124], Loss: 0.0088\n",
      "Epoch [5/5], Step [8/124], Loss: 0.0063\n",
      "Epoch [5/5], Step [12/124], Loss: 0.0172\n",
      "Epoch [5/5], Step [16/124], Loss: 0.0150\n",
      "Epoch [5/5], Step [20/124], Loss: 0.0064\n",
      "Epoch [5/5], Step [24/124], Loss: 0.0387\n",
      "Epoch [5/5], Step [28/124], Loss: 0.0093\n",
      "Epoch [5/5], Step [32/124], Loss: 0.0191\n",
      "Epoch [5/5], Step [36/124], Loss: 0.0015\n",
      "Epoch [5/5], Step [40/124], Loss: 0.0020\n",
      "Epoch [5/5], Step [44/124], Loss: 0.0088\n",
      "Epoch [5/5], Step [48/124], Loss: 0.0074\n",
      "Epoch [5/5], Step [52/124], Loss: 0.0026\n",
      "Epoch [5/5], Step [56/124], Loss: 0.0056\n",
      "Epoch [5/5], Step [60/124], Loss: 0.0030\n",
      "Epoch [5/5], Step [64/124], Loss: 0.0086\n",
      "Epoch [5/5], Step [68/124], Loss: 0.0092\n",
      "Epoch [5/5], Step [72/124], Loss: 0.5416\n",
      "Epoch [5/5], Step [76/124], Loss: 0.0031\n",
      "Epoch [5/5], Step [80/124], Loss: 0.0217\n",
      "Epoch [5/5], Step [84/124], Loss: 0.1385\n",
      "Epoch [5/5], Step [88/124], Loss: 0.0016\n",
      "Epoch [5/5], Step [92/124], Loss: 0.0769\n",
      "Epoch [5/5], Step [96/124], Loss: 0.0013\n"
     ]
    }
   ],
   "source": [
    "#add 1 because of pad token\n",
    "net = LSTMClassifier(total_words, hidden_size, hidden_size, num_classes, batch_size)\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.NLLLoss(weight = torch.Tensor([1/39,1]))  \n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)#, momentum = momentum, weight_decay = 0.0001)\n",
    "#scheduler = MultiStepLR(optimizer, milestones=[31,62,93,124], gamma = 0.1)\n",
    "\n",
    "losses = []\n",
    "\n",
    "num_batch = len(dl) - 1\n",
    "# Train the Model\n",
    "for epoch in range(num_epochs):\n",
    "    it = iter(dl)\n",
    "    # Loop over all batches\n",
    "    for i in range(num_batch):\n",
    "        batch_x,batch_y,batch_len = next(it)\n",
    "        tweets = Variable(batch_x.transpose(0,1))\n",
    "        labels = Variable(batch_y)\n",
    "        lengths = Variable(batch_len)\n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()  # zero the gradient buffer\n",
    "        outputs = net(tweets)\n",
    "        loss = criterion(outputs, labels)\n",
    "        losses.append(loss.data[0])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 4 == 0:\n",
    "            print ('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
    "                   %(epoch+1, num_epochs, i+1, len(train.clean_tweet)//batch_size, loss.data[0]))\n",
    "            \n",
    "    #scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11707ddd8>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111346e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = VectorizeData(validation, label = 'hatespeech')\n",
    "\n",
    "dl2 = DataLoader(data, batch_size = 32, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "pred_labels = []\n",
    "#get training predictions\n",
    "it = iter(dl2)\n",
    "num_batch = len(dl2) - 1\n",
    "# Loop over all batches\n",
    "for i in range(num_batch):\n",
    "    batch_x,batch_y,batch_len = next(it)\n",
    "    tweets = Variable(batch_x.transpose(0,1))\n",
    "    labels = Variable(batch_y)\n",
    "    lengths = Variable(batch_len)\n",
    "    # Forward + Backward + Optimize\n",
    "    outputs = net(tweets)\n",
    "    _, pred = torch.max(outputs.data, 1)\n",
    "    predictions.extend(list(pred.numpy()))\n",
    "    pred_labels.extend(list(labels.data.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    728\n",
       "1     40\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(predictions).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46875"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(pred_labels, predictions)\n",
    "#overfits to training data almost perfectly with 10 epochs, but validation accuracy is low"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
