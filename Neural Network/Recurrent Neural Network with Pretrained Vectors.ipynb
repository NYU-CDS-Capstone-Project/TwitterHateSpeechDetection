{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Import libraries<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as autograd\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils import clip_grad_norm\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import model_selection\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#drew inspiration from\n",
    "#https://github.com/dmesquita/understanding_pytorch_nn and\n",
    "#https://github.com/msahamed/yelp_comments_classification_nlp/blob/master/word_embeddings.ipynb\n",
    "#https://github.com/nyu-mll/DS-GA-1011-Fall2017/blob/master/week%20eight/Week%20Eight%20Solutions.ipynb\n",
    "#https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html\n",
    "#https://github.com/claravania/lstm-pytorch/blob/master/model.py\n",
    "#https://medium.com/@sonicboom8/sentiment-analysis-with-variable-length-sequences-in-pytorch-6241635ae130\n",
    "#https://github.com/hpanwar08/sentence-classification-pytorch/blob/master/Sentiment%20analysis%20pytorch.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://medium.com/@martinpella/how-to-use-pre-trained-word-embeddings-in-pytorch-71ca59249f76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://modelzoo.co/model/pytorch-nlp\n",
    "#http://anie.me/On-Torchtext/\n",
    "#https://readthedocs.org/projects/pytorchnlp/downloads/pdf/latest/\n",
    "#https://github.com/A-Jacobson/CNN_Sentence_Classification/blob/master/WordVectors.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b> Data Processing<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../train_nn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = ['CAPS', 'Obscenity', 'Threat', 'hatespeech', 'namecalling', 'negprejudice', 'noneng', 'porn', 'stereotypes']\n",
    "\n",
    "for label in labels:\n",
    "    cols = [label + str(x) for x in range(1,8)]\n",
    "    train[label + '_num_yes'] = train[cols].sum(axis = 1)\n",
    "    train[label] = pd.Series(train[label + '_num_yes'] >= 2).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5465\n",
       "1     134\n",
       "Name: hatespeech, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['hatespeech'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02539492101579684"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "127/(127 + 4874) #previous ratio, before adding new tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.023932845150919806"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "134/(5465 + 134)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hatespeech</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>1</td>\n",
       "      <td>hahahaha fat transgender cunt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      hatespeech                    clean_tweet\n",
       "1586           1  hahahaha fat transgender cunt"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[train.Tweet.str.contains(\"FAT TRANSGENDER\"), ['hatespeech', 'clean_tweet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = train.loc[train['clean_tweet'].isnull() == False,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word2index = {}\n",
    "index2word = {}\n",
    "\n",
    "word2index['PAD'] = 0\n",
    "index2word[0] = 'PAD'\n",
    "\n",
    "word2index['UNK'] = 1\n",
    "index2word[1] = 'UNK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab = Counter()\n",
    "\n",
    "for text in train.clean_tweet:\n",
    "    for word in text.split(' '):\n",
    "        vocab[word.lower()]+=1\n",
    "\n",
    "total_words = len(vocab)\n",
    "\n",
    "for i,word in enumerate(vocab):\n",
    "    word2index[word.lower()] = i+2\n",
    "    index2word[i+2] = word.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_words = total_words + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_glove(path):\n",
    "    \"\"\"\n",
    "    creates a dictionary mapping words to vectors from a file in glove format.\n",
    "    \"\"\"\n",
    "    with open(path) as f:\n",
    "        glove = {}\n",
    "        for line in f.readlines():\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.array(values[1:], dtype='float32')\n",
    "            glove[word] = vector\n",
    "        return glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 16s, sys: 22.3 s, total: 1min 38s\n",
      "Wall time: 1min 58s\n"
     ]
    }
   ],
   "source": [
    "glove_path = \"/Users/carolineroper/Desktop/Capstone Project/Neural Network/glove.twitter.27B/glove.twitter.27B.200d.txt\"\n",
    "%time glove = load_glove(glove_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2938"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2index['hello']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.46830010e-01,  -1.96119994e-01,  -3.49229991e-01,\n",
       "        -2.81580001e-01,  -7.56269991e-01,  -4.00349982e-02,\n",
       "         5.34219980e-01,   1.53270003e-03,  -2.19630003e-01,\n",
       "        -5.67080021e-01,  -7.51120001e-02,   3.90740007e-01,\n",
       "         1.92010000e-01,   4.80460003e-02,  -1.68009996e-01,\n",
       "        -1.91400006e-01,   1.21619999e-01,  -2.25130007e-01,\n",
       "         2.22759992e-02,  -2.76320010e-01,   1.07210003e-01,\n",
       "        -5.81910014e-02,  -1.76540002e-01,  -2.06199996e-02,\n",
       "        -3.97679992e-02,   1.26190007e-01,   1.89270005e-01,\n",
       "         1.70169994e-01,  -2.34529991e-02,  -4.23489988e-01,\n",
       "        -4.26400006e-02,  -2.81010002e-01,  -3.24609995e-01,\n",
       "         3.08699995e-01,   9.45290029e-02,   1.35590002e-01,\n",
       "        -5.02489984e-01,   3.00720006e-01,   1.58050001e-01,\n",
       "         5.50790012e-01,  -3.70050013e-01,  -2.17209995e-01,\n",
       "        -7.11619973e-01,   4.29749995e-01,  -1.24509996e-02,\n",
       "        -2.42750004e-01,  -6.29020035e-02,   4.37549986e-02,\n",
       "         5.90980016e-02,   2.15529993e-01,   3.40479985e-02,\n",
       "        -1.57350004e-01,  -4.47309986e-02,  -1.27189994e-01,\n",
       "         3.33469987e-01,   2.23859996e-01,   3.97159994e-01,\n",
       "         8.43819976e-02,  -4.70569991e-02,  -1.49430007e-01,\n",
       "         2.01399997e-02,  -5.13449982e-02,  -1.77820008e-02,\n",
       "        -4.85579997e-01,  -4.40770015e-02,   3.86900008e-01,\n",
       "        -3.51390004e-01,   8.89970005e-01,   6.69700027e-01,\n",
       "        -4.40119989e-02,   4.26730007e-01,  -1.96710005e-01,\n",
       "        -5.85529990e-02,   1.02069996e-01,  -3.70260000e-01,\n",
       "         2.96330005e-01,   4.60469991e-01,   3.56990010e-01,\n",
       "        -2.15639994e-01,   5.06760001e-01,   4.05409992e-01,\n",
       "         4.15380001e-01,   5.34810007e-01,   2.20500007e-01,\n",
       "         1.55780002e-01,  -5.70949972e-01,  -5.50019979e-01,\n",
       "         5.38770020e-01,   3.34190011e-01,  -3.31999987e-01,\n",
       "        -2.02110007e-01,  -3.72189999e-01,  -1.10299997e-01,\n",
       "         8.95290017e-01,  -2.10519999e-01,  -1.30119994e-01,\n",
       "        -2.42339998e-01,  -3.03470008e-02,   2.25569993e-01,\n",
       "         2.46030003e-01,  -4.70919997e-01,   6.57190010e-02,\n",
       "        -7.65509978e-02,  -2.37489998e-01,  -2.78149992e-01,\n",
       "         2.20500007e-01,   2.05669999e-01,   5.34839988e-01,\n",
       "        -1.17660001e-01,   8.30340013e-02,  -5.71230017e-02,\n",
       "        -1.76139995e-01,  -4.97150004e-01,   1.28289998e-01,\n",
       "        -1.52419999e-01,  -7.73880005e-01,  -7.81400025e-01,\n",
       "        -4.31719989e-01,   6.76060021e-01,   2.92690009e-01,\n",
       "         1.96710005e-01,   5.05530000e-01,  -1.89209998e-01,\n",
       "        -1.88999996e-01,   7.10150003e-02,  -3.93469989e-01,\n",
       "         7.74319982e-03,  -7.63300002e-01,  -4.18280005e-01,\n",
       "         4.38820004e-01,   8.99469972e-01,  -2.40669996e-01,\n",
       "         1.38630003e-01,   2.53309995e-01,  -1.08690001e-02,\n",
       "        -1.01340003e-01,  -3.43650013e-01,   7.19609976e-01,\n",
       "         1.68559998e-01,   9.60540026e-02,  -1.72350004e-01,\n",
       "        -5.26499987e-01,   1.96500003e-01,  -9.11900029e-02,\n",
       "        -1.76569998e-01,   1.48699999e-01,  -2.31759995e-02,\n",
       "         9.75740016e-01,   7.65380025e-01,  -2.87939996e-01,\n",
       "         3.57760012e-01,   1.43210003e-02,  -3.83780003e+00,\n",
       "        -1.78489998e-01,  -4.89069998e-01,   4.22560014e-02,\n",
       "        -6.94400012e-01,  -3.79290015e-01,  -4.33890000e-02,\n",
       "        -1.56560004e-01,   7.40360022e-01,  -3.70370001e-01,\n",
       "        -3.35020006e-01,  -5.39570004e-02,  -1.74779996e-01,\n",
       "        -6.73770010e-02,   4.20540005e-01,  -5.86589985e-02,\n",
       "        -2.42180005e-01,  -8.40779990e-02,  -3.03719997e-01,\n",
       "         1.35490000e-01,   2.70880014e-01,   4.79490012e-01,\n",
       "         3.33929993e-02,   7.09469974e-01,  -2.88120002e-01,\n",
       "         2.96270013e-01,  -4.10059988e-01,  -2.76690006e-01,\n",
       "        -1.70460001e-01,   3.84479985e-02,  -1.07420003e-02,\n",
       "         3.82499993e-01,   8.68320018e-02,  -1.78350005e-02,\n",
       "        -7.03899980e-01,   1.96139999e-02,   8.27580038e-03,\n",
       "         3.20300013e-01,   3.50510003e-03,   3.31299990e-01,\n",
       "         1.53259993e-01,  -2.20070004e-01,  -4.57010001e-01,\n",
       "        -1.77190006e-02,  -6.19970024e-01,  -5.20730019e-01,\n",
       "         8.22940022e-02,  -5.44780016e-01], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove['hello']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matrix_len = len(vocab) + 2\n",
    "weights_matrix = np.zeros((matrix_len, 200))\n",
    "words_found = 0\n",
    "\n",
    "for i, word in index2word.items():\n",
    "    try: \n",
    "        weights_matrix[i] = glove[index2word[i]]\n",
    "        words_found += 1\n",
    "    except KeyError:\n",
    "        weights_matrix[i] = np.random.rand(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7569622051719238"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_found/len(vocab) #76% of words were found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights_matrix[0, ] = np.zeros(200) #initialize pad embedding to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.46830010e-01,  -1.96119994e-01,  -3.49229991e-01,\n",
       "        -2.81580001e-01,  -7.56269991e-01,  -4.00349982e-02,\n",
       "         5.34219980e-01,   1.53270003e-03,  -2.19630003e-01,\n",
       "        -5.67080021e-01,  -7.51120001e-02,   3.90740007e-01,\n",
       "         1.92010000e-01,   4.80460003e-02,  -1.68009996e-01,\n",
       "        -1.91400006e-01,   1.21619999e-01,  -2.25130007e-01,\n",
       "         2.22759992e-02,  -2.76320010e-01,   1.07210003e-01,\n",
       "        -5.81910014e-02,  -1.76540002e-01,  -2.06199996e-02,\n",
       "        -3.97679992e-02,   1.26190007e-01,   1.89270005e-01,\n",
       "         1.70169994e-01,  -2.34529991e-02,  -4.23489988e-01,\n",
       "        -4.26400006e-02,  -2.81010002e-01,  -3.24609995e-01,\n",
       "         3.08699995e-01,   9.45290029e-02,   1.35590002e-01,\n",
       "        -5.02489984e-01,   3.00720006e-01,   1.58050001e-01,\n",
       "         5.50790012e-01,  -3.70050013e-01,  -2.17209995e-01,\n",
       "        -7.11619973e-01,   4.29749995e-01,  -1.24509996e-02,\n",
       "        -2.42750004e-01,  -6.29020035e-02,   4.37549986e-02,\n",
       "         5.90980016e-02,   2.15529993e-01,   3.40479985e-02,\n",
       "        -1.57350004e-01,  -4.47309986e-02,  -1.27189994e-01,\n",
       "         3.33469987e-01,   2.23859996e-01,   3.97159994e-01,\n",
       "         8.43819976e-02,  -4.70569991e-02,  -1.49430007e-01,\n",
       "         2.01399997e-02,  -5.13449982e-02,  -1.77820008e-02,\n",
       "        -4.85579997e-01,  -4.40770015e-02,   3.86900008e-01,\n",
       "        -3.51390004e-01,   8.89970005e-01,   6.69700027e-01,\n",
       "        -4.40119989e-02,   4.26730007e-01,  -1.96710005e-01,\n",
       "        -5.85529990e-02,   1.02069996e-01,  -3.70260000e-01,\n",
       "         2.96330005e-01,   4.60469991e-01,   3.56990010e-01,\n",
       "        -2.15639994e-01,   5.06760001e-01,   4.05409992e-01,\n",
       "         4.15380001e-01,   5.34810007e-01,   2.20500007e-01,\n",
       "         1.55780002e-01,  -5.70949972e-01,  -5.50019979e-01,\n",
       "         5.38770020e-01,   3.34190011e-01,  -3.31999987e-01,\n",
       "        -2.02110007e-01,  -3.72189999e-01,  -1.10299997e-01,\n",
       "         8.95290017e-01,  -2.10519999e-01,  -1.30119994e-01,\n",
       "        -2.42339998e-01,  -3.03470008e-02,   2.25569993e-01,\n",
       "         2.46030003e-01,  -4.70919997e-01,   6.57190010e-02,\n",
       "        -7.65509978e-02,  -2.37489998e-01,  -2.78149992e-01,\n",
       "         2.20500007e-01,   2.05669999e-01,   5.34839988e-01,\n",
       "        -1.17660001e-01,   8.30340013e-02,  -5.71230017e-02,\n",
       "        -1.76139995e-01,  -4.97150004e-01,   1.28289998e-01,\n",
       "        -1.52419999e-01,  -7.73880005e-01,  -7.81400025e-01,\n",
       "        -4.31719989e-01,   6.76060021e-01,   2.92690009e-01,\n",
       "         1.96710005e-01,   5.05530000e-01,  -1.89209998e-01,\n",
       "        -1.88999996e-01,   7.10150003e-02,  -3.93469989e-01,\n",
       "         7.74319982e-03,  -7.63300002e-01,  -4.18280005e-01,\n",
       "         4.38820004e-01,   8.99469972e-01,  -2.40669996e-01,\n",
       "         1.38630003e-01,   2.53309995e-01,  -1.08690001e-02,\n",
       "        -1.01340003e-01,  -3.43650013e-01,   7.19609976e-01,\n",
       "         1.68559998e-01,   9.60540026e-02,  -1.72350004e-01,\n",
       "        -5.26499987e-01,   1.96500003e-01,  -9.11900029e-02,\n",
       "        -1.76569998e-01,   1.48699999e-01,  -2.31759995e-02,\n",
       "         9.75740016e-01,   7.65380025e-01,  -2.87939996e-01,\n",
       "         3.57760012e-01,   1.43210003e-02,  -3.83780003e+00,\n",
       "        -1.78489998e-01,  -4.89069998e-01,   4.22560014e-02,\n",
       "        -6.94400012e-01,  -3.79290015e-01,  -4.33890000e-02,\n",
       "        -1.56560004e-01,   7.40360022e-01,  -3.70370001e-01,\n",
       "        -3.35020006e-01,  -5.39570004e-02,  -1.74779996e-01,\n",
       "        -6.73770010e-02,   4.20540005e-01,  -5.86589985e-02,\n",
       "        -2.42180005e-01,  -8.40779990e-02,  -3.03719997e-01,\n",
       "         1.35490000e-01,   2.70880014e-01,   4.79490012e-01,\n",
       "         3.33929993e-02,   7.09469974e-01,  -2.88120002e-01,\n",
       "         2.96270013e-01,  -4.10059988e-01,  -2.76690006e-01,\n",
       "        -1.70460001e-01,   3.84479985e-02,  -1.07420003e-02,\n",
       "         3.82499993e-01,   8.68320018e-02,  -1.78350005e-02,\n",
       "        -7.03899980e-01,   1.96139999e-02,   8.27580038e-03,\n",
       "         3.20300013e-01,   3.50510003e-03,   3.31299990e-01,\n",
       "         1.53259993e-01,  -2.20070004e-01,  -4.57010001e-01,\n",
       "        -1.77190006e-02,  -6.19970024e-01,  -5.20730019e-01,\n",
       "         8.22940022e-02,  -5.44780016e-01])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_matrix[2938, ] #confirmed that at index \"hello\" we're seeing the glove vector for \"hello\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14076"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14078, 200)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pad_data(s, length):\n",
    "    padded = np.zeros((length,), dtype = np.int64)\n",
    "    if len(s) > length: \n",
    "        padded = s[:length]\n",
    "    else:\n",
    "        padded[:len(s)] = s\n",
    "    return np.array(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_index(x):\n",
    "    try:\n",
    "        return word2index[x]\n",
    "    except KeyError:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['seq_len'] = [len(x.split(' ')) for x in train['clean_tweet']]\n",
    "\n",
    "train['numeric'] = [[get_index(y) for y in x.split(' ')] for x in train['clean_tweet']]\n",
    "\n",
    "train['padded_tweet'] = [pad_data(x, 25) for x in train.numeric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6292, 1151,  557, 6293,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.padded_tweet[1581]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x130796f28>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naPkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x130796908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.seq_len.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#if we want validation accuracy to better resemble test accuracy, need to create vocab on training only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_sub, validation = model_selection.train_test_split(train, test_size = 0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4467, 88)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# subclass the custom dataset class with torch.utils.data.Dataset\n",
    "# implement __len__ and __getitem__ function\n",
    "class VectorizeData(Dataset):\n",
    "    def __init__(self, df, label, maxlen=20):\n",
    "        self.df = df\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X = self.df.padded_tweet[idx]\n",
    "        y = self.df[self.label][idx]\n",
    "        lens = self.df.seq_len[idx]\n",
    "        return X,y,lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_sub.reset_index(inplace = True, drop = True)\n",
    "\n",
    "validation.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = VectorizeData(train_sub, label = 'hatespeech')\n",
    "\n",
    "dl = DataLoader(data, batch_size = 32, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sort_batch(X, y, lengths):\n",
    "    lengths, indx = lengths.sort(dim=0, descending=True)\n",
    "    X = X[indx]\n",
    "    y = y[indx]\n",
    "    return X, y, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, weights, vocab_size, embedding_dim, hidden_dim, output_size, batch_size):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.weights = weights\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.embedding.weight = nn.Parameter(self.weights)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=1)\n",
    "        self.hidden2out = nn.Linear(hidden_dim, output_size)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "        self.dropout_layer = nn.Dropout(p=0.2)\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        return(autograd.Variable(torch.randn(1, batch_size, self.hidden_dim)), \\\n",
    "               autograd.Variable(torch.randn(1, batch_size, self.hidden_dim)))\n",
    "\n",
    "    def forward(self, batch, lengths):\n",
    "        self.hidden = self.init_hidden(batch_size)\n",
    "        embeds = self.embedding(batch) \n",
    "        embeds = pack_padded_sequence(embeds, lengths)\n",
    "        outputs, (ht, ct) = self.lstm(embeds, self.hidden)\n",
    "        outputs, lengths = pad_packed_sequence(outputs)\n",
    "        # ht is the last hidden state of the sequences\n",
    "        # ht = (1 x batch_size x hidden_dim)\n",
    "        # ht[-1] = (batch_size x hidden_dim)\n",
    "        output = self.dropout_layer(ht[-1])\n",
    "        output = self.hidden2out(output)\n",
    "        output = self.softmax(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_size = 200 \n",
    "num_classes = 2\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "weights = torch.FloatTensor(weights_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_validation_loss(validation_data_loader, model):\n",
    "    predictions = []\n",
    "    pred_labels = []\n",
    "    #get training predictions\n",
    "    it = iter(validation_data_loader)\n",
    "    num_batch = len(validation_data_loader) - 1\n",
    "    # Loop over all batches\n",
    "    for i in range(num_batch):\n",
    "        batch_x,batch_y,batch_len = next(it)\n",
    "        batch_x,batch_y,batch_len = sort_batch(batch_x,batch_y,batch_len)\n",
    "        tweets = Variable(batch_x.transpose(0,1))\n",
    "        labels = Variable(batch_y)\n",
    "        lengths = batch_len.numpy()\n",
    "        outputs = model(tweets, lengths)\n",
    "        _, pred = torch.max(outputs.data, 1)\n",
    "        predictions.extend(list(pred.numpy()))\n",
    "        pred_labels.extend(list(labels.data.numpy()))\n",
    "    return (f1_score(predictions, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5450\n",
       "1     134\n",
       "Name: hatespeech, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.hatespeech.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = LSTMClassifier(weights, total_words, hidden_size, hidden_size, num_classes, batch_size)\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.NLLLoss(weight = torch.Tensor([1/41,1]))  \n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "#Validation Data\n",
    "val = VectorizeData(validation, label = 'hatespeech')\n",
    "dl2 = DataLoader(val, batch_size = 32, shuffle = False)\n",
    "\n",
    "losses = []\n",
    "val_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Step [6/174], Loss: 0.6040\n",
      "Epoch [1/30], Step [12/174], Loss: 0.5602\n",
      "Epoch [1/30], Step [18/174], Loss: 0.3809\n",
      "Epoch [1/30], Step [24/174], Loss: 1.3662\n",
      "Epoch [1/30], Step [30/174], Loss: 0.1468\n",
      "Epoch [1/30], Step [36/174], Loss: 1.0133\n",
      "Epoch [1/30], Step [42/174], Loss: 0.8776\n",
      "Epoch [1/30], Step [48/174], Loss: 0.7293\n",
      "Epoch [1/30], Step [54/174], Loss: 0.6186\n",
      "Epoch [1/30], Step [60/174], Loss: 0.7650\n",
      "Epoch [1/30], Step [66/174], Loss: 0.3344\n",
      "Epoch [1/30], Step [72/174], Loss: 0.3956\n",
      "Epoch [1/30], Step [78/174], Loss: 0.3785\n",
      "Epoch [1/30], Step [84/174], Loss: 0.2866\n",
      "Epoch [1/30], Step [90/174], Loss: 0.1174\n",
      "Epoch [1/30], Step [96/174], Loss: 0.0224\n",
      "Epoch [1/30], Step [102/174], Loss: 0.0379\n",
      "Epoch [1/30], Step [108/174], Loss: 0.0615\n",
      "Epoch [1/30], Step [114/174], Loss: 0.0604\n",
      "Epoch [1/30], Step [120/174], Loss: 0.2227\n",
      "Epoch [1/30], Step [126/174], Loss: 0.0597\n",
      "Epoch [1/30], Step [132/174], Loss: 0.1094\n",
      "Epoch [1/30], Step [138/174], Loss: 1.1911\n",
      "Epoch [2/30], Step [6/174], Loss: 0.0382\n",
      "Epoch [2/30], Step [12/174], Loss: 0.0412\n",
      "Epoch [2/30], Step [18/174], Loss: 0.0376\n",
      "Epoch [2/30], Step [24/174], Loss: 0.0529\n",
      "Epoch [2/30], Step [30/174], Loss: 1.7194\n",
      "Epoch [2/30], Step [36/174], Loss: 0.0957\n",
      "Epoch [2/30], Step [42/174], Loss: 0.1331\n",
      "Epoch [2/30], Step [48/174], Loss: 0.3227\n",
      "Epoch [2/30], Step [54/174], Loss: 0.0374\n",
      "Epoch [2/30], Step [60/174], Loss: 1.2325\n",
      "Epoch [2/30], Step [66/174], Loss: 0.0532\n",
      "Epoch [2/30], Step [72/174], Loss: 1.4132\n",
      "Epoch [2/30], Step [78/174], Loss: 1.2462\n",
      "Epoch [2/30], Step [84/174], Loss: 0.1665\n",
      "Epoch [2/30], Step [90/174], Loss: 0.1581\n",
      "Epoch [2/30], Step [96/174], Loss: 1.1009\n",
      "Epoch [2/30], Step [102/174], Loss: 1.0011\n",
      "Epoch [2/30], Step [108/174], Loss: 0.0227\n",
      "Epoch [2/30], Step [114/174], Loss: 1.8667\n",
      "Epoch [2/30], Step [120/174], Loss: 1.3294\n",
      "Epoch [2/30], Step [126/174], Loss: 0.0725\n",
      "Epoch [2/30], Step [132/174], Loss: 0.2198\n",
      "Epoch [2/30], Step [138/174], Loss: 0.0942\n",
      "Epoch [3/30], Step [6/174], Loss: 0.1007\n",
      "Epoch [3/30], Step [12/174], Loss: 0.0809\n",
      "Epoch [3/30], Step [18/174], Loss: 0.0217\n",
      "Epoch [3/30], Step [24/174], Loss: 0.0577\n",
      "Epoch [3/30], Step [30/174], Loss: 0.0871\n",
      "Epoch [3/30], Step [36/174], Loss: 0.0267\n",
      "Epoch [3/30], Step [42/174], Loss: 0.1365\n",
      "Epoch [3/30], Step [48/174], Loss: 0.0262\n",
      "Epoch [3/30], Step [54/174], Loss: 0.3725\n",
      "Epoch [3/30], Step [60/174], Loss: 0.1532\n",
      "Epoch [3/30], Step [66/174], Loss: 0.0805\n",
      "Epoch [3/30], Step [72/174], Loss: 0.0798\n",
      "Epoch [3/30], Step [78/174], Loss: 1.1118\n",
      "Epoch [3/30], Step [84/174], Loss: 0.1396\n",
      "Epoch [3/30], Step [90/174], Loss: 0.0389\n",
      "Epoch [3/30], Step [96/174], Loss: 0.2224\n",
      "Epoch [3/30], Step [102/174], Loss: 0.8273\n",
      "Epoch [3/30], Step [108/174], Loss: 0.0219\n",
      "Epoch [3/30], Step [114/174], Loss: 0.0154\n",
      "Epoch [3/30], Step [120/174], Loss: 0.1847\n",
      "Epoch [3/30], Step [126/174], Loss: 2.1823\n",
      "Epoch [3/30], Step [132/174], Loss: 0.0392\n",
      "Epoch [3/30], Step [138/174], Loss: 0.0267\n",
      "Epoch [4/30], Step [6/174], Loss: 1.5631\n",
      "Epoch [4/30], Step [12/174], Loss: 0.0325\n",
      "Epoch [4/30], Step [18/174], Loss: 0.2472\n",
      "Epoch [4/30], Step [24/174], Loss: 0.0342\n",
      "Epoch [4/30], Step [30/174], Loss: 0.0388\n",
      "Epoch [4/30], Step [36/174], Loss: 1.7238\n",
      "Epoch [4/30], Step [42/174], Loss: 0.0235\n",
      "Epoch [4/30], Step [48/174], Loss: 0.0230\n",
      "Epoch [4/30], Step [54/174], Loss: 0.0111\n",
      "Epoch [4/30], Step [60/174], Loss: 0.0212\n",
      "Epoch [4/30], Step [66/174], Loss: 1.1144\n",
      "Epoch [4/30], Step [72/174], Loss: 0.0230\n",
      "Epoch [4/30], Step [78/174], Loss: 0.0513\n",
      "Epoch [4/30], Step [84/174], Loss: 0.0074\n",
      "Epoch [4/30], Step [90/174], Loss: 0.0343\n",
      "Epoch [4/30], Step [96/174], Loss: 0.0224\n",
      "Epoch [4/30], Step [102/174], Loss: 0.1621\n",
      "Epoch [4/30], Step [108/174], Loss: 0.0242\n",
      "Epoch [4/30], Step [114/174], Loss: 0.1079\n",
      "Epoch [4/30], Step [120/174], Loss: 0.0209\n",
      "Epoch [4/30], Step [126/174], Loss: 0.8502\n",
      "Epoch [4/30], Step [132/174], Loss: 0.0342\n",
      "Epoch [4/30], Step [138/174], Loss: 0.0202\n",
      "Epoch [5/30], Step [6/174], Loss: 0.0108\n",
      "Epoch [5/30], Step [12/174], Loss: 0.3105\n",
      "Epoch [5/30], Step [18/174], Loss: 0.0200\n",
      "Epoch [5/30], Step [24/174], Loss: 0.1918\n",
      "Epoch [5/30], Step [30/174], Loss: 0.1109\n",
      "Epoch [5/30], Step [36/174], Loss: 0.2344\n",
      "Epoch [5/30], Step [42/174], Loss: 0.0092\n",
      "Epoch [5/30], Step [48/174], Loss: 0.0101\n",
      "Epoch [5/30], Step [54/174], Loss: 0.0134\n",
      "Epoch [5/30], Step [60/174], Loss: 0.0222\n",
      "Epoch [5/30], Step [66/174], Loss: 0.1346\n",
      "Epoch [5/30], Step [72/174], Loss: 0.1964\n",
      "Epoch [5/30], Step [78/174], Loss: 0.0056\n",
      "Epoch [5/30], Step [84/174], Loss: 0.0004\n",
      "Epoch [5/30], Step [90/174], Loss: 0.0038\n",
      "Epoch [5/30], Step [96/174], Loss: 0.0125\n",
      "Epoch [5/30], Step [102/174], Loss: 0.0291\n",
      "Epoch [5/30], Step [108/174], Loss: 0.1112\n",
      "Epoch [5/30], Step [114/174], Loss: 0.0573\n",
      "Epoch [5/30], Step [120/174], Loss: 0.0176\n",
      "Epoch [5/30], Step [126/174], Loss: 0.0020\n",
      "Epoch [5/30], Step [132/174], Loss: 0.0037\n",
      "Epoch [5/30], Step [138/174], Loss: 0.0022\n",
      "Epoch [6/30], Step [6/174], Loss: 0.0209\n",
      "Epoch [6/30], Step [12/174], Loss: 0.0141\n",
      "Epoch [6/30], Step [18/174], Loss: 0.0049\n",
      "Epoch [6/30], Step [24/174], Loss: 0.0015\n",
      "Epoch [6/30], Step [30/174], Loss: 0.0296\n",
      "Epoch [6/30], Step [36/174], Loss: 0.0075\n",
      "Epoch [6/30], Step [42/174], Loss: 0.0062\n",
      "Epoch [6/30], Step [48/174], Loss: 0.0084\n",
      "Epoch [6/30], Step [54/174], Loss: 0.0004\n",
      "Epoch [6/30], Step [60/174], Loss: 0.0648\n",
      "Epoch [6/30], Step [66/174], Loss: 0.2182\n",
      "Epoch [6/30], Step [72/174], Loss: 0.0024\n",
      "Epoch [6/30], Step [78/174], Loss: 0.0001\n",
      "Epoch [6/30], Step [84/174], Loss: 0.0699\n",
      "Epoch [6/30], Step [90/174], Loss: 0.0014\n",
      "Epoch [6/30], Step [96/174], Loss: 0.0133\n",
      "Epoch [6/30], Step [102/174], Loss: 0.0081\n",
      "Epoch [6/30], Step [108/174], Loss: 0.0063\n",
      "Epoch [6/30], Step [114/174], Loss: 0.0057\n",
      "Epoch [6/30], Step [120/174], Loss: 0.4122\n",
      "Epoch [6/30], Step [126/174], Loss: 0.0151\n",
      "Epoch [6/30], Step [132/174], Loss: 0.0107\n",
      "Epoch [6/30], Step [138/174], Loss: 0.0890\n",
      "Epoch [7/30], Step [6/174], Loss: 0.0000\n",
      "Epoch [7/30], Step [12/174], Loss: 0.0001\n",
      "Epoch [7/30], Step [18/174], Loss: 0.0015\n",
      "Epoch [7/30], Step [24/174], Loss: 0.0079\n",
      "Epoch [7/30], Step [30/174], Loss: 0.0033\n",
      "Epoch [7/30], Step [36/174], Loss: 0.0007\n",
      "Epoch [7/30], Step [42/174], Loss: 0.0042\n",
      "Epoch [7/30], Step [48/174], Loss: 0.0006\n",
      "Epoch [7/30], Step [54/174], Loss: 0.1749\n",
      "Epoch [7/30], Step [60/174], Loss: 0.0055\n",
      "Epoch [7/30], Step [66/174], Loss: 0.0260\n",
      "Epoch [7/30], Step [72/174], Loss: 0.0199\n",
      "Epoch [7/30], Step [78/174], Loss: 0.0010\n",
      "Epoch [7/30], Step [84/174], Loss: 0.0384\n",
      "Epoch [7/30], Step [90/174], Loss: 0.0007\n",
      "Epoch [7/30], Step [96/174], Loss: 2.5901\n",
      "Epoch [7/30], Step [102/174], Loss: 0.0166\n",
      "Epoch [7/30], Step [108/174], Loss: 0.0005\n",
      "Epoch [7/30], Step [114/174], Loss: 0.0041\n",
      "Epoch [7/30], Step [120/174], Loss: 0.0026\n",
      "Epoch [7/30], Step [126/174], Loss: 0.0971\n",
      "Epoch [7/30], Step [132/174], Loss: 0.0084\n",
      "Epoch [7/30], Step [138/174], Loss: 0.0008\n",
      "Epoch [8/30], Step [6/174], Loss: 0.0008\n",
      "Epoch [8/30], Step [12/174], Loss: 0.0028\n",
      "Epoch [8/30], Step [18/174], Loss: 0.0030\n",
      "Epoch [8/30], Step [24/174], Loss: 0.0003\n",
      "Epoch [8/30], Step [30/174], Loss: 0.0010\n",
      "Epoch [8/30], Step [36/174], Loss: 0.0022\n",
      "Epoch [8/30], Step [42/174], Loss: 0.0043\n",
      "Epoch [8/30], Step [48/174], Loss: 0.0018\n",
      "Epoch [8/30], Step [54/174], Loss: 0.0048\n",
      "Epoch [8/30], Step [60/174], Loss: 0.0016\n",
      "Epoch [8/30], Step [66/174], Loss: 0.0090\n",
      "Epoch [8/30], Step [72/174], Loss: 0.0014\n",
      "Epoch [8/30], Step [78/174], Loss: 0.0022\n",
      "Epoch [8/30], Step [84/174], Loss: 0.0004\n",
      "Epoch [8/30], Step [90/174], Loss: 0.0131\n",
      "Epoch [8/30], Step [96/174], Loss: 0.0005\n",
      "Epoch [8/30], Step [102/174], Loss: 0.0008\n",
      "Epoch [8/30], Step [108/174], Loss: 0.0014\n",
      "Epoch [8/30], Step [114/174], Loss: 0.0005\n",
      "Epoch [8/30], Step [120/174], Loss: 0.0018\n",
      "Epoch [8/30], Step [126/174], Loss: 0.0001\n",
      "Epoch [8/30], Step [132/174], Loss: 0.0171\n",
      "Epoch [8/30], Step [138/174], Loss: 0.0008\n",
      "Epoch [9/30], Step [6/174], Loss: 0.1341\n",
      "Epoch [9/30], Step [12/174], Loss: 0.0050\n",
      "Epoch [9/30], Step [18/174], Loss: 0.0006\n",
      "Epoch [9/30], Step [24/174], Loss: 0.0012\n",
      "Epoch [9/30], Step [30/174], Loss: 0.0027\n",
      "Epoch [9/30], Step [36/174], Loss: 0.0002\n",
      "Epoch [9/30], Step [42/174], Loss: 0.0014\n",
      "Epoch [9/30], Step [48/174], Loss: 0.0083\n",
      "Epoch [9/30], Step [54/174], Loss: 0.0045\n",
      "Epoch [9/30], Step [60/174], Loss: 0.0013\n",
      "Epoch [9/30], Step [66/174], Loss: 0.1118\n",
      "Epoch [9/30], Step [72/174], Loss: 0.0121\n",
      "Epoch [9/30], Step [78/174], Loss: 0.0193\n",
      "Epoch [9/30], Step [84/174], Loss: 0.0047\n",
      "Epoch [9/30], Step [90/174], Loss: 0.0001\n",
      "Epoch [9/30], Step [96/174], Loss: 0.0004\n",
      "Epoch [9/30], Step [102/174], Loss: 0.0000\n",
      "Epoch [9/30], Step [108/174], Loss: 0.1648\n",
      "Epoch [9/30], Step [114/174], Loss: 0.0012\n",
      "Epoch [9/30], Step [120/174], Loss: 0.0018\n",
      "Epoch [9/30], Step [126/174], Loss: 0.0001\n",
      "Epoch [9/30], Step [132/174], Loss: 0.0001\n",
      "Epoch [9/30], Step [138/174], Loss: 0.0002\n",
      "Epoch [10/30], Step [6/174], Loss: 0.0011\n",
      "Epoch [10/30], Step [12/174], Loss: 0.0031\n",
      "Epoch [10/30], Step [18/174], Loss: 0.0012\n",
      "Epoch [10/30], Step [24/174], Loss: 0.0023\n",
      "Epoch [10/30], Step [30/174], Loss: 0.0021\n",
      "Epoch [10/30], Step [36/174], Loss: 0.0045\n",
      "Epoch [10/30], Step [42/174], Loss: 0.0030\n",
      "Epoch [10/30], Step [48/174], Loss: 0.0002\n",
      "Epoch [10/30], Step [54/174], Loss: 0.0014\n",
      "Epoch [10/30], Step [60/174], Loss: 0.0008\n",
      "Epoch [10/30], Step [66/174], Loss: 0.0005\n",
      "Epoch [10/30], Step [72/174], Loss: 0.0011\n",
      "Epoch [10/30], Step [78/174], Loss: 0.0005\n",
      "Epoch [10/30], Step [84/174], Loss: 0.0003\n",
      "Epoch [10/30], Step [90/174], Loss: 0.0007\n",
      "Epoch [10/30], Step [96/174], Loss: 0.0001\n",
      "Epoch [10/30], Step [102/174], Loss: 0.0003\n",
      "Epoch [10/30], Step [108/174], Loss: 0.0910\n",
      "Epoch [10/30], Step [114/174], Loss: 0.0023\n",
      "Epoch [10/30], Step [120/174], Loss: 0.0030\n",
      "Epoch [10/30], Step [126/174], Loss: 0.0002\n",
      "Epoch [10/30], Step [132/174], Loss: 0.0063\n",
      "Epoch [10/30], Step [138/174], Loss: 0.0008\n",
      "Epoch [11/30], Step [6/174], Loss: 0.0011\n",
      "Epoch [11/30], Step [12/174], Loss: 0.0014\n",
      "Epoch [11/30], Step [18/174], Loss: 0.0011\n",
      "Epoch [11/30], Step [24/174], Loss: 0.0226\n",
      "Epoch [11/30], Step [30/174], Loss: 0.0002\n",
      "Epoch [11/30], Step [36/174], Loss: 0.0002\n",
      "Epoch [11/30], Step [42/174], Loss: 0.0001\n",
      "Epoch [11/30], Step [48/174], Loss: 0.0097\n",
      "Epoch [11/30], Step [54/174], Loss: 0.0003\n",
      "Epoch [11/30], Step [60/174], Loss: 0.0005\n",
      "Epoch [11/30], Step [66/174], Loss: 0.0002\n",
      "Epoch [11/30], Step [72/174], Loss: 0.0002\n",
      "Epoch [11/30], Step [78/174], Loss: 0.0002\n",
      "Epoch [11/30], Step [84/174], Loss: 0.0001\n",
      "Epoch [11/30], Step [90/174], Loss: 0.0001\n",
      "Epoch [11/30], Step [96/174], Loss: 0.0497\n",
      "Epoch [11/30], Step [102/174], Loss: 0.1311\n",
      "Epoch [11/30], Step [108/174], Loss: 0.0002\n",
      "Epoch [11/30], Step [114/174], Loss: 0.0001\n",
      "Epoch [11/30], Step [120/174], Loss: 0.0001\n",
      "Epoch [11/30], Step [126/174], Loss: 0.0008\n",
      "Epoch [11/30], Step [132/174], Loss: 0.3300\n",
      "Epoch [11/30], Step [138/174], Loss: 0.0079\n",
      "Epoch [12/30], Step [6/174], Loss: 0.0001\n",
      "Epoch [12/30], Step [12/174], Loss: 0.0004\n",
      "Epoch [12/30], Step [18/174], Loss: 0.0003\n",
      "Epoch [12/30], Step [24/174], Loss: 0.0003\n",
      "Epoch [12/30], Step [30/174], Loss: 0.0118\n",
      "Epoch [12/30], Step [36/174], Loss: 0.0750\n",
      "Epoch [12/30], Step [42/174], Loss: 0.0007\n",
      "Epoch [12/30], Step [48/174], Loss: 0.0002\n",
      "Epoch [12/30], Step [54/174], Loss: 0.0001\n",
      "Epoch [12/30], Step [60/174], Loss: 0.0002\n",
      "Epoch [12/30], Step [66/174], Loss: 0.0002\n",
      "Epoch [12/30], Step [72/174], Loss: 0.0001\n",
      "Epoch [12/30], Step [78/174], Loss: 0.0015\n",
      "Epoch [12/30], Step [84/174], Loss: 0.0038\n",
      "Epoch [12/30], Step [90/174], Loss: 0.0004\n",
      "Epoch [12/30], Step [96/174], Loss: 0.0004\n",
      "Epoch [12/30], Step [102/174], Loss: 0.0011\n",
      "Epoch [12/30], Step [108/174], Loss: 0.0029\n",
      "Epoch [12/30], Step [114/174], Loss: 0.0036\n",
      "Epoch [12/30], Step [120/174], Loss: 0.0006\n",
      "Epoch [12/30], Step [126/174], Loss: 0.0001\n",
      "Epoch [12/30], Step [132/174], Loss: 0.0006\n",
      "Epoch [12/30], Step [138/174], Loss: 0.0005\n",
      "Epoch [13/30], Step [6/174], Loss: 0.0001\n",
      "Epoch [13/30], Step [12/174], Loss: 0.0009\n",
      "Epoch [13/30], Step [18/174], Loss: 0.0035\n",
      "Epoch [13/30], Step [24/174], Loss: 0.0004\n",
      "Epoch [13/30], Step [30/174], Loss: 0.0005\n",
      "Epoch [13/30], Step [36/174], Loss: 0.0003\n",
      "Epoch [13/30], Step [42/174], Loss: 0.0007\n",
      "Epoch [13/30], Step [48/174], Loss: 0.0005\n",
      "Epoch [13/30], Step [54/174], Loss: 0.0003\n",
      "Epoch [13/30], Step [60/174], Loss: 0.0018\n",
      "Epoch [13/30], Step [66/174], Loss: 0.0001\n",
      "Epoch [13/30], Step [72/174], Loss: 0.0002\n",
      "Epoch [13/30], Step [78/174], Loss: 0.0009\n",
      "Epoch [13/30], Step [84/174], Loss: 0.0001\n",
      "Epoch [13/30], Step [90/174], Loss: 0.0065\n",
      "Epoch [13/30], Step [96/174], Loss: 0.0005\n",
      "Epoch [13/30], Step [102/174], Loss: 0.0004\n",
      "Epoch [13/30], Step [108/174], Loss: 0.0184\n",
      "Epoch [13/30], Step [114/174], Loss: 0.0011\n",
      "Epoch [13/30], Step [120/174], Loss: 0.0007\n",
      "Epoch [13/30], Step [126/174], Loss: 0.0002\n",
      "Epoch [13/30], Step [132/174], Loss: 0.0000\n",
      "Epoch [13/30], Step [138/174], Loss: 0.0001\n",
      "Epoch [14/30], Step [6/174], Loss: 0.0011\n",
      "Epoch [14/30], Step [12/174], Loss: 0.0001\n",
      "Epoch [14/30], Step [18/174], Loss: 0.0010\n",
      "Epoch [14/30], Step [24/174], Loss: 0.0015\n",
      "Epoch [14/30], Step [30/174], Loss: 0.0003\n",
      "Epoch [14/30], Step [36/174], Loss: 0.0001\n",
      "Epoch [14/30], Step [42/174], Loss: 0.0001\n",
      "Epoch [14/30], Step [48/174], Loss: 0.0733\n",
      "Epoch [14/30], Step [54/174], Loss: 0.0006\n",
      "Epoch [14/30], Step [60/174], Loss: 0.0003\n",
      "Epoch [14/30], Step [66/174], Loss: 0.0000\n",
      "Epoch [14/30], Step [72/174], Loss: 0.0015\n",
      "Epoch [14/30], Step [78/174], Loss: 0.0001\n",
      "Epoch [14/30], Step [84/174], Loss: 0.0007\n",
      "Epoch [14/30], Step [90/174], Loss: 0.0002\n",
      "Epoch [14/30], Step [96/174], Loss: 0.0001\n",
      "Epoch [14/30], Step [102/174], Loss: 0.0005\n",
      "Epoch [14/30], Step [108/174], Loss: 0.0033\n",
      "Epoch [14/30], Step [114/174], Loss: 0.0006\n",
      "Epoch [14/30], Step [120/174], Loss: 0.0021\n",
      "Epoch [14/30], Step [126/174], Loss: 0.2260\n",
      "Epoch [14/30], Step [132/174], Loss: 0.0003\n",
      "Epoch [14/30], Step [138/174], Loss: 0.0088\n",
      "Epoch [15/30], Step [6/174], Loss: 0.0378\n",
      "Epoch [15/30], Step [12/174], Loss: 0.0009\n",
      "Epoch [15/30], Step [18/174], Loss: 0.0003\n",
      "Epoch [15/30], Step [24/174], Loss: 0.0004\n",
      "Epoch [15/30], Step [30/174], Loss: 0.0001\n",
      "Epoch [15/30], Step [36/174], Loss: 0.0002\n",
      "Epoch [15/30], Step [42/174], Loss: 0.0001\n",
      "Epoch [15/30], Step [48/174], Loss: 0.0009\n",
      "Epoch [15/30], Step [54/174], Loss: 0.0016\n",
      "Epoch [15/30], Step [60/174], Loss: 0.0003\n",
      "Epoch [15/30], Step [66/174], Loss: 0.0000\n",
      "Epoch [15/30], Step [72/174], Loss: 0.0004\n",
      "Epoch [15/30], Step [78/174], Loss: 0.0009\n",
      "Epoch [15/30], Step [84/174], Loss: 0.0012\n",
      "Epoch [15/30], Step [90/174], Loss: 0.0002\n",
      "Epoch [15/30], Step [96/174], Loss: 0.0003\n",
      "Epoch [15/30], Step [102/174], Loss: 0.0010\n",
      "Epoch [15/30], Step [108/174], Loss: 0.0770\n",
      "Epoch [15/30], Step [114/174], Loss: 0.0002\n",
      "Epoch [15/30], Step [120/174], Loss: 0.0002\n",
      "Epoch [15/30], Step [126/174], Loss: 0.0001\n",
      "Epoch [15/30], Step [132/174], Loss: 0.0002\n",
      "Epoch [15/30], Step [138/174], Loss: 0.0008\n",
      "Epoch [16/30], Step [6/174], Loss: 0.0003\n",
      "Epoch [16/30], Step [12/174], Loss: 0.0002\n",
      "Epoch [16/30], Step [18/174], Loss: 0.0007\n",
      "Epoch [16/30], Step [24/174], Loss: 0.0017\n",
      "Epoch [16/30], Step [30/174], Loss: 0.0001\n",
      "Epoch [16/30], Step [36/174], Loss: 0.1211\n",
      "Epoch [16/30], Step [42/174], Loss: 0.0000\n",
      "Epoch [16/30], Step [48/174], Loss: 0.0001\n",
      "Epoch [16/30], Step [54/174], Loss: 0.0404\n",
      "Epoch [16/30], Step [60/174], Loss: 0.0053\n",
      "Epoch [16/30], Step [66/174], Loss: 0.0001\n",
      "Epoch [16/30], Step [72/174], Loss: 0.0003\n",
      "Epoch [16/30], Step [78/174], Loss: 0.0000\n",
      "Epoch [16/30], Step [84/174], Loss: 0.0034\n",
      "Epoch [16/30], Step [90/174], Loss: 0.0000\n",
      "Epoch [16/30], Step [96/174], Loss: 0.0000\n",
      "Epoch [16/30], Step [102/174], Loss: 0.0001\n",
      "Epoch [16/30], Step [108/174], Loss: 0.0105\n",
      "Epoch [16/30], Step [114/174], Loss: 0.0001\n",
      "Epoch [16/30], Step [120/174], Loss: 0.0096\n",
      "Epoch [16/30], Step [126/174], Loss: 0.0001\n",
      "Epoch [16/30], Step [132/174], Loss: 0.0007\n",
      "Epoch [16/30], Step [138/174], Loss: 0.0037\n",
      "Epoch [17/30], Step [6/174], Loss: 0.0000\n",
      "Epoch [17/30], Step [12/174], Loss: 0.0024\n",
      "Epoch [17/30], Step [18/174], Loss: 0.0018\n",
      "Epoch [17/30], Step [24/174], Loss: 0.0944\n",
      "Epoch [17/30], Step [30/174], Loss: 0.0000\n",
      "Epoch [17/30], Step [36/174], Loss: 0.0004\n",
      "Epoch [17/30], Step [42/174], Loss: 0.0019\n",
      "Epoch [17/30], Step [48/174], Loss: 0.0000\n",
      "Epoch [17/30], Step [54/174], Loss: 0.0000\n",
      "Epoch [17/30], Step [60/174], Loss: 0.0000\n",
      "Epoch [17/30], Step [66/174], Loss: 0.0026\n",
      "Epoch [17/30], Step [72/174], Loss: 0.0002\n",
      "Epoch [17/30], Step [78/174], Loss: 0.0002\n",
      "Epoch [17/30], Step [84/174], Loss: 0.0001\n",
      "Epoch [17/30], Step [90/174], Loss: 0.1117\n",
      "Epoch [17/30], Step [96/174], Loss: 0.0010\n",
      "Epoch [17/30], Step [102/174], Loss: 0.0000\n",
      "Epoch [17/30], Step [108/174], Loss: 0.0002\n",
      "Epoch [17/30], Step [114/174], Loss: 0.0001\n",
      "Epoch [17/30], Step [120/174], Loss: 0.0002\n",
      "Epoch [17/30], Step [126/174], Loss: 0.0000\n",
      "Epoch [17/30], Step [132/174], Loss: 0.0006\n",
      "Epoch [17/30], Step [138/174], Loss: 0.0000\n",
      "Epoch [18/30], Step [6/174], Loss: 0.0000\n",
      "Epoch [18/30], Step [12/174], Loss: 0.0004\n",
      "Epoch [18/30], Step [18/174], Loss: 0.0003\n",
      "Epoch [18/30], Step [24/174], Loss: 0.0010\n",
      "Epoch [18/30], Step [30/174], Loss: 0.0000\n",
      "Epoch [18/30], Step [36/174], Loss: 0.1675\n",
      "Epoch [18/30], Step [42/174], Loss: 0.0003\n",
      "Epoch [18/30], Step [48/174], Loss: 0.0000\n",
      "Epoch [18/30], Step [54/174], Loss: 0.0001\n",
      "Epoch [18/30], Step [60/174], Loss: 0.0004\n",
      "Epoch [18/30], Step [66/174], Loss: 0.0058\n",
      "Epoch [18/30], Step [72/174], Loss: 0.0002\n",
      "Epoch [18/30], Step [78/174], Loss: 0.0000\n",
      "Epoch [18/30], Step [84/174], Loss: 0.0002\n",
      "Epoch [18/30], Step [90/174], Loss: 0.0000\n",
      "Epoch [18/30], Step [96/174], Loss: 0.0000\n",
      "Epoch [18/30], Step [102/174], Loss: 0.0000\n",
      "Epoch [18/30], Step [108/174], Loss: 0.0001\n",
      "Epoch [18/30], Step [114/174], Loss: 0.0001\n",
      "Epoch [18/30], Step [120/174], Loss: 0.0001\n",
      "Epoch [18/30], Step [126/174], Loss: 0.0001\n",
      "Epoch [18/30], Step [132/174], Loss: 0.0000\n",
      "Epoch [18/30], Step [138/174], Loss: 0.0000\n",
      "Epoch [19/30], Step [6/174], Loss: 0.0004\n",
      "Epoch [19/30], Step [12/174], Loss: 0.0007\n",
      "Epoch [19/30], Step [18/174], Loss: 0.0065\n",
      "Epoch [19/30], Step [24/174], Loss: 0.0008\n",
      "Epoch [19/30], Step [30/174], Loss: 0.0012\n",
      "Epoch [19/30], Step [36/174], Loss: 0.0002\n",
      "Epoch [19/30], Step [42/174], Loss: 0.0004\n",
      "Epoch [19/30], Step [48/174], Loss: 0.0001\n",
      "Epoch [19/30], Step [54/174], Loss: 0.0002\n",
      "Epoch [19/30], Step [60/174], Loss: 0.0129\n",
      "Epoch [19/30], Step [66/174], Loss: 0.0228\n",
      "Epoch [19/30], Step [72/174], Loss: 0.0677\n",
      "Epoch [19/30], Step [78/174], Loss: 0.0001\n",
      "Epoch [19/30], Step [84/174], Loss: 0.0001\n",
      "Epoch [19/30], Step [90/174], Loss: 0.0010\n",
      "Epoch [19/30], Step [96/174], Loss: 0.0009\n",
      "Epoch [19/30], Step [102/174], Loss: 0.1190\n",
      "Epoch [19/30], Step [108/174], Loss: 0.0001\n",
      "Epoch [19/30], Step [114/174], Loss: 0.0001\n",
      "Epoch [19/30], Step [120/174], Loss: 0.0477\n",
      "Epoch [19/30], Step [126/174], Loss: 0.0001\n",
      "Epoch [19/30], Step [132/174], Loss: 0.0002\n",
      "Epoch [19/30], Step [138/174], Loss: 0.0003\n",
      "Epoch [20/30], Step [6/174], Loss: 0.0001\n",
      "Epoch [20/30], Step [12/174], Loss: 0.0002\n",
      "Epoch [20/30], Step [18/174], Loss: 0.0413\n",
      "Epoch [20/30], Step [24/174], Loss: 0.0000\n",
      "Epoch [20/30], Step [30/174], Loss: 0.0000\n",
      "Epoch [20/30], Step [36/174], Loss: 0.0001\n",
      "Epoch [20/30], Step [42/174], Loss: 0.0047\n",
      "Epoch [20/30], Step [48/174], Loss: 0.0008\n",
      "Epoch [20/30], Step [54/174], Loss: 0.0001\n",
      "Epoch [20/30], Step [60/174], Loss: 0.0188\n",
      "Epoch [20/30], Step [66/174], Loss: 0.0002\n",
      "Epoch [20/30], Step [72/174], Loss: 0.0002\n",
      "Epoch [20/30], Step [78/174], Loss: 0.0000\n",
      "Epoch [20/30], Step [84/174], Loss: 0.0006\n",
      "Epoch [20/30], Step [90/174], Loss: 0.0000\n",
      "Epoch [20/30], Step [96/174], Loss: 0.0003\n",
      "Epoch [20/30], Step [102/174], Loss: 0.0007\n",
      "Epoch [20/30], Step [108/174], Loss: 0.0001\n",
      "Epoch [20/30], Step [114/174], Loss: 0.0023\n",
      "Epoch [20/30], Step [120/174], Loss: 0.0000\n",
      "Epoch [20/30], Step [126/174], Loss: 0.0000\n",
      "Epoch [20/30], Step [132/174], Loss: 0.0009\n",
      "Epoch [20/30], Step [138/174], Loss: 0.0002\n",
      "Epoch [21/30], Step [6/174], Loss: 0.0007\n",
      "Epoch [21/30], Step [12/174], Loss: 0.0006\n",
      "Epoch [21/30], Step [18/174], Loss: 0.0000\n",
      "Epoch [21/30], Step [24/174], Loss: 0.0000\n",
      "Epoch [21/30], Step [30/174], Loss: 0.0007\n",
      "Epoch [21/30], Step [36/174], Loss: 0.0000\n",
      "Epoch [21/30], Step [42/174], Loss: 0.0000\n",
      "Epoch [21/30], Step [48/174], Loss: 0.0001\n",
      "Epoch [21/30], Step [54/174], Loss: 0.0001\n",
      "Epoch [21/30], Step [60/174], Loss: 0.0002\n",
      "Epoch [21/30], Step [66/174], Loss: 0.0002\n",
      "Epoch [21/30], Step [72/174], Loss: 0.0018\n",
      "Epoch [21/30], Step [78/174], Loss: 0.0001\n",
      "Epoch [21/30], Step [84/174], Loss: 0.0001\n",
      "Epoch [21/30], Step [90/174], Loss: 0.0000\n",
      "Epoch [21/30], Step [96/174], Loss: 0.0000\n",
      "Epoch [21/30], Step [102/174], Loss: 0.1092\n",
      "Epoch [21/30], Step [108/174], Loss: 0.0007\n",
      "Epoch [21/30], Step [114/174], Loss: 0.0002\n",
      "Epoch [21/30], Step [120/174], Loss: 0.0498\n",
      "Epoch [21/30], Step [126/174], Loss: 0.0000\n",
      "Epoch [21/30], Step [132/174], Loss: 0.0000\n",
      "Epoch [21/30], Step [138/174], Loss: 0.0001\n",
      "Epoch [22/30], Step [6/174], Loss: 0.0000\n",
      "Epoch [22/30], Step [12/174], Loss: 0.0002\n",
      "Epoch [22/30], Step [18/174], Loss: 0.0001\n",
      "Epoch [22/30], Step [24/174], Loss: 0.0001\n",
      "Epoch [22/30], Step [30/174], Loss: 0.0000\n",
      "Epoch [22/30], Step [36/174], Loss: 0.0000\n",
      "Epoch [22/30], Step [42/174], Loss: 0.0001\n",
      "Epoch [22/30], Step [48/174], Loss: 0.0025\n",
      "Epoch [22/30], Step [54/174], Loss: 0.0001\n",
      "Epoch [22/30], Step [60/174], Loss: 0.0001\n",
      "Epoch [22/30], Step [66/174], Loss: 0.0098\n",
      "Epoch [22/30], Step [72/174], Loss: 0.0001\n",
      "Epoch [22/30], Step [78/174], Loss: 0.0000\n",
      "Epoch [22/30], Step [84/174], Loss: 0.0000\n",
      "Epoch [22/30], Step [90/174], Loss: 0.0000\n",
      "Epoch [22/30], Step [96/174], Loss: 0.0001\n",
      "Epoch [22/30], Step [102/174], Loss: 0.0000\n",
      "Epoch [22/30], Step [108/174], Loss: 0.0000\n",
      "Epoch [22/30], Step [114/174], Loss: 0.0000\n",
      "Epoch [22/30], Step [120/174], Loss: 0.0001\n",
      "Epoch [22/30], Step [126/174], Loss: 0.0386\n",
      "Epoch [22/30], Step [132/174], Loss: 0.0006\n",
      "Epoch [22/30], Step [138/174], Loss: 0.0001\n",
      "Epoch [23/30], Step [6/174], Loss: 0.0001\n",
      "Epoch [23/30], Step [12/174], Loss: 0.0000\n",
      "Epoch [23/30], Step [18/174], Loss: 0.0006\n",
      "Epoch [23/30], Step [24/174], Loss: 0.0005\n",
      "Epoch [23/30], Step [30/174], Loss: 0.0001\n",
      "Epoch [23/30], Step [36/174], Loss: 0.0037\n",
      "Epoch [23/30], Step [42/174], Loss: 0.0000\n",
      "Epoch [23/30], Step [48/174], Loss: 0.0366\n",
      "Epoch [23/30], Step [54/174], Loss: 0.0000\n",
      "Epoch [23/30], Step [60/174], Loss: 0.0000\n",
      "Epoch [23/30], Step [66/174], Loss: 0.0000\n",
      "Epoch [23/30], Step [72/174], Loss: 0.0000\n",
      "Epoch [23/30], Step [78/174], Loss: 0.0004\n",
      "Epoch [23/30], Step [84/174], Loss: 0.0002\n",
      "Epoch [23/30], Step [90/174], Loss: 0.0000\n",
      "Epoch [23/30], Step [96/174], Loss: 0.0000\n",
      "Epoch [23/30], Step [102/174], Loss: 0.0000\n",
      "Epoch [23/30], Step [108/174], Loss: 0.0001\n",
      "Epoch [23/30], Step [114/174], Loss: 0.0000\n",
      "Epoch [23/30], Step [120/174], Loss: 0.0000\n",
      "Epoch [23/30], Step [126/174], Loss: 0.0000\n",
      "Epoch [23/30], Step [132/174], Loss: 0.0000\n",
      "Epoch [23/30], Step [138/174], Loss: 0.0000\n",
      "Epoch [24/30], Step [6/174], Loss: 0.0001\n",
      "Epoch [24/30], Step [12/174], Loss: 0.0001\n",
      "Epoch [24/30], Step [18/174], Loss: 0.0000\n",
      "Epoch [24/30], Step [24/174], Loss: 0.0001\n",
      "Epoch [24/30], Step [30/174], Loss: 0.0001\n",
      "Epoch [24/30], Step [36/174], Loss: 0.0002\n",
      "Epoch [24/30], Step [42/174], Loss: 0.1501\n",
      "Epoch [24/30], Step [48/174], Loss: 0.0002\n",
      "Epoch [24/30], Step [54/174], Loss: 0.0000\n",
      "Epoch [24/30], Step [60/174], Loss: 0.0005\n",
      "Epoch [24/30], Step [66/174], Loss: 0.0001\n",
      "Epoch [24/30], Step [72/174], Loss: 0.0010\n",
      "Epoch [24/30], Step [78/174], Loss: 0.0003\n",
      "Epoch [24/30], Step [84/174], Loss: 0.0011\n",
      "Epoch [24/30], Step [90/174], Loss: 0.0000\n",
      "Epoch [24/30], Step [96/174], Loss: 0.0002\n",
      "Epoch [24/30], Step [102/174], Loss: 0.0000\n",
      "Epoch [24/30], Step [108/174], Loss: 0.0000\n",
      "Epoch [24/30], Step [114/174], Loss: 0.0000\n",
      "Epoch [24/30], Step [120/174], Loss: 0.0001\n",
      "Epoch [24/30], Step [126/174], Loss: 0.0001\n",
      "Epoch [24/30], Step [132/174], Loss: 0.0004\n",
      "Epoch [24/30], Step [138/174], Loss: 0.0000\n",
      "Epoch [25/30], Step [6/174], Loss: 0.0007\n",
      "Epoch [25/30], Step [12/174], Loss: 0.0001\n",
      "Epoch [25/30], Step [18/174], Loss: 0.0000\n",
      "Epoch [25/30], Step [24/174], Loss: 0.0001\n",
      "Epoch [25/30], Step [30/174], Loss: 0.0000\n",
      "Epoch [25/30], Step [36/174], Loss: 0.0002\n",
      "Epoch [25/30], Step [42/174], Loss: 0.0002\n",
      "Epoch [25/30], Step [48/174], Loss: 0.0000\n",
      "Epoch [25/30], Step [54/174], Loss: 0.0000\n",
      "Epoch [25/30], Step [60/174], Loss: 0.0740\n",
      "Epoch [25/30], Step [66/174], Loss: 0.0003\n",
      "Epoch [25/30], Step [72/174], Loss: 0.0000\n",
      "Epoch [25/30], Step [78/174], Loss: 0.0001\n",
      "Epoch [25/30], Step [84/174], Loss: 0.0002\n",
      "Epoch [25/30], Step [90/174], Loss: 0.0001\n",
      "Epoch [25/30], Step [96/174], Loss: 0.0000\n",
      "Epoch [25/30], Step [102/174], Loss: 0.0085\n",
      "Epoch [25/30], Step [108/174], Loss: 0.0000\n",
      "Epoch [25/30], Step [114/174], Loss: 0.0000\n",
      "Epoch [25/30], Step [120/174], Loss: 0.0270\n",
      "Epoch [25/30], Step [126/174], Loss: 0.0000\n",
      "Epoch [25/30], Step [132/174], Loss: 0.0001\n",
      "Epoch [25/30], Step [138/174], Loss: 0.0001\n",
      "Epoch [26/30], Step [6/174], Loss: 0.0030\n",
      "Epoch [26/30], Step [12/174], Loss: 0.0000\n",
      "Epoch [26/30], Step [18/174], Loss: 0.0004\n",
      "Epoch [26/30], Step [24/174], Loss: 0.0001\n",
      "Epoch [26/30], Step [30/174], Loss: 0.0000\n",
      "Epoch [26/30], Step [36/174], Loss: 0.0000\n",
      "Epoch [26/30], Step [42/174], Loss: 0.0000\n",
      "Epoch [26/30], Step [48/174], Loss: 0.0001\n",
      "Epoch [26/30], Step [54/174], Loss: 0.0000\n",
      "Epoch [26/30], Step [60/174], Loss: 0.0001\n",
      "Epoch [26/30], Step [66/174], Loss: 0.0000\n",
      "Epoch [26/30], Step [72/174], Loss: 0.0000\n",
      "Epoch [26/30], Step [78/174], Loss: 0.0009\n",
      "Epoch [26/30], Step [84/174], Loss: 0.0023\n",
      "Epoch [26/30], Step [90/174], Loss: 0.0000\n",
      "Epoch [26/30], Step [96/174], Loss: 0.0000\n",
      "Epoch [26/30], Step [102/174], Loss: 0.0741\n",
      "Epoch [26/30], Step [108/174], Loss: 0.0000\n",
      "Epoch [26/30], Step [114/174], Loss: 0.0011\n",
      "Epoch [26/30], Step [120/174], Loss: 0.0000\n",
      "Epoch [26/30], Step [126/174], Loss: 0.0000\n",
      "Epoch [26/30], Step [132/174], Loss: 0.0000\n",
      "Epoch [26/30], Step [138/174], Loss: 0.0001\n",
      "Epoch [27/30], Step [6/174], Loss: 0.0000\n",
      "Epoch [27/30], Step [12/174], Loss: 0.0000\n",
      "Epoch [27/30], Step [18/174], Loss: 0.0000\n",
      "Epoch [27/30], Step [24/174], Loss: 0.0001\n",
      "Epoch [27/30], Step [30/174], Loss: 0.0203\n",
      "Epoch [27/30], Step [36/174], Loss: 0.0000\n",
      "Epoch [27/30], Step [42/174], Loss: 0.0000\n",
      "Epoch [27/30], Step [48/174], Loss: 0.0000\n",
      "Epoch [27/30], Step [54/174], Loss: 0.1328\n",
      "Epoch [27/30], Step [60/174], Loss: 0.0000\n",
      "Epoch [27/30], Step [66/174], Loss: 0.0000\n",
      "Epoch [27/30], Step [72/174], Loss: 0.0002\n",
      "Epoch [27/30], Step [78/174], Loss: 0.0000\n",
      "Epoch [27/30], Step [84/174], Loss: 0.0000\n",
      "Epoch [27/30], Step [90/174], Loss: 0.0318\n",
      "Epoch [27/30], Step [96/174], Loss: 0.0001\n",
      "Epoch [27/30], Step [102/174], Loss: 0.0000\n",
      "Epoch [27/30], Step [108/174], Loss: 0.0012\n",
      "Epoch [27/30], Step [114/174], Loss: 0.0000\n",
      "Epoch [27/30], Step [120/174], Loss: 0.0000\n",
      "Epoch [27/30], Step [126/174], Loss: 0.0000\n",
      "Epoch [27/30], Step [132/174], Loss: 0.0001\n",
      "Epoch [27/30], Step [138/174], Loss: 0.0378\n",
      "Epoch [28/30], Step [6/174], Loss: 0.0000\n",
      "Epoch [28/30], Step [12/174], Loss: 0.0002\n",
      "Epoch [28/30], Step [18/174], Loss: 0.0000\n",
      "Epoch [28/30], Step [24/174], Loss: 0.0000\n",
      "Epoch [28/30], Step [30/174], Loss: 0.0442\n",
      "Epoch [28/30], Step [36/174], Loss: 0.0014\n",
      "Epoch [28/30], Step [42/174], Loss: 0.0000\n",
      "Epoch [28/30], Step [48/174], Loss: 0.0000\n",
      "Epoch [28/30], Step [54/174], Loss: 0.0000\n",
      "Epoch [28/30], Step [60/174], Loss: 0.0788\n",
      "Epoch [28/30], Step [66/174], Loss: 0.0000\n",
      "Epoch [28/30], Step [72/174], Loss: 0.0001\n",
      "Epoch [28/30], Step [78/174], Loss: 0.0000\n",
      "Epoch [28/30], Step [84/174], Loss: 0.0001\n",
      "Epoch [28/30], Step [90/174], Loss: 0.0000\n",
      "Epoch [28/30], Step [96/174], Loss: 0.0001\n",
      "Epoch [28/30], Step [102/174], Loss: 0.0001\n",
      "Epoch [28/30], Step [108/174], Loss: 0.0004\n",
      "Epoch [28/30], Step [114/174], Loss: 0.0000\n",
      "Epoch [28/30], Step [120/174], Loss: 0.0000\n",
      "Epoch [28/30], Step [126/174], Loss: 0.0000\n",
      "Epoch [28/30], Step [132/174], Loss: 0.0001\n",
      "Epoch [28/30], Step [138/174], Loss: 0.0000\n",
      "Epoch [29/30], Step [6/174], Loss: 0.0002\n",
      "Epoch [29/30], Step [12/174], Loss: 0.0000\n",
      "Epoch [29/30], Step [18/174], Loss: 0.0012\n",
      "Epoch [29/30], Step [24/174], Loss: 0.0000\n",
      "Epoch [29/30], Step [30/174], Loss: 0.0000\n",
      "Epoch [29/30], Step [36/174], Loss: 0.0006\n",
      "Epoch [29/30], Step [42/174], Loss: 0.0001\n",
      "Epoch [29/30], Step [48/174], Loss: 0.0001\n",
      "Epoch [29/30], Step [54/174], Loss: 0.0000\n",
      "Epoch [29/30], Step [60/174], Loss: 0.0002\n",
      "Epoch [29/30], Step [66/174], Loss: 0.0000\n",
      "Epoch [29/30], Step [72/174], Loss: 0.0002\n",
      "Epoch [29/30], Step [78/174], Loss: 0.0000\n",
      "Epoch [29/30], Step [84/174], Loss: 0.0000\n",
      "Epoch [29/30], Step [90/174], Loss: 0.0000\n",
      "Epoch [29/30], Step [96/174], Loss: 0.0001\n",
      "Epoch [29/30], Step [102/174], Loss: 0.0000\n",
      "Epoch [29/30], Step [108/174], Loss: 0.0000\n",
      "Epoch [29/30], Step [114/174], Loss: 0.0000\n",
      "Epoch [29/30], Step [120/174], Loss: 0.0000\n",
      "Epoch [29/30], Step [126/174], Loss: 0.0000\n",
      "Epoch [29/30], Step [132/174], Loss: 0.0002\n",
      "Epoch [29/30], Step [138/174], Loss: 0.0000\n",
      "Epoch [30/30], Step [6/174], Loss: 0.0006\n",
      "Epoch [30/30], Step [12/174], Loss: 0.0005\n",
      "Epoch [30/30], Step [18/174], Loss: 0.0000\n",
      "Epoch [30/30], Step [24/174], Loss: 0.0000\n",
      "Epoch [30/30], Step [30/174], Loss: 0.0001\n",
      "Epoch [30/30], Step [36/174], Loss: 0.0000\n",
      "Epoch [30/30], Step [42/174], Loss: 0.0001\n",
      "Epoch [30/30], Step [48/174], Loss: 0.0000\n",
      "Epoch [30/30], Step [54/174], Loss: 0.0000\n",
      "Epoch [30/30], Step [60/174], Loss: 0.0000\n",
      "Epoch [30/30], Step [66/174], Loss: 0.0000\n",
      "Epoch [30/30], Step [72/174], Loss: 0.0907\n",
      "Epoch [30/30], Step [78/174], Loss: 0.0001\n",
      "Epoch [30/30], Step [84/174], Loss: 0.0855\n",
      "Epoch [30/30], Step [90/174], Loss: 0.0001\n",
      "Epoch [30/30], Step [96/174], Loss: 0.0008\n",
      "Epoch [30/30], Step [102/174], Loss: 0.0004\n",
      "Epoch [30/30], Step [108/174], Loss: 0.0002\n",
      "Epoch [30/30], Step [114/174], Loss: 0.0001\n",
      "Epoch [30/30], Step [120/174], Loss: 0.0000\n",
      "Epoch [30/30], Step [126/174], Loss: 0.0025\n",
      "Epoch [30/30], Step [132/174], Loss: 0.0000\n",
      "Epoch [30/30], Step [138/174], Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "\n",
    "num_batch = len(dl) - 1\n",
    "# Train the Model\n",
    "for epoch in range(num_epochs):\n",
    "    it = iter(dl)\n",
    "    # Loop over all batches\n",
    "    for i in range(num_batch):\n",
    "        batch_x,batch_y,batch_len = next(it)\n",
    "        batch_x,batch_y,batch_len = sort_batch(batch_x,batch_y,batch_len)\n",
    "        tweets = Variable(batch_x.transpose(0,1))\n",
    "        labels = Variable(batch_y)\n",
    "        lengths = batch_len.numpy()\n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()  # zero the gradient buffer\n",
    "        outputs = net(tweets, lengths)\n",
    "        loss = criterion(outputs, labels)\n",
    "        losses.append(loss.data[0])\n",
    "        loss.backward()\n",
    "        clip_grad_norm(net.parameters(), max_norm = 1)\n",
    "        for p in net.parameters():\n",
    "            p.data.add_(-learning_rate, p.grad.data)\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 6 == 0:\n",
    "            print ('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
    "                   %(epoch+1, num_epochs, i+1, len(train.clean_tweet)//batch_size, loss.data[0]))\n",
    "        if (i+1) % 12 == 0:\n",
    "            val_scores.append(get_validation_loss(dl2, net))\n",
    "            if val_scores[-1] == max(val_scores):\n",
    "                best_net = net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11f3c3518>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1376dc320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses) #trained at lr of 0.001 for 30 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11e9eb6d8>]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRANC4k4QBNGAkLgTBEE0IP8fGiTe04cBsqcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e9845c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(val_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70175438596491224"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(val_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "pred_labels = []\n",
    "#get training predictions\n",
    "it = iter(dl2)\n",
    "num_batch = len(dl2) - 1\n",
    "# Loop over all batches\n",
    "for i in range(num_batch):\n",
    "    batch_x,batch_y,batch_len = next(it)\n",
    "    batch_x,batch_y,batch_len = sort_batch(batch_x,batch_y,batch_len)\n",
    "    tweets = Variable(batch_x.transpose(0,1))\n",
    "    labels = Variable(batch_y)\n",
    "    lengths = batch_len.numpy()\n",
    "    outputs = best_net(tweets, lengths)\n",
    "    _, pred = torch.max(outputs.data, 1)\n",
    "    predictions.extend(list(pred.numpy()))\n",
    "    pred_labels.extend(list(labels.data.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1062\n",
       "1      26\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(predictions).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1046,   12],\n",
       "       [  16,   14]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(pred_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = 'best_rnn.sav'\n",
    "pickle.dump(best_net, open(filename, \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
