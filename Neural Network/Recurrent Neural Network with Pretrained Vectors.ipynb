{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Import libraries<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as autograd\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils import clip_grad_norm\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import model_selection\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#drew inspiration from\n",
    "#https://github.com/dmesquita/understanding_pytorch_nn and\n",
    "#https://github.com/msahamed/yelp_comments_classification_nlp/blob/master/word_embeddings.ipynb\n",
    "#https://github.com/nyu-mll/DS-GA-1011-Fall2017/blob/master/week%20eight/Week%20Eight%20Solutions.ipynb\n",
    "#https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html\n",
    "#https://github.com/claravania/lstm-pytorch/blob/master/model.py\n",
    "#https://medium.com/@sonicboom8/sentiment-analysis-with-variable-length-sequences-in-pytorch-6241635ae130\n",
    "#https://github.com/hpanwar08/sentence-classification-pytorch/blob/master/Sentiment%20analysis%20pytorch.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://medium.com/@martinpella/how-to-use-pre-trained-word-embeddings-in-pytorch-71ca59249f76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://modelzoo.co/model/pytorch-nlp\n",
    "#http://anie.me/On-Torchtext/\n",
    "#https://readthedocs.org/projects/pytorchnlp/downloads/pdf/latest/\n",
    "#https://github.com/A-Jacobson/CNN_Sentence_Classification/blob/master/WordVectors.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b> Data Processing<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../train_nn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = ['CAPS', 'Obscenity', 'Threat', 'hatespeech', 'namecalling', 'negprejudice', 'noneng', 'porn', 'stereotypes']\n",
    "\n",
    "for label in labels:\n",
    "    cols = [label + str(x) for x in range(1,8)]\n",
    "    train[label + '_num_yes'] = train[cols].sum(axis = 1)\n",
    "    train[label] = pd.Series(train[label + '_num_yes'] >= 2).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5465\n",
       "1     134\n",
       "Name: hatespeech, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['hatespeech'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02539492101579684"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "127/(127 + 4874) #previous ratio, before adding new tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.023932845150919806"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "134/(5465 + 134)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = train.loc[train['clean_tweet'].isnull() == False,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_sub, validation = model_selection.train_test_split(train, test_size = 0.2, random_state = 123)\n",
    "\n",
    "train_sub.reset_index(inplace = True, drop = True)\n",
    "\n",
    "validation.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word2index = {}\n",
    "index2word = {}\n",
    "\n",
    "word2index['PAD'] = 0\n",
    "index2word[0] = 'PAD'\n",
    "\n",
    "word2index['UNK'] = 1\n",
    "index2word[1] = 'UNK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab = Counter()\n",
    "\n",
    "for text in train_sub.clean_tweet:\n",
    "    for word in text.split(' '):\n",
    "        vocab[word.lower()]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10002"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "vocab = dict(vocab.most_common(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_words = vocab_size + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,word in enumerate(vocab):\n",
    "    word2index[word.lower()] = i+2\n",
    "    index2word[i+2] = word.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_glove(path):\n",
    "    \"\"\"\n",
    "    creates a dictionary mapping words to vectors from a file in glove format.\n",
    "    \"\"\"\n",
    "    with open(path) as f:\n",
    "        glove = {}\n",
    "        for line in f.readlines():\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.array(values[1:], dtype='float32')\n",
    "            glove[word] = vector\n",
    "        return glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 13s, sys: 17.9 s, total: 1min 31s\n",
      "Wall time: 1min 41s\n"
     ]
    }
   ],
   "source": [
    "glove_path = \"/Users/carolineroper/Desktop/Capstone Project/Neural Network/glove.twitter.27B/glove.twitter.27B.200d.txt\"\n",
    "%time glove = load_glove(glove_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2403"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2index['hello']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.46830010e-01,  -1.96119994e-01,  -3.49229991e-01,\n",
       "        -2.81580001e-01,  -7.56269991e-01,  -4.00349982e-02,\n",
       "         5.34219980e-01,   1.53270003e-03,  -2.19630003e-01,\n",
       "        -5.67080021e-01,  -7.51120001e-02,   3.90740007e-01,\n",
       "         1.92010000e-01,   4.80460003e-02,  -1.68009996e-01,\n",
       "        -1.91400006e-01,   1.21619999e-01,  -2.25130007e-01,\n",
       "         2.22759992e-02,  -2.76320010e-01,   1.07210003e-01,\n",
       "        -5.81910014e-02,  -1.76540002e-01,  -2.06199996e-02,\n",
       "        -3.97679992e-02,   1.26190007e-01,   1.89270005e-01,\n",
       "         1.70169994e-01,  -2.34529991e-02,  -4.23489988e-01,\n",
       "        -4.26400006e-02,  -2.81010002e-01,  -3.24609995e-01,\n",
       "         3.08699995e-01,   9.45290029e-02,   1.35590002e-01,\n",
       "        -5.02489984e-01,   3.00720006e-01,   1.58050001e-01,\n",
       "         5.50790012e-01,  -3.70050013e-01,  -2.17209995e-01,\n",
       "        -7.11619973e-01,   4.29749995e-01,  -1.24509996e-02,\n",
       "        -2.42750004e-01,  -6.29020035e-02,   4.37549986e-02,\n",
       "         5.90980016e-02,   2.15529993e-01,   3.40479985e-02,\n",
       "        -1.57350004e-01,  -4.47309986e-02,  -1.27189994e-01,\n",
       "         3.33469987e-01,   2.23859996e-01,   3.97159994e-01,\n",
       "         8.43819976e-02,  -4.70569991e-02,  -1.49430007e-01,\n",
       "         2.01399997e-02,  -5.13449982e-02,  -1.77820008e-02,\n",
       "        -4.85579997e-01,  -4.40770015e-02,   3.86900008e-01,\n",
       "        -3.51390004e-01,   8.89970005e-01,   6.69700027e-01,\n",
       "        -4.40119989e-02,   4.26730007e-01,  -1.96710005e-01,\n",
       "        -5.85529990e-02,   1.02069996e-01,  -3.70260000e-01,\n",
       "         2.96330005e-01,   4.60469991e-01,   3.56990010e-01,\n",
       "        -2.15639994e-01,   5.06760001e-01,   4.05409992e-01,\n",
       "         4.15380001e-01,   5.34810007e-01,   2.20500007e-01,\n",
       "         1.55780002e-01,  -5.70949972e-01,  -5.50019979e-01,\n",
       "         5.38770020e-01,   3.34190011e-01,  -3.31999987e-01,\n",
       "        -2.02110007e-01,  -3.72189999e-01,  -1.10299997e-01,\n",
       "         8.95290017e-01,  -2.10519999e-01,  -1.30119994e-01,\n",
       "        -2.42339998e-01,  -3.03470008e-02,   2.25569993e-01,\n",
       "         2.46030003e-01,  -4.70919997e-01,   6.57190010e-02,\n",
       "        -7.65509978e-02,  -2.37489998e-01,  -2.78149992e-01,\n",
       "         2.20500007e-01,   2.05669999e-01,   5.34839988e-01,\n",
       "        -1.17660001e-01,   8.30340013e-02,  -5.71230017e-02,\n",
       "        -1.76139995e-01,  -4.97150004e-01,   1.28289998e-01,\n",
       "        -1.52419999e-01,  -7.73880005e-01,  -7.81400025e-01,\n",
       "        -4.31719989e-01,   6.76060021e-01,   2.92690009e-01,\n",
       "         1.96710005e-01,   5.05530000e-01,  -1.89209998e-01,\n",
       "        -1.88999996e-01,   7.10150003e-02,  -3.93469989e-01,\n",
       "         7.74319982e-03,  -7.63300002e-01,  -4.18280005e-01,\n",
       "         4.38820004e-01,   8.99469972e-01,  -2.40669996e-01,\n",
       "         1.38630003e-01,   2.53309995e-01,  -1.08690001e-02,\n",
       "        -1.01340003e-01,  -3.43650013e-01,   7.19609976e-01,\n",
       "         1.68559998e-01,   9.60540026e-02,  -1.72350004e-01,\n",
       "        -5.26499987e-01,   1.96500003e-01,  -9.11900029e-02,\n",
       "        -1.76569998e-01,   1.48699999e-01,  -2.31759995e-02,\n",
       "         9.75740016e-01,   7.65380025e-01,  -2.87939996e-01,\n",
       "         3.57760012e-01,   1.43210003e-02,  -3.83780003e+00,\n",
       "        -1.78489998e-01,  -4.89069998e-01,   4.22560014e-02,\n",
       "        -6.94400012e-01,  -3.79290015e-01,  -4.33890000e-02,\n",
       "        -1.56560004e-01,   7.40360022e-01,  -3.70370001e-01,\n",
       "        -3.35020006e-01,  -5.39570004e-02,  -1.74779996e-01,\n",
       "        -6.73770010e-02,   4.20540005e-01,  -5.86589985e-02,\n",
       "        -2.42180005e-01,  -8.40779990e-02,  -3.03719997e-01,\n",
       "         1.35490000e-01,   2.70880014e-01,   4.79490012e-01,\n",
       "         3.33929993e-02,   7.09469974e-01,  -2.88120002e-01,\n",
       "         2.96270013e-01,  -4.10059988e-01,  -2.76690006e-01,\n",
       "        -1.70460001e-01,   3.84479985e-02,  -1.07420003e-02,\n",
       "         3.82499993e-01,   8.68320018e-02,  -1.78350005e-02,\n",
       "        -7.03899980e-01,   1.96139999e-02,   8.27580038e-03,\n",
       "         3.20300013e-01,   3.50510003e-03,   3.31299990e-01,\n",
       "         1.53259993e-01,  -2.20070004e-01,  -4.57010001e-01,\n",
       "        -1.77190006e-02,  -6.19970024e-01,  -5.20730019e-01,\n",
       "         8.22940022e-02,  -5.44780016e-01], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove['hello']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10002"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matrix_len = total_words\n",
    "weights_matrix = np.zeros((matrix_len, 200))\n",
    "words_found = 0\n",
    "\n",
    "for i, word in index2word.items():\n",
    "    try: \n",
    "        weights_matrix[i] = glove[index2word[i]]\n",
    "        words_found += 1\n",
    "    except KeyError:\n",
    "        weights_matrix[i] = np.random.rand(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7858"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_found/len(vocab) #79% of words were found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights_matrix[0, ] = np.zeros(200) #initialize pad embedding to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.46830010e-01,  -1.96119994e-01,  -3.49229991e-01,\n",
       "        -2.81580001e-01,  -7.56269991e-01,  -4.00349982e-02,\n",
       "         5.34219980e-01,   1.53270003e-03,  -2.19630003e-01,\n",
       "        -5.67080021e-01,  -7.51120001e-02,   3.90740007e-01,\n",
       "         1.92010000e-01,   4.80460003e-02,  -1.68009996e-01,\n",
       "        -1.91400006e-01,   1.21619999e-01,  -2.25130007e-01,\n",
       "         2.22759992e-02,  -2.76320010e-01,   1.07210003e-01,\n",
       "        -5.81910014e-02,  -1.76540002e-01,  -2.06199996e-02,\n",
       "        -3.97679992e-02,   1.26190007e-01,   1.89270005e-01,\n",
       "         1.70169994e-01,  -2.34529991e-02,  -4.23489988e-01,\n",
       "        -4.26400006e-02,  -2.81010002e-01,  -3.24609995e-01,\n",
       "         3.08699995e-01,   9.45290029e-02,   1.35590002e-01,\n",
       "        -5.02489984e-01,   3.00720006e-01,   1.58050001e-01,\n",
       "         5.50790012e-01,  -3.70050013e-01,  -2.17209995e-01,\n",
       "        -7.11619973e-01,   4.29749995e-01,  -1.24509996e-02,\n",
       "        -2.42750004e-01,  -6.29020035e-02,   4.37549986e-02,\n",
       "         5.90980016e-02,   2.15529993e-01,   3.40479985e-02,\n",
       "        -1.57350004e-01,  -4.47309986e-02,  -1.27189994e-01,\n",
       "         3.33469987e-01,   2.23859996e-01,   3.97159994e-01,\n",
       "         8.43819976e-02,  -4.70569991e-02,  -1.49430007e-01,\n",
       "         2.01399997e-02,  -5.13449982e-02,  -1.77820008e-02,\n",
       "        -4.85579997e-01,  -4.40770015e-02,   3.86900008e-01,\n",
       "        -3.51390004e-01,   8.89970005e-01,   6.69700027e-01,\n",
       "        -4.40119989e-02,   4.26730007e-01,  -1.96710005e-01,\n",
       "        -5.85529990e-02,   1.02069996e-01,  -3.70260000e-01,\n",
       "         2.96330005e-01,   4.60469991e-01,   3.56990010e-01,\n",
       "        -2.15639994e-01,   5.06760001e-01,   4.05409992e-01,\n",
       "         4.15380001e-01,   5.34810007e-01,   2.20500007e-01,\n",
       "         1.55780002e-01,  -5.70949972e-01,  -5.50019979e-01,\n",
       "         5.38770020e-01,   3.34190011e-01,  -3.31999987e-01,\n",
       "        -2.02110007e-01,  -3.72189999e-01,  -1.10299997e-01,\n",
       "         8.95290017e-01,  -2.10519999e-01,  -1.30119994e-01,\n",
       "        -2.42339998e-01,  -3.03470008e-02,   2.25569993e-01,\n",
       "         2.46030003e-01,  -4.70919997e-01,   6.57190010e-02,\n",
       "        -7.65509978e-02,  -2.37489998e-01,  -2.78149992e-01,\n",
       "         2.20500007e-01,   2.05669999e-01,   5.34839988e-01,\n",
       "        -1.17660001e-01,   8.30340013e-02,  -5.71230017e-02,\n",
       "        -1.76139995e-01,  -4.97150004e-01,   1.28289998e-01,\n",
       "        -1.52419999e-01,  -7.73880005e-01,  -7.81400025e-01,\n",
       "        -4.31719989e-01,   6.76060021e-01,   2.92690009e-01,\n",
       "         1.96710005e-01,   5.05530000e-01,  -1.89209998e-01,\n",
       "        -1.88999996e-01,   7.10150003e-02,  -3.93469989e-01,\n",
       "         7.74319982e-03,  -7.63300002e-01,  -4.18280005e-01,\n",
       "         4.38820004e-01,   8.99469972e-01,  -2.40669996e-01,\n",
       "         1.38630003e-01,   2.53309995e-01,  -1.08690001e-02,\n",
       "        -1.01340003e-01,  -3.43650013e-01,   7.19609976e-01,\n",
       "         1.68559998e-01,   9.60540026e-02,  -1.72350004e-01,\n",
       "        -5.26499987e-01,   1.96500003e-01,  -9.11900029e-02,\n",
       "        -1.76569998e-01,   1.48699999e-01,  -2.31759995e-02,\n",
       "         9.75740016e-01,   7.65380025e-01,  -2.87939996e-01,\n",
       "         3.57760012e-01,   1.43210003e-02,  -3.83780003e+00,\n",
       "        -1.78489998e-01,  -4.89069998e-01,   4.22560014e-02,\n",
       "        -6.94400012e-01,  -3.79290015e-01,  -4.33890000e-02,\n",
       "        -1.56560004e-01,   7.40360022e-01,  -3.70370001e-01,\n",
       "        -3.35020006e-01,  -5.39570004e-02,  -1.74779996e-01,\n",
       "        -6.73770010e-02,   4.20540005e-01,  -5.86589985e-02,\n",
       "        -2.42180005e-01,  -8.40779990e-02,  -3.03719997e-01,\n",
       "         1.35490000e-01,   2.70880014e-01,   4.79490012e-01,\n",
       "         3.33929993e-02,   7.09469974e-01,  -2.88120002e-01,\n",
       "         2.96270013e-01,  -4.10059988e-01,  -2.76690006e-01,\n",
       "        -1.70460001e-01,   3.84479985e-02,  -1.07420003e-02,\n",
       "         3.82499993e-01,   8.68320018e-02,  -1.78350005e-02,\n",
       "        -7.03899980e-01,   1.96139999e-02,   8.27580038e-03,\n",
       "         3.20300013e-01,   3.50510003e-03,   3.31299990e-01,\n",
       "         1.53259993e-01,  -2.20070004e-01,  -4.57010001e-01,\n",
       "        -1.77190006e-02,  -6.19970024e-01,  -5.20730019e-01,\n",
       "         8.22940022e-02,  -5.44780016e-01])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_matrix[2403, ] #confirmed that at index \"hello\" we're seeing the glove vector for \"hello\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10002, 200)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pad_data(s, length):\n",
    "    padded = np.zeros((length,), dtype = np.int64)\n",
    "    if len(s) > length: \n",
    "        padded = s[:length]\n",
    "    else:\n",
    "        padded[:len(s)] = s\n",
    "    return np.array(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_index(x):\n",
    "    try:\n",
    "        return word2index[x]\n",
    "    except KeyError:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prep_data(data):\n",
    "    data['seq_len'] = [len(x.split(' ')) for x in data['clean_tweet']]\n",
    "    data['numeric'] = [[get_index(y) for y in x.split(' ')] for x in data['clean_tweet']]\n",
    "    data['padded_tweet'] = [pad_data(x, 25) for x in data.numeric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "prep_data(train_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "prep_data(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4976,   40,   98, 4977,  240, 1052,   31,   16,  943,   46,   57,\n",
       "         54,  364,   38, 3214,  204,    6, 1333,   60,   31, 3215,  943,\n",
       "          0,    0,    0])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sub.padded_tweet[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1226fd748>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFLVJREFUeJzt3X+s3fV93/Hna6YlJF74Mbory7ZmNlmpDG7ScMXIUlWX\nsBU3iWL+Yo7oYjYUawpr6GQpsltp0f6wxLTRNVVGJCuwEBHF80g6rBCSUjdX0aQRBvlRYwjFLSbY\nM7hdEtjNIppL3/vjfAmnN2b3+pzje87x5/mQrs73+/l+Pt/v58055nW/3+8556aqkCS16W+NewKS\npPExBCSpYYaAJDXMEJCkhhkCktQwQ0CSGmYISFLDDAFJapghIEkNu2DcE1jO5ZdfXps2bVq2349+\n9CPe8pa3nPsJnUPWMBmsYTKcDzXA+Op4/PHH/7KqfmG5fhMfAps2beKxxx5btt/8/Dxzc3PnfkLn\nkDVMBmuYDOdDDTC+OpI8t5J+Xg6SpIYZApLUMENAkhpmCEhSwwwBSWqYISBJDVs2BJLck+R0kifO\nsG13kkpyeV/b3iTHkjyd5Ia+9quTHOm2/X6SjK4MSdIgVnIm8Blg29LGJBuBXwO+19e2BdgBXNmN\nuSvJmm7zp4APA5u7n5/ZpyRpdS0bAlX1deD7Z9j0H4GPAf1/pHg7cKCqXqmqZ4FjwDVJ1gFvrapH\nqvdHjT8L3Dj07CVJQxnoE8NJtgMnq+o7S67qrAce6Vs/0bX9pFte2v5G+98F7AKYmZlhfn5+2Tkt\nLCysqN8kG0UNR06+NJrJnKWt6y8GfB4mhTVMjkmv46xDIMmbgd+mdynonKiq/cB+gNnZ2VrJR67P\nh4+Yj6KGW/Y8OJrJnKXjN88BPg+Twhomx6TXMciZwD8ArgBeOwvYAHwzyTXASWBjX98NXdvJbnlp\nuyRpjM76LaJVdaSq/m5VbaqqTfQu7byzql4ADgE7klyY5Ap6N4AfrapTwMtJru3eFfQh4IHRlSFJ\nGsRK3iL6eeB/AG9LciLJrW/Ut6qOAgeBJ4GvALdV1avd5o8An6Z3s/jPgIeGnLskaUjLXg6qqg8u\ns33TkvV9wL4z9HsMuOos5ydJOof8xLAkNcwQkKSGGQKS1DBDQJIaZghIUsMMAUlqmCEgSQ0zBCSp\nYYaAJDVsoK+Slpba1H176e6ti6v+TabH73jfqh5POp94JiBJDTMEJKlhhoAkNcwQkKSGGQKS1DBD\nQJIaZghIUsMMAUlqmCEgSQ0zBCSpYcuGQJJ7kpxO8kRf279P8t0kf5LkD5Jc0rdtb5JjSZ5OckNf\n+9VJjnTbfj9JRl+OJOlsrORM4DPAtiVtDwNXVdUvAX8K7AVIsgXYAVzZjbkryZpuzKeADwObu5+l\n+5QkrbJlQ6Cqvg58f0nbH1bVYrf6CLChW94OHKiqV6rqWeAYcE2SdcBbq+qRqirgs8CNoypCkjSY\nUdwT+BfAQ93yeuD5vm0nurb13fLSdknSGA31VdJJfgdYBD43mun8dL+7gF0AMzMzzM/PLztmYWFh\nRf0m2Shq2L11cflO59DMRas/h1E/776WJsP5UANMfh0Dh0CSW4D3A9d3l3gATgIb+7pt6NpO8vol\no/72M6qq/cB+gNnZ2Zqbm1t2PvPz86yk3yQbRQ2r/V3+S+3eusidR1b3z1Qcv3lupPvztTQZzoca\nYPLrGOhyUJJtwMeAD1TV/+3bdAjYkeTCJFfQuwH8aFWdAl5Ocm33rqAPAQ8MOXdJ0pCW/ZUtyeeB\nOeDyJCeAj9N7N9CFwMPdOz0fqap/WVVHkxwEnqR3mei2qnq129VH6L3T6CJ69xAeQpI0VsuGQFV9\n8AzNd/9/+u8D9p2h/THgqrOanSTpnPITw5LUMENAkhpmCEhSwwwBSWqYISBJDTMEJKlhhoAkNcwQ\nkKSGGQKS1DBDQJIaZghIUsMMAUlqmCEgSQ0zBCSpYYaAJDXMEJCkhhkCktQwQ0CSGmYISFLDDAFJ\napghIEkNu2C5DknuAd4PnK6qq7q2y4D/AmwCjgM3VdUPum17gVuBV4GPVtVXu/argc8AFwFfBm6v\nqhptOZNh054HBxq3e+sitww4VpIGsZIzgc8A25a07QEOV9Vm4HC3TpItwA7gym7MXUnWdGM+BXwY\n2Nz9LN2nJGmVLRsCVfV14PtLmrcD93bL9wI39rUfqKpXqupZ4BhwTZJ1wFur6pHut//P9o2RJI3J\nspeD3sBMVZ3qll8AZrrl9cAjff1OdG0/6ZaXtp9Rkl3ALoCZmRnm5+eXndDCwsKK+q2G3VsXBxo3\nc9HgYyfFOGoY9fM+Sa+lQVnD5Jj0OgYNgZ+qqkoy0mv7VbUf2A8wOztbc3Nzy46Zn59nJf1Ww6DX\n9XdvXeTOI0M/JWM1jhqO3zw30v1N0mtpUNYwOSa9jkHfHfRid4mH7vF0134S2NjXb0PXdrJbXtou\nSRqjQUPgELCzW94JPNDXviPJhUmuoHcD+NHu0tHLSa5NEuBDfWMkSWOykreIfh6YAy5PcgL4OHAH\ncDDJrcBzwE0AVXU0yUHgSWARuK2qXu129RFef4voQ92PJGmMlg2BqvrgG2y6/g367wP2naH9MeCq\ns5qdJOmc8hPDktQwQ0CSGmYISFLDDAFJapghIEkNMwQkqWGGgCQ1zBCQpIYZApLUMENAkhpmCEhS\nwwwBSWqYISBJDTMEJKlhhoAkNcwQkKSGGQKS1DBDQJIaZghIUsMMAUlq2FAhkORfJzma5Ikkn0/y\npiSXJXk4yTPd46V9/fcmOZbk6SQ3DD99SdIwBg6BJOuBjwKzVXUVsAbYAewBDlfVZuBwt06SLd32\nK4FtwF1J1gw3fUnSMIa9HHQBcFGSC4A3A/8L2A7c222/F7ixW94OHKiqV6rqWeAYcM2Qx5ckDWHg\nEKiqk8B/AL4HnAJeqqo/BGaq6lTX7QVgplteDzzft4sTXZskaUxSVYMN7F3r/wLwT4EfAv8VuB/4\nZFVd0tfvB1V1aZJPAo9U1X1d+93AQ1V1/xn2vQvYBTAzM3P1gQMHlp3PwsICa9euHaiWUTty8qWB\nxs1cBC/+eMSTWWXjqGHr+otHur9Jei0Nyhomx7jquO666x6vqtnl+l0wxDH+MfBsVf0FQJIvAv8I\neDHJuqo6lWQdcLrrfxLY2Dd+Q9f2M6pqP7AfYHZ2tubm5padzPz8PCvptxpu2fPgQON2b13kziPD\nPCXjN44ajt88N9L9TdJraVDWMDkmvY5h7gl8D7g2yZuTBLgeeAo4BOzs+uwEHuiWDwE7klyY5Apg\nM/DoEMeXJA1p4F/ZquobSe4HvgksAt+i99v7WuBgkluB54Cbuv5HkxwEnuz631ZVrw45f0nSEIY6\nb6+qjwMfX9L8Cr2zgjP13wfsG+aYkqTR8RPDktQwQ0CSGmYISFLDDAFJapghIEkNMwQkqWGGgCQ1\nzBCQpIYZApLUMENAkhpmCEhSwwwBSWqYISBJDTMEJKlhhoAkNcwQkKSGGQKS1DBDQJIaZghIUsMM\nAUlqmCEgSQ0bKgSSXJLk/iTfTfJUkncluSzJw0me6R4v7eu/N8mxJE8nuWH46UuShjHsmcAngK9U\n1S8CbweeAvYAh6tqM3C4WyfJFmAHcCWwDbgryZohjy9JGsLAIZDkYuBXgbsBquqvquqHwHbg3q7b\nvcCN3fJ24EBVvVJVzwLHgGsGPb4kaXipqsEGJu8A9gNP0jsLeBy4HThZVZd0fQL8oKouSfJJ4JGq\nuq/bdjfwUFXdf4Z97wJ2AczMzFx94MCBZeezsLDA2rVrB6pl1I6cfGmgcTMXwYs/HvFkVtk4ati6\n/uKR7m+SXkuDsobJMa46rrvuuserana5fhcMcYwLgHcCv1lV30jyCbpLP6+pqkpy1ilTVfvpBQyz\ns7M1Nze37Jj5+XlW0m813LLnwYHG7d66yJ1HhnlKxm8cNRy/eW6k+5uk19KgrGFyTHodw9wTOAGc\nqKpvdOv30wuFF5OsA+geT3fbTwIb+8Zv6NokSWMycAhU1QvA80ne1jVdT+/S0CFgZ9e2E3igWz4E\n7EhyYZIrgM3Ao4MeX5I0vGHP238T+FySnwf+HPjn9ILlYJJbgeeAmwCq6miSg/SCYhG4rapeHfL4\nkqQhDBUCVfVt4Ew3Hq5/g/77gH3DHFOSNDp+YliSGmYISFLDDAFJapghIEkNMwQkqWGGgCQ1zBCQ\npIYZApLUMENAkhpmCEhSwwwBSWqYISBJDTMEJKlhhoAkNcwQkKSGGQKS1DBDQJIaZghIUsMMAUlq\nmCEgSQ0bOgSSrEnyrSRf6tYvS/Jwkme6x0v7+u5NcizJ00luGPbYkqThjOJM4Hbgqb71PcDhqtoM\nHO7WSbIF2AFcCWwD7kqyZgTHlyQNaKgQSLIBeB/w6b7m7cC93fK9wI197Qeq6pWqehY4BlwzzPEl\nScMZ9kzg94CPAX/d1zZTVae65ReAmW55PfB8X78TXZskaUwuGHRgkvcDp6vq8SRzZ+pTVZWkBtj3\nLmAXwMzMDPPz88uOWVhYWFG/1bB76+JA42YuGnzspBhHDaN+3ifptTQoa5gck17HwCEAvBv4QJL3\nAm8C3prkPuDFJOuq6lSSdcDprv9JYGPf+A1d28+oqv3AfoDZ2dmam5tbdjLz8/Ms7bdpz4NnU88I\nDfafdffWRe48MsxTMn7jqOH4zXMj3d+ZXkvTxhomx6TXMfDloKraW1UbqmoTvRu+f1xVvwEcAnZ2\n3XYCD3TLh4AdSS5McgWwGXh04JlLkoZ2Ln5luwM4mORW4DngJoCqOprkIPAksAjcVlWvnoPjS5JW\naCQhUFXzwHy3/L+B69+g3z5g3yiOKUkanp8YlqSGGQKS1DBDQJIaZghIUsMMAUlqmCEgSQ0zBCSp\nYYaAJDVsur+oRmL03xG1e+sit6xgn8fveN9IjyuNg2cCktQwQ0CSGmYISFLDDAFJapghIEkNMwQk\nqWGGgCQ1zBCQpIYZApLUMENAkhpmCEhSwwwBSWrYwCGQZGOSryV5MsnRJLd37ZcleTjJM93jpX1j\n9iY5luTpJDeMogBJ0uCGORNYBHZX1RbgWuC2JFuAPcDhqtoMHO7W6bbtAK4EtgF3JVkzzOQlScMZ\nOASq6lRVfbNb/j/AU8B6YDtwb9ftXuDGbnk7cKCqXqmqZ4FjwDWDHl+SNLxU1fA7STYBXweuAr5X\nVZd07QF+UFWXJPkk8EhV3ddtuxt4qKruP8P+dgG7AGZmZq4+cODAsnNYWFhg7dq1f6PtyMmXhqhq\n9c1cBC/+eNyzGE5LNWxdf/G5n8yAzvTvYdqcDzXA+Oq47rrrHq+q2eX6Df1HZZKsBb4A/FZVvdz7\n/35PVVWSs06ZqtoP7AeYnZ2tubm5ZcfMz8+ztN9K/jDIJNm9dZE7j0z33/lpqYbjN8+d+8kM6Ez/\nHqbN+VADTH4dQ707KMnP0QuAz1XVF7vmF5Os67avA0537SeBjX3DN3RtkqQxGebdQQHuBp6qqt/t\n23QI2Nkt7wQe6GvfkeTCJFcAm4FHBz2+JGl4w5y3vxv4Z8CRJN/u2n4buAM4mORW4DngJoCqOprk\nIPAkvXcW3VZVrw5xfEnSkAYOgar670DeYPP1bzBmH7Bv0GNKkkbLTwxLUsMMAUlqmCEgSQ0zBCSp\nYYaAJDXMEJCkhhkCktQwQ0CSGmYISFLDDAFJapghIEkNMwQkqWGGgCQ1zBCQpIYZApLUMENAkhpm\nCEhSwwwBSWqYISBJDTMEJKlhA/+h+UEl2QZ8AlgDfLqq7ljtOUijsGnPg2M79vE73je2Y+v8sqpn\nAknWAP8J+HVgC/DBJFtWcw6SpNet9uWga4BjVfXnVfVXwAFg+yrPQZLUWe0QWA8837d+omuTJI3B\nqt8TWIkku4Bd3epCkqdXMOxy4C/P3azOvY9aw0SYhhry75btMvE1rMD5UAOMr46/t5JOqx0CJ4GN\nfesbura/oar2A/vPZsdJHquq2eGmN17WMBmsYTKcDzXA5Nex2peD/iewOckVSX4e2AEcWuU5SJI6\nq3omUFWLSf4V8FV6bxG9p6qOruYcJEmvW/V7AlX1ZeDL52DXZ3X5aEJZw2SwhslwPtQAE15Hqmrc\nc5AkjYlfGyFJDZv6EEiyLcnTSY4l2TPu+axUknuSnE7yRF/bZUkeTvJM93jpOOe4nCQbk3wtyZNJ\njia5vWufmjqSvCnJo0m+09Xwb7v2qakBep/GT/KtJF/q1qdq/gBJjic5kuTbSR7r2qaqjiSXJLk/\nyXeTPJXkXZNew1SHwJR/DcVngG1L2vYAh6tqM3C4W59ki8DuqtoCXAvc1v33n6Y6XgHeU1VvB94B\nbEtyLdNVA8DtwFN969M2/9dcV1Xv6HtL5bTV8QngK1X1i8Db6T0nk11DVU3tD/Au4Kt963uBveOe\n11nMfxPwRN/608C6bnkd8PS453iW9TwA/JNprQN4M/BN4B9OUw30Pm9zGHgP8KVpfS0Bx4HLl7RN\nTR3AxcCzdPdap6WGqT4T4Pz7GoqZqjrVLb8AzIxzMmcjySbgl4FvMGV1dJdSvg2cBh6uqmmr4feA\njwF/3dc2TfN/TQF/lOTx7lsDYLrquAL4C+A/d5fmPp3kLUx4DdMeAuet6v3aMBVv3UqyFvgC8FtV\n9XL/tmmoo6perap30PuN+pokVy3ZPrE1JHk/cLqqHn+jPpM8/yV+pXsefp3epcVf7d84BXVcALwT\n+FRV/TLwI5Zc+pnEGqY9BFb0NRRT5MUk6wC6x9Njns+ykvwcvQD4XFV9sWueujoAquqHwNfo3auZ\nlhreDXwgyXF638r7niT3MT3z/6mqOtk9ngb+gN63Dk9THSeAE92ZJMD99EJhomuY9hA4376G4hCw\ns1veSe8a+8RKEuBu4Kmq+t2+TVNTR5JfSHJJt3wRvXsa32VKaqiqvVW1oao20Xv9/3FV/QZTMv/X\nJHlLkr/92jLwa8ATTFEdVfUC8HySt3VN1wNPMuk1jPumxAhuxrwX+FPgz4DfGfd8zmLenwdOAT+h\n9xvErcDfoXeD7xngj4DLxj3PZWr4FXqntn8CfLv7ee801QH8EvCtroYngH/TtU9NDX21zPH6jeGp\nmj/w94HvdD9HX/u3PIV1vAN4rHs9/Tfg0kmvwU8MS1LDpv1ykCRpCIaAJDXMEJCkhhkCktQwQ0CS\nGmYISFLDDAFJapghIEkN+38LL7DxoVBrnwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112972a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_sub.seq_len.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#if we want validation accuracy to better resemble test accuracy, need to create vocab on training only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4467, 88)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# subclass the custom dataset class with torch.utils.data.Dataset\n",
    "# implement __len__ and __getitem__ function\n",
    "class VectorizeData(Dataset):\n",
    "    def __init__(self, df, label, maxlen=20):\n",
    "        self.df = df\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X = self.df.padded_tweet[idx]\n",
    "        y = self.df[self.label][idx]\n",
    "        lens = self.df.seq_len[idx]\n",
    "        return X,y,lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = VectorizeData(train_sub, label = 'hatespeech')\n",
    "\n",
    "dl = DataLoader(data, batch_size = 32, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sort_batch(X, y, lengths):\n",
    "    lengths, indx = lengths.sort(dim=0, descending=True)\n",
    "    X = X[indx]\n",
    "    y = y[indx]\n",
    "    return X, y, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, weights, vocab_size, embedding_dim, hidden_dim, output_size, batch_size):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.weights = weights\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.embedding.weight = nn.Parameter(self.weights)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=1)\n",
    "        self.hidden2out = nn.Linear(hidden_dim, output_size)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "        self.dropout_layer = nn.Dropout(p=0.2)\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        return(autograd.Variable(torch.randn(1, batch_size, self.hidden_dim)), \\\n",
    "               autograd.Variable(torch.randn(1, batch_size, self.hidden_dim)))\n",
    "\n",
    "    def forward(self, batch, lengths):\n",
    "        self.hidden = self.init_hidden(batch_size)\n",
    "        embeds = self.embedding(batch) \n",
    "        embeds = pack_padded_sequence(embeds, lengths)\n",
    "        outputs, (ht, ct) = self.lstm(embeds, self.hidden)\n",
    "        outputs, lengths = pad_packed_sequence(outputs)\n",
    "        # ht is the last hidden state of the sequences\n",
    "        # ht = (1 x batch_size x hidden_dim)\n",
    "        # ht[-1] = (batch_size x hidden_dim)\n",
    "        output = self.dropout_layer(ht[-1])\n",
    "        output = self.hidden2out(output)\n",
    "        output = self.softmax(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_size = 200 \n",
    "num_classes = 2\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "weights = torch.FloatTensor(weights_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_validation_loss(validation_data_loader, model):\n",
    "    predictions = []\n",
    "    pred_labels = []\n",
    "    #get training predictions\n",
    "    it = iter(validation_data_loader)\n",
    "    num_batch = len(validation_data_loader) - 1\n",
    "    # Loop over all batches\n",
    "    for i in range(num_batch):\n",
    "        batch_x,batch_y,batch_len = next(it)\n",
    "        batch_x,batch_y,batch_len = sort_batch(batch_x,batch_y,batch_len)\n",
    "        tweets = Variable(batch_x.transpose(0,1))\n",
    "        labels = Variable(batch_y)\n",
    "        lengths = batch_len.numpy()\n",
    "        outputs = model(tweets, lengths)\n",
    "        _, pred = torch.max(outputs.data, 1)\n",
    "        predictions.extend(list(pred.numpy()))\n",
    "        pred_labels.extend(list(labels.data.numpy()))\n",
    "    return (f1_score(predictions, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4364\n",
       "1     103\n",
       "Name: hatespeech, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sub.hatespeech.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = LSTMClassifier(weights, total_words, hidden_size, hidden_size, num_classes, batch_size)\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.NLLLoss(weight = torch.Tensor([1/41,1]))  \n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "#Validation Data\n",
    "val = VectorizeData(validation, label = 'hatespeech')\n",
    "dl2 = DataLoader(val, batch_size = 32, shuffle = False)\n",
    "\n",
    "losses = []\n",
    "val_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Step [6/174], Loss: 0.7784\n",
      "Epoch [1/30], Step [12/174], Loss: 0.5962\n",
      "Epoch [1/30], Step [18/174], Loss: 0.3717\n",
      "Epoch [1/30], Step [24/174], Loss: 0.6762\n",
      "Epoch [1/30], Step [30/174], Loss: 1.9041\n",
      "Epoch [1/30], Step [36/174], Loss: 1.5746\n",
      "Epoch [1/30], Step [42/174], Loss: 0.3525\n",
      "Epoch [1/30], Step [48/174], Loss: 1.6497\n",
      "Epoch [1/30], Step [54/174], Loss: 0.1155\n",
      "Epoch [1/30], Step [60/174], Loss: 0.3714\n",
      "Epoch [1/30], Step [66/174], Loss: 0.1550\n",
      "Epoch [1/30], Step [72/174], Loss: 0.0944\n",
      "Epoch [1/30], Step [78/174], Loss: 0.8453\n",
      "Epoch [1/30], Step [84/174], Loss: 1.4999\n",
      "Epoch [1/30], Step [90/174], Loss: 0.0716\n",
      "Epoch [1/30], Step [96/174], Loss: 1.1747\n",
      "Epoch [1/30], Step [102/174], Loss: 1.2441\n",
      "Epoch [1/30], Step [108/174], Loss: 0.1901\n",
      "Epoch [1/30], Step [114/174], Loss: 0.2015\n",
      "Epoch [1/30], Step [120/174], Loss: 0.2322\n",
      "Epoch [1/30], Step [126/174], Loss: 0.2852\n",
      "Epoch [1/30], Step [132/174], Loss: 0.1820\n",
      "Epoch [1/30], Step [138/174], Loss: 0.1538\n",
      "Epoch [2/30], Step [6/174], Loss: 0.3527\n",
      "Epoch [2/30], Step [12/174], Loss: 0.0864\n",
      "Epoch [2/30], Step [18/174], Loss: 0.0916\n",
      "Epoch [2/30], Step [24/174], Loss: 1.1997\n",
      "Epoch [2/30], Step [30/174], Loss: 0.0304\n",
      "Epoch [2/30], Step [36/174], Loss: 0.0686\n",
      "Epoch [2/30], Step [42/174], Loss: 0.0256\n",
      "Epoch [2/30], Step [48/174], Loss: 1.3828\n",
      "Epoch [2/30], Step [54/174], Loss: 0.0404\n",
      "Epoch [2/30], Step [60/174], Loss: 0.0843\n",
      "Epoch [2/30], Step [66/174], Loss: 0.1389\n",
      "Epoch [2/30], Step [72/174], Loss: 0.2496\n",
      "Epoch [2/30], Step [78/174], Loss: 0.0745\n",
      "Epoch [2/30], Step [84/174], Loss: 0.0635\n",
      "Epoch [2/30], Step [90/174], Loss: 0.0594\n",
      "Epoch [2/30], Step [96/174], Loss: 0.9531\n",
      "Epoch [2/30], Step [102/174], Loss: 0.0263\n",
      "Epoch [2/30], Step [108/174], Loss: 0.8454\n",
      "Epoch [2/30], Step [114/174], Loss: 0.3006\n",
      "Epoch [2/30], Step [120/174], Loss: 0.1550\n",
      "Epoch [2/30], Step [126/174], Loss: 0.1415\n",
      "Epoch [2/30], Step [132/174], Loss: 1.3380\n",
      "Epoch [2/30], Step [138/174], Loss: 0.0235\n",
      "Epoch [3/30], Step [6/174], Loss: 0.1291\n",
      "Epoch [3/30], Step [12/174], Loss: 0.0483\n",
      "Epoch [3/30], Step [18/174], Loss: 0.0261\n",
      "Epoch [3/30], Step [24/174], Loss: 0.0845\n",
      "Epoch [3/30], Step [30/174], Loss: 0.1461\n",
      "Epoch [3/30], Step [36/174], Loss: 0.0656\n",
      "Epoch [3/30], Step [42/174], Loss: 0.2250\n",
      "Epoch [3/30], Step [48/174], Loss: 0.0284\n",
      "Epoch [3/30], Step [54/174], Loss: 1.6753\n",
      "Epoch [3/30], Step [60/174], Loss: 0.0215\n",
      "Epoch [3/30], Step [66/174], Loss: 0.0575\n",
      "Epoch [3/30], Step [72/174], Loss: 0.0558\n",
      "Epoch [3/30], Step [78/174], Loss: 0.4459\n",
      "Epoch [3/30], Step [84/174], Loss: 0.0840\n",
      "Epoch [3/30], Step [90/174], Loss: 0.0661\n",
      "Epoch [3/30], Step [96/174], Loss: 0.0309\n",
      "Epoch [3/30], Step [102/174], Loss: 0.0656\n",
      "Epoch [3/30], Step [108/174], Loss: 0.3088\n",
      "Epoch [3/30], Step [114/174], Loss: 0.0337\n",
      "Epoch [3/30], Step [120/174], Loss: 0.0171\n",
      "Epoch [3/30], Step [126/174], Loss: 0.0304\n",
      "Epoch [3/30], Step [132/174], Loss: 0.0219\n",
      "Epoch [3/30], Step [138/174], Loss: 0.0582\n",
      "Epoch [4/30], Step [6/174], Loss: 0.0240\n",
      "Epoch [4/30], Step [12/174], Loss: 0.0210\n",
      "Epoch [4/30], Step [18/174], Loss: 0.0070\n",
      "Epoch [4/30], Step [24/174], Loss: 0.3443\n",
      "Epoch [4/30], Step [30/174], Loss: 0.0222\n",
      "Epoch [4/30], Step [36/174], Loss: 1.3699\n",
      "Epoch [4/30], Step [42/174], Loss: 0.0258\n",
      "Epoch [4/30], Step [48/174], Loss: 0.1884\n",
      "Epoch [4/30], Step [54/174], Loss: 0.0452\n",
      "Epoch [4/30], Step [60/174], Loss: 0.0096\n",
      "Epoch [4/30], Step [66/174], Loss: 0.0060\n",
      "Epoch [4/30], Step [72/174], Loss: 0.0054\n",
      "Epoch [4/30], Step [78/174], Loss: 0.0273\n",
      "Epoch [4/30], Step [84/174], Loss: 0.0354\n",
      "Epoch [4/30], Step [90/174], Loss: 0.1300\n",
      "Epoch [4/30], Step [96/174], Loss: 0.1741\n",
      "Epoch [4/30], Step [102/174], Loss: 0.0327\n",
      "Epoch [4/30], Step [108/174], Loss: 0.0461\n",
      "Epoch [4/30], Step [114/174], Loss: 0.0284\n",
      "Epoch [4/30], Step [120/174], Loss: 0.1831\n",
      "Epoch [4/30], Step [126/174], Loss: 0.0568\n",
      "Epoch [4/30], Step [132/174], Loss: 0.0402\n",
      "Epoch [4/30], Step [138/174], Loss: 1.0804\n",
      "Epoch [5/30], Step [6/174], Loss: 0.0067\n",
      "Epoch [5/30], Step [12/174], Loss: 0.0094\n",
      "Epoch [5/30], Step [18/174], Loss: 0.0025\n",
      "Epoch [5/30], Step [24/174], Loss: 0.0152\n",
      "Epoch [5/30], Step [30/174], Loss: 0.0394\n",
      "Epoch [5/30], Step [36/174], Loss: 0.7139\n",
      "Epoch [5/30], Step [42/174], Loss: 1.0459\n",
      "Epoch [5/30], Step [48/174], Loss: 0.0082\n",
      "Epoch [5/30], Step [54/174], Loss: 0.0363\n",
      "Epoch [5/30], Step [60/174], Loss: 0.0022\n",
      "Epoch [5/30], Step [66/174], Loss: 0.0017\n",
      "Epoch [5/30], Step [72/174], Loss: 0.0091\n",
      "Epoch [5/30], Step [78/174], Loss: 0.0030\n",
      "Epoch [5/30], Step [84/174], Loss: 0.0056\n",
      "Epoch [5/30], Step [90/174], Loss: 0.0334\n",
      "Epoch [5/30], Step [96/174], Loss: 0.0115\n",
      "Epoch [5/30], Step [102/174], Loss: 0.0020\n",
      "Epoch [5/30], Step [108/174], Loss: 0.0157\n",
      "Epoch [5/30], Step [114/174], Loss: 0.0332\n",
      "Epoch [5/30], Step [120/174], Loss: 0.0042\n",
      "Epoch [5/30], Step [126/174], Loss: 0.0413\n",
      "Epoch [5/30], Step [132/174], Loss: 0.0187\n",
      "Epoch [5/30], Step [138/174], Loss: 0.1370\n",
      "Epoch [6/30], Step [6/174], Loss: 0.0161\n",
      "Epoch [6/30], Step [12/174], Loss: 0.0077\n",
      "Epoch [6/30], Step [18/174], Loss: 0.0012\n",
      "Epoch [6/30], Step [24/174], Loss: 0.0021\n",
      "Epoch [6/30], Step [30/174], Loss: 0.0055\n",
      "Epoch [6/30], Step [36/174], Loss: 0.0048\n",
      "Epoch [6/30], Step [42/174], Loss: 0.0843\n",
      "Epoch [6/30], Step [48/174], Loss: 0.0045\n",
      "Epoch [6/30], Step [54/174], Loss: 0.0487\n",
      "Epoch [6/30], Step [60/174], Loss: 0.3347\n",
      "Epoch [6/30], Step [66/174], Loss: 0.0044\n",
      "Epoch [6/30], Step [72/174], Loss: 0.0037\n",
      "Epoch [6/30], Step [78/174], Loss: 0.0080\n",
      "Epoch [6/30], Step [84/174], Loss: 0.0057\n",
      "Epoch [6/30], Step [90/174], Loss: 0.5319\n",
      "Epoch [6/30], Step [96/174], Loss: 0.9710\n",
      "Epoch [6/30], Step [102/174], Loss: 0.0198\n",
      "Epoch [6/30], Step [108/174], Loss: 0.0206\n",
      "Epoch [6/30], Step [114/174], Loss: 0.0034\n",
      "Epoch [6/30], Step [120/174], Loss: 0.0008\n",
      "Epoch [6/30], Step [126/174], Loss: 0.0019\n",
      "Epoch [6/30], Step [132/174], Loss: 0.0471\n",
      "Epoch [6/30], Step [138/174], Loss: 0.0018\n",
      "Epoch [7/30], Step [6/174], Loss: 0.0792\n",
      "Epoch [7/30], Step [12/174], Loss: 0.0009\n",
      "Epoch [7/30], Step [18/174], Loss: 0.0005\n",
      "Epoch [7/30], Step [24/174], Loss: 0.0042\n",
      "Epoch [7/30], Step [30/174], Loss: 0.0030\n",
      "Epoch [7/30], Step [36/174], Loss: 0.0117\n",
      "Epoch [7/30], Step [42/174], Loss: 0.0015\n",
      "Epoch [7/30], Step [48/174], Loss: 0.0031\n",
      "Epoch [7/30], Step [54/174], Loss: 0.0008\n",
      "Epoch [7/30], Step [60/174], Loss: 0.3656\n",
      "Epoch [7/30], Step [66/174], Loss: 0.0007\n",
      "Epoch [7/30], Step [72/174], Loss: 0.0715\n",
      "Epoch [7/30], Step [78/174], Loss: 0.0006\n",
      "Epoch [7/30], Step [84/174], Loss: 0.0019\n",
      "Epoch [7/30], Step [90/174], Loss: 0.0006\n",
      "Epoch [7/30], Step [96/174], Loss: 2.0210\n",
      "Epoch [7/30], Step [102/174], Loss: 0.0160\n",
      "Epoch [7/30], Step [108/174], Loss: 0.1066\n",
      "Epoch [7/30], Step [114/174], Loss: 0.0032\n",
      "Epoch [7/30], Step [120/174], Loss: 0.0019\n",
      "Epoch [7/30], Step [126/174], Loss: 0.0031\n",
      "Epoch [7/30], Step [132/174], Loss: 0.0043\n",
      "Epoch [7/30], Step [138/174], Loss: 0.0047\n",
      "Epoch [8/30], Step [6/174], Loss: 0.0031\n",
      "Epoch [8/30], Step [12/174], Loss: 0.0019\n",
      "Epoch [8/30], Step [18/174], Loss: 0.0112\n",
      "Epoch [8/30], Step [24/174], Loss: 0.0016\n",
      "Epoch [8/30], Step [30/174], Loss: 0.0012\n",
      "Epoch [8/30], Step [36/174], Loss: 0.0001\n",
      "Epoch [8/30], Step [42/174], Loss: 0.0022\n",
      "Epoch [8/30], Step [48/174], Loss: 0.0001\n",
      "Epoch [8/30], Step [54/174], Loss: 0.0447\n",
      "Epoch [8/30], Step [60/174], Loss: 0.0058\n",
      "Epoch [8/30], Step [66/174], Loss: 0.1376\n",
      "Epoch [8/30], Step [72/174], Loss: 0.0085\n",
      "Epoch [8/30], Step [78/174], Loss: 0.0055\n",
      "Epoch [8/30], Step [84/174], Loss: 0.0034\n",
      "Epoch [8/30], Step [90/174], Loss: 0.0011\n",
      "Epoch [8/30], Step [96/174], Loss: 0.0195\n",
      "Epoch [8/30], Step [102/174], Loss: 0.0098\n",
      "Epoch [8/30], Step [108/174], Loss: 0.0014\n",
      "Epoch [8/30], Step [114/174], Loss: 0.0037\n",
      "Epoch [8/30], Step [120/174], Loss: 0.1551\n",
      "Epoch [8/30], Step [126/174], Loss: 0.1251\n",
      "Epoch [8/30], Step [132/174], Loss: 0.0009\n",
      "Epoch [8/30], Step [138/174], Loss: 0.0026\n",
      "Epoch [9/30], Step [6/174], Loss: 0.0010\n",
      "Epoch [9/30], Step [12/174], Loss: 0.0003\n",
      "Epoch [9/30], Step [18/174], Loss: 0.0003\n",
      "Epoch [9/30], Step [24/174], Loss: 0.0011\n",
      "Epoch [9/30], Step [30/174], Loss: 0.0001\n",
      "Epoch [9/30], Step [36/174], Loss: 0.0079\n",
      "Epoch [9/30], Step [42/174], Loss: 0.0006\n",
      "Epoch [9/30], Step [48/174], Loss: 0.0004\n",
      "Epoch [9/30], Step [54/174], Loss: 0.0002\n",
      "Epoch [9/30], Step [60/174], Loss: 0.0017\n",
      "Epoch [9/30], Step [66/174], Loss: 0.0032\n",
      "Epoch [9/30], Step [72/174], Loss: 0.0003\n",
      "Epoch [9/30], Step [78/174], Loss: 0.0003\n",
      "Epoch [9/30], Step [84/174], Loss: 0.0058\n",
      "Epoch [9/30], Step [90/174], Loss: 0.0019\n",
      "Epoch [9/30], Step [96/174], Loss: 0.0001\n",
      "Epoch [9/30], Step [102/174], Loss: 0.0001\n",
      "Epoch [9/30], Step [108/174], Loss: 0.0228\n",
      "Epoch [9/30], Step [114/174], Loss: 0.0090\n",
      "Epoch [9/30], Step [120/174], Loss: 0.0048\n",
      "Epoch [9/30], Step [126/174], Loss: 0.0128\n",
      "Epoch [9/30], Step [132/174], Loss: 0.0007\n",
      "Epoch [9/30], Step [138/174], Loss: 0.0021\n",
      "Epoch [10/30], Step [6/174], Loss: 0.0001\n",
      "Epoch [10/30], Step [12/174], Loss: 0.0005\n",
      "Epoch [10/30], Step [18/174], Loss: 0.0004\n",
      "Epoch [10/30], Step [24/174], Loss: 0.0017\n",
      "Epoch [10/30], Step [30/174], Loss: 0.0012\n",
      "Epoch [10/30], Step [36/174], Loss: 0.0017\n",
      "Epoch [10/30], Step [42/174], Loss: 0.0001\n",
      "Epoch [10/30], Step [48/174], Loss: 0.0004\n",
      "Epoch [10/30], Step [54/174], Loss: 0.0006\n",
      "Epoch [10/30], Step [60/174], Loss: 0.0042\n",
      "Epoch [10/30], Step [66/174], Loss: 0.0029\n",
      "Epoch [10/30], Step [72/174], Loss: 0.0047\n",
      "Epoch [10/30], Step [78/174], Loss: 0.0013\n",
      "Epoch [10/30], Step [84/174], Loss: 0.0034\n",
      "Epoch [10/30], Step [90/174], Loss: 0.0001\n",
      "Epoch [10/30], Step [96/174], Loss: 0.0013\n",
      "Epoch [10/30], Step [102/174], Loss: 0.0020\n",
      "Epoch [10/30], Step [108/174], Loss: 0.0008\n",
      "Epoch [10/30], Step [114/174], Loss: 0.0013\n",
      "Epoch [10/30], Step [120/174], Loss: 0.0081\n",
      "Epoch [10/30], Step [126/174], Loss: 0.0031\n",
      "Epoch [10/30], Step [132/174], Loss: 0.0007\n",
      "Epoch [10/30], Step [138/174], Loss: 0.0003\n",
      "Epoch [11/30], Step [6/174], Loss: 0.0004\n",
      "Epoch [11/30], Step [12/174], Loss: 0.0002\n",
      "Epoch [11/30], Step [18/174], Loss: 0.0055\n",
      "Epoch [11/30], Step [24/174], Loss: 0.0020\n",
      "Epoch [11/30], Step [30/174], Loss: 0.0024\n",
      "Epoch [11/30], Step [36/174], Loss: 0.0004\n",
      "Epoch [11/30], Step [42/174], Loss: 0.0004\n",
      "Epoch [11/30], Step [48/174], Loss: 0.0001\n",
      "Epoch [11/30], Step [54/174], Loss: 0.0722\n",
      "Epoch [11/30], Step [60/174], Loss: 0.0020\n",
      "Epoch [11/30], Step [66/174], Loss: 0.0001\n",
      "Epoch [11/30], Step [72/174], Loss: 0.0003\n",
      "Epoch [11/30], Step [78/174], Loss: 0.0067\n",
      "Epoch [11/30], Step [84/174], Loss: 0.0001\n",
      "Epoch [11/30], Step [90/174], Loss: 0.0070\n",
      "Epoch [11/30], Step [96/174], Loss: 0.0001\n",
      "Epoch [11/30], Step [102/174], Loss: 0.0037\n",
      "Epoch [11/30], Step [108/174], Loss: 0.0001\n",
      "Epoch [11/30], Step [114/174], Loss: 0.0001\n",
      "Epoch [11/30], Step [120/174], Loss: 0.0094\n",
      "Epoch [11/30], Step [126/174], Loss: 0.0029\n",
      "Epoch [11/30], Step [132/174], Loss: 0.0993\n",
      "Epoch [11/30], Step [138/174], Loss: 0.0005\n",
      "Epoch [12/30], Step [6/174], Loss: 0.0004\n",
      "Epoch [12/30], Step [12/174], Loss: 0.0025\n",
      "Epoch [12/30], Step [18/174], Loss: 0.1054\n",
      "Epoch [12/30], Step [24/174], Loss: 0.0002\n",
      "Epoch [12/30], Step [30/174], Loss: 0.0004\n",
      "Epoch [12/30], Step [36/174], Loss: 0.0002\n",
      "Epoch [12/30], Step [42/174], Loss: 0.0001\n",
      "Epoch [12/30], Step [48/174], Loss: 0.0002\n",
      "Epoch [12/30], Step [54/174], Loss: 0.1778\n",
      "Epoch [12/30], Step [60/174], Loss: 0.0001\n",
      "Epoch [12/30], Step [66/174], Loss: 0.0003\n",
      "Epoch [12/30], Step [72/174], Loss: 0.0005\n",
      "Epoch [12/30], Step [78/174], Loss: 0.1496\n",
      "Epoch [12/30], Step [84/174], Loss: 0.0038\n",
      "Epoch [12/30], Step [90/174], Loss: 0.0001\n",
      "Epoch [12/30], Step [96/174], Loss: 0.0008\n",
      "Epoch [12/30], Step [102/174], Loss: 0.0014\n",
      "Epoch [12/30], Step [108/174], Loss: 0.0014\n",
      "Epoch [12/30], Step [114/174], Loss: 0.0002\n",
      "Epoch [12/30], Step [120/174], Loss: 0.0005\n",
      "Epoch [12/30], Step [126/174], Loss: 0.0024\n",
      "Epoch [12/30], Step [132/174], Loss: 0.0001\n",
      "Epoch [12/30], Step [138/174], Loss: 0.0045\n",
      "Epoch [13/30], Step [6/174], Loss: 0.0002\n",
      "Epoch [13/30], Step [12/174], Loss: 0.0181\n",
      "Epoch [13/30], Step [18/174], Loss: 0.0002\n",
      "Epoch [13/30], Step [24/174], Loss: 0.0034\n",
      "Epoch [13/30], Step [30/174], Loss: 0.0003\n",
      "Epoch [13/30], Step [36/174], Loss: 0.0011\n",
      "Epoch [13/30], Step [42/174], Loss: 0.0056\n",
      "Epoch [13/30], Step [48/174], Loss: 0.0001\n",
      "Epoch [13/30], Step [54/174], Loss: 0.0033\n",
      "Epoch [13/30], Step [60/174], Loss: 0.0021\n",
      "Epoch [13/30], Step [66/174], Loss: 0.0711\n",
      "Epoch [13/30], Step [72/174], Loss: 0.0001\n",
      "Epoch [13/30], Step [78/174], Loss: 0.0001\n",
      "Epoch [13/30], Step [84/174], Loss: 0.0003\n",
      "Epoch [13/30], Step [90/174], Loss: 0.1337\n",
      "Epoch [13/30], Step [96/174], Loss: 0.0025\n",
      "Epoch [13/30], Step [102/174], Loss: 0.0010\n",
      "Epoch [13/30], Step [108/174], Loss: 0.0002\n",
      "Epoch [13/30], Step [114/174], Loss: 0.0052\n",
      "Epoch [13/30], Step [120/174], Loss: 0.0011\n",
      "Epoch [13/30], Step [126/174], Loss: 0.0002\n",
      "Epoch [13/30], Step [132/174], Loss: 0.0002\n",
      "Epoch [13/30], Step [138/174], Loss: 0.0613\n",
      "Epoch [14/30], Step [6/174], Loss: 0.0020\n",
      "Epoch [14/30], Step [12/174], Loss: 0.0026\n",
      "Epoch [14/30], Step [18/174], Loss: 0.0088\n",
      "Epoch [14/30], Step [24/174], Loss: 0.0001\n",
      "Epoch [14/30], Step [30/174], Loss: 0.0001\n",
      "Epoch [14/30], Step [36/174], Loss: 0.0004\n",
      "Epoch [14/30], Step [42/174], Loss: 0.0013\n",
      "Epoch [14/30], Step [48/174], Loss: 0.0015\n",
      "Epoch [14/30], Step [54/174], Loss: 0.0006\n",
      "Epoch [14/30], Step [60/174], Loss: 0.0003\n",
      "Epoch [14/30], Step [66/174], Loss: 0.0001\n",
      "Epoch [14/30], Step [72/174], Loss: 0.0001\n",
      "Epoch [14/30], Step [78/174], Loss: 0.0007\n",
      "Epoch [14/30], Step [84/174], Loss: 0.0000\n",
      "Epoch [14/30], Step [90/174], Loss: 0.0001\n",
      "Epoch [14/30], Step [96/174], Loss: 0.0010\n",
      "Epoch [14/30], Step [102/174], Loss: 0.0001\n",
      "Epoch [14/30], Step [108/174], Loss: 0.0007\n",
      "Epoch [14/30], Step [114/174], Loss: 0.0011\n",
      "Epoch [14/30], Step [120/174], Loss: 0.0001\n",
      "Epoch [14/30], Step [126/174], Loss: 0.0001\n",
      "Epoch [14/30], Step [132/174], Loss: 0.0047\n",
      "Epoch [14/30], Step [138/174], Loss: 0.0001\n",
      "Epoch [15/30], Step [6/174], Loss: 0.0008\n",
      "Epoch [15/30], Step [12/174], Loss: 0.0001\n",
      "Epoch [15/30], Step [18/174], Loss: 0.0090\n",
      "Epoch [15/30], Step [24/174], Loss: 0.2810\n",
      "Epoch [15/30], Step [30/174], Loss: 0.0015\n",
      "Epoch [15/30], Step [36/174], Loss: 0.0042\n",
      "Epoch [15/30], Step [42/174], Loss: 0.0005\n",
      "Epoch [15/30], Step [48/174], Loss: 0.0002\n",
      "Epoch [15/30], Step [54/174], Loss: 0.0001\n",
      "Epoch [15/30], Step [60/174], Loss: 0.0001\n",
      "Epoch [15/30], Step [66/174], Loss: 0.0032\n",
      "Epoch [15/30], Step [72/174], Loss: 0.0002\n",
      "Epoch [15/30], Step [78/174], Loss: 0.0003\n",
      "Epoch [15/30], Step [84/174], Loss: 0.0001\n",
      "Epoch [15/30], Step [90/174], Loss: 0.0450\n",
      "Epoch [15/30], Step [96/174], Loss: 0.0009\n",
      "Epoch [15/30], Step [102/174], Loss: 0.0002\n",
      "Epoch [15/30], Step [108/174], Loss: 0.0014\n",
      "Epoch [15/30], Step [114/174], Loss: 0.0002\n",
      "Epoch [15/30], Step [120/174], Loss: 0.0000\n",
      "Epoch [15/30], Step [126/174], Loss: 0.0000\n",
      "Epoch [15/30], Step [132/174], Loss: 0.0001\n",
      "Epoch [15/30], Step [138/174], Loss: 0.0001\n",
      "Epoch [16/30], Step [6/174], Loss: 0.0002\n",
      "Epoch [16/30], Step [12/174], Loss: 0.0004\n",
      "Epoch [16/30], Step [18/174], Loss: 0.0013\n",
      "Epoch [16/30], Step [24/174], Loss: 0.0001\n",
      "Epoch [16/30], Step [30/174], Loss: 0.0003\n",
      "Epoch [16/30], Step [36/174], Loss: 0.0003\n",
      "Epoch [16/30], Step [42/174], Loss: 0.0021\n",
      "Epoch [16/30], Step [48/174], Loss: 0.0185\n",
      "Epoch [16/30], Step [54/174], Loss: 0.0008\n",
      "Epoch [16/30], Step [60/174], Loss: 0.0002\n",
      "Epoch [16/30], Step [66/174], Loss: 0.0002\n",
      "Epoch [16/30], Step [72/174], Loss: 0.0001\n",
      "Epoch [16/30], Step [78/174], Loss: 0.0005\n",
      "Epoch [16/30], Step [84/174], Loss: 0.0000\n",
      "Epoch [16/30], Step [90/174], Loss: 0.0004\n",
      "Epoch [16/30], Step [96/174], Loss: 0.0003\n",
      "Epoch [16/30], Step [102/174], Loss: 0.0025\n",
      "Epoch [16/30], Step [108/174], Loss: 0.0004\n",
      "Epoch [16/30], Step [114/174], Loss: 0.0023\n",
      "Epoch [16/30], Step [120/174], Loss: 0.0005\n",
      "Epoch [16/30], Step [126/174], Loss: 0.0001\n",
      "Epoch [16/30], Step [132/174], Loss: 0.0000\n",
      "Epoch [16/30], Step [138/174], Loss: 0.0002\n",
      "Epoch [17/30], Step [6/174], Loss: 0.0572\n",
      "Epoch [17/30], Step [12/174], Loss: 0.0001\n",
      "Epoch [17/30], Step [18/174], Loss: 0.0002\n",
      "Epoch [17/30], Step [24/174], Loss: 0.0001\n",
      "Epoch [17/30], Step [30/174], Loss: 0.0043\n",
      "Epoch [17/30], Step [36/174], Loss: 0.0001\n",
      "Epoch [17/30], Step [42/174], Loss: 0.0001\n",
      "Epoch [17/30], Step [48/174], Loss: 0.0002\n",
      "Epoch [17/30], Step [54/174], Loss: 0.0002\n",
      "Epoch [17/30], Step [60/174], Loss: 0.0366\n",
      "Epoch [17/30], Step [66/174], Loss: 0.0000\n",
      "Epoch [17/30], Step [72/174], Loss: 0.0098\n",
      "Epoch [17/30], Step [78/174], Loss: 0.0000\n",
      "Epoch [17/30], Step [84/174], Loss: 0.0009\n",
      "Epoch [17/30], Step [90/174], Loss: 0.0039\n",
      "Epoch [17/30], Step [96/174], Loss: 0.0000\n",
      "Epoch [17/30], Step [102/174], Loss: 0.0009\n",
      "Epoch [17/30], Step [108/174], Loss: 0.0034\n",
      "Epoch [17/30], Step [114/174], Loss: 0.0003\n",
      "Epoch [17/30], Step [120/174], Loss: 0.0001\n",
      "Epoch [17/30], Step [126/174], Loss: 0.0020\n",
      "Epoch [17/30], Step [132/174], Loss: 0.0165\n",
      "Epoch [17/30], Step [138/174], Loss: 0.0000\n",
      "Epoch [18/30], Step [6/174], Loss: 0.0000\n",
      "Epoch [18/30], Step [12/174], Loss: 0.0000\n",
      "Epoch [18/30], Step [18/174], Loss: 0.0001\n",
      "Epoch [18/30], Step [24/174], Loss: 0.0001\n",
      "Epoch [18/30], Step [30/174], Loss: 0.0002\n",
      "Epoch [18/30], Step [36/174], Loss: 0.0001\n",
      "Epoch [18/30], Step [42/174], Loss: 0.0001\n",
      "Epoch [18/30], Step [48/174], Loss: 0.0003\n",
      "Epoch [18/30], Step [54/174], Loss: 0.0010\n",
      "Epoch [18/30], Step [60/174], Loss: 0.0001\n",
      "Epoch [18/30], Step [66/174], Loss: 0.0001\n",
      "Epoch [18/30], Step [72/174], Loss: 0.0850\n",
      "Epoch [18/30], Step [78/174], Loss: 0.0002\n",
      "Epoch [18/30], Step [84/174], Loss: 0.0006\n",
      "Epoch [18/30], Step [90/174], Loss: 0.0000\n",
      "Epoch [18/30], Step [96/174], Loss: 0.0001\n",
      "Epoch [18/30], Step [102/174], Loss: 0.0004\n",
      "Epoch [18/30], Step [108/174], Loss: 0.0002\n",
      "Epoch [18/30], Step [114/174], Loss: 0.0041\n",
      "Epoch [18/30], Step [120/174], Loss: 0.0003\n",
      "Epoch [18/30], Step [126/174], Loss: 0.0000\n",
      "Epoch [18/30], Step [132/174], Loss: 0.0008\n",
      "Epoch [18/30], Step [138/174], Loss: 0.0000\n",
      "Epoch [19/30], Step [6/174], Loss: 0.0001\n",
      "Epoch [19/30], Step [12/174], Loss: 0.0003\n",
      "Epoch [19/30], Step [18/174], Loss: 0.0013\n",
      "Epoch [19/30], Step [24/174], Loss: 0.0001\n",
      "Epoch [19/30], Step [30/174], Loss: 0.1415\n",
      "Epoch [19/30], Step [36/174], Loss: 0.0005\n",
      "Epoch [19/30], Step [42/174], Loss: 0.0001\n",
      "Epoch [19/30], Step [48/174], Loss: 0.0000\n",
      "Epoch [19/30], Step [54/174], Loss: 0.0002\n",
      "Epoch [19/30], Step [60/174], Loss: 0.0000\n",
      "Epoch [19/30], Step [66/174], Loss: 0.0000\n",
      "Epoch [19/30], Step [72/174], Loss: 0.0013\n",
      "Epoch [19/30], Step [78/174], Loss: 0.0005\n",
      "Epoch [19/30], Step [84/174], Loss: 0.0005\n",
      "Epoch [19/30], Step [90/174], Loss: 0.0000\n",
      "Epoch [19/30], Step [96/174], Loss: 0.0000\n",
      "Epoch [19/30], Step [102/174], Loss: 0.0001\n",
      "Epoch [19/30], Step [108/174], Loss: 0.0000\n",
      "Epoch [19/30], Step [114/174], Loss: 0.0005\n",
      "Epoch [19/30], Step [120/174], Loss: 0.0002\n",
      "Epoch [19/30], Step [126/174], Loss: 0.0002\n",
      "Epoch [19/30], Step [132/174], Loss: 0.0006\n",
      "Epoch [19/30], Step [138/174], Loss: 0.0000\n",
      "Epoch [20/30], Step [6/174], Loss: 0.0000\n",
      "Epoch [20/30], Step [12/174], Loss: 0.0001\n",
      "Epoch [20/30], Step [18/174], Loss: 0.1195\n",
      "Epoch [20/30], Step [24/174], Loss: 0.0002\n",
      "Epoch [20/30], Step [30/174], Loss: 0.0001\n",
      "Epoch [20/30], Step [36/174], Loss: 0.0011\n",
      "Epoch [20/30], Step [42/174], Loss: 0.0000\n",
      "Epoch [20/30], Step [48/174], Loss: 0.0000\n",
      "Epoch [20/30], Step [54/174], Loss: 0.0027\n",
      "Epoch [20/30], Step [60/174], Loss: 0.0002\n",
      "Epoch [20/30], Step [66/174], Loss: 0.0012\n",
      "Epoch [20/30], Step [72/174], Loss: 0.0002\n",
      "Epoch [20/30], Step [78/174], Loss: 0.0002\n",
      "Epoch [20/30], Step [84/174], Loss: 0.0000\n",
      "Epoch [20/30], Step [90/174], Loss: 0.0003\n",
      "Epoch [20/30], Step [96/174], Loss: 0.0000\n",
      "Epoch [20/30], Step [102/174], Loss: 0.0000\n",
      "Epoch [20/30], Step [108/174], Loss: 0.0000\n",
      "Epoch [20/30], Step [114/174], Loss: 0.0025\n",
      "Epoch [20/30], Step [120/174], Loss: 0.0020\n",
      "Epoch [20/30], Step [126/174], Loss: 0.0037\n",
      "Epoch [20/30], Step [132/174], Loss: 0.0004\n",
      "Epoch [20/30], Step [138/174], Loss: 0.0001\n",
      "Epoch [21/30], Step [6/174], Loss: 0.0002\n",
      "Epoch [21/30], Step [12/174], Loss: 0.0001\n",
      "Epoch [21/30], Step [18/174], Loss: 0.0002\n",
      "Epoch [21/30], Step [24/174], Loss: 0.0001\n",
      "Epoch [21/30], Step [30/174], Loss: 0.0002\n",
      "Epoch [21/30], Step [36/174], Loss: 0.0000\n",
      "Epoch [21/30], Step [42/174], Loss: 0.0001\n",
      "Epoch [21/30], Step [48/174], Loss: 0.0004\n",
      "Epoch [21/30], Step [54/174], Loss: 0.0000\n",
      "Epoch [21/30], Step [60/174], Loss: 0.0322\n",
      "Epoch [21/30], Step [66/174], Loss: 0.0000\n",
      "Epoch [21/30], Step [72/174], Loss: 0.0000\n",
      "Epoch [21/30], Step [78/174], Loss: 0.0831\n",
      "Epoch [21/30], Step [84/174], Loss: 0.0000\n",
      "Epoch [21/30], Step [90/174], Loss: 0.0003\n",
      "Epoch [21/30], Step [96/174], Loss: 0.0000\n",
      "Epoch [21/30], Step [102/174], Loss: 0.0003\n",
      "Epoch [21/30], Step [108/174], Loss: 0.0010\n",
      "Epoch [21/30], Step [114/174], Loss: 0.0006\n",
      "Epoch [21/30], Step [120/174], Loss: 0.0000\n",
      "Epoch [21/30], Step [126/174], Loss: 0.0007\n",
      "Epoch [21/30], Step [132/174], Loss: 0.0000\n",
      "Epoch [21/30], Step [138/174], Loss: 0.0000\n",
      "Epoch [22/30], Step [6/174], Loss: 0.1042\n",
      "Epoch [22/30], Step [12/174], Loss: 0.0001\n",
      "Epoch [22/30], Step [18/174], Loss: 0.1134\n",
      "Epoch [22/30], Step [24/174], Loss: 0.0001\n",
      "Epoch [22/30], Step [30/174], Loss: 0.0000\n",
      "Epoch [22/30], Step [36/174], Loss: 0.0000\n",
      "Epoch [22/30], Step [42/174], Loss: 0.0004\n",
      "Epoch [22/30], Step [48/174], Loss: 0.0005\n",
      "Epoch [22/30], Step [54/174], Loss: 0.0004\n",
      "Epoch [22/30], Step [60/174], Loss: 0.0005\n",
      "Epoch [22/30], Step [66/174], Loss: 0.0004\n",
      "Epoch [22/30], Step [72/174], Loss: 0.0000\n",
      "Epoch [22/30], Step [78/174], Loss: 0.0002\n",
      "Epoch [22/30], Step [84/174], Loss: 0.0001\n",
      "Epoch [22/30], Step [90/174], Loss: 0.0000\n",
      "Epoch [22/30], Step [96/174], Loss: 0.0001\n",
      "Epoch [22/30], Step [102/174], Loss: 0.0006\n",
      "Epoch [22/30], Step [108/174], Loss: 0.0005\n",
      "Epoch [22/30], Step [114/174], Loss: 0.0008\n",
      "Epoch [22/30], Step [120/174], Loss: 0.0001\n",
      "Epoch [22/30], Step [126/174], Loss: 0.0012\n",
      "Epoch [22/30], Step [132/174], Loss: 0.0001\n",
      "Epoch [22/30], Step [138/174], Loss: 0.0005\n",
      "Epoch [23/30], Step [6/174], Loss: 0.0674\n",
      "Epoch [23/30], Step [12/174], Loss: 0.0000\n",
      "Epoch [23/30], Step [18/174], Loss: 0.0000\n",
      "Epoch [23/30], Step [24/174], Loss: 0.0003\n",
      "Epoch [23/30], Step [30/174], Loss: 0.0000\n",
      "Epoch [23/30], Step [36/174], Loss: 0.0003\n",
      "Epoch [23/30], Step [42/174], Loss: 0.0000\n",
      "Epoch [23/30], Step [48/174], Loss: 0.0000\n",
      "Epoch [23/30], Step [54/174], Loss: 0.0002\n",
      "Epoch [23/30], Step [60/174], Loss: 0.0008\n",
      "Epoch [23/30], Step [66/174], Loss: 0.0001\n",
      "Epoch [23/30], Step [72/174], Loss: 0.0005\n",
      "Epoch [23/30], Step [78/174], Loss: 0.0000\n",
      "Epoch [23/30], Step [84/174], Loss: 0.0000\n",
      "Epoch [23/30], Step [90/174], Loss: 0.0002\n",
      "Epoch [23/30], Step [96/174], Loss: 0.0004\n",
      "Epoch [23/30], Step [102/174], Loss: 0.0000\n",
      "Epoch [23/30], Step [108/174], Loss: 0.0000\n",
      "Epoch [23/30], Step [114/174], Loss: 0.0001\n",
      "Epoch [23/30], Step [120/174], Loss: 0.0000\n",
      "Epoch [23/30], Step [126/174], Loss: 0.0222\n",
      "Epoch [23/30], Step [132/174], Loss: 0.0002\n",
      "Epoch [23/30], Step [138/174], Loss: 0.0000\n",
      "Epoch [24/30], Step [6/174], Loss: 0.0000\n",
      "Epoch [24/30], Step [12/174], Loss: 0.0117\n",
      "Epoch [24/30], Step [18/174], Loss: 0.0002\n",
      "Epoch [24/30], Step [24/174], Loss: 0.0010\n",
      "Epoch [24/30], Step [30/174], Loss: 0.0000\n",
      "Epoch [24/30], Step [36/174], Loss: 0.0018\n",
      "Epoch [24/30], Step [42/174], Loss: 0.0003\n",
      "Epoch [24/30], Step [48/174], Loss: 0.0000\n",
      "Epoch [24/30], Step [54/174], Loss: 0.0469\n",
      "Epoch [24/30], Step [60/174], Loss: 0.0000\n",
      "Epoch [24/30], Step [66/174], Loss: 0.0000\n",
      "Epoch [24/30], Step [72/174], Loss: 0.0000\n",
      "Epoch [24/30], Step [78/174], Loss: 0.0000\n",
      "Epoch [24/30], Step [84/174], Loss: 0.0000\n",
      "Epoch [24/30], Step [90/174], Loss: 0.0016\n",
      "Epoch [24/30], Step [96/174], Loss: 0.0030\n",
      "Epoch [24/30], Step [102/174], Loss: 0.0000\n",
      "Epoch [24/30], Step [108/174], Loss: 0.0007\n",
      "Epoch [24/30], Step [114/174], Loss: 0.0007\n",
      "Epoch [24/30], Step [120/174], Loss: 0.0117\n",
      "Epoch [24/30], Step [126/174], Loss: 0.0001\n",
      "Epoch [24/30], Step [132/174], Loss: 0.0000\n",
      "Epoch [24/30], Step [138/174], Loss: 0.0035\n",
      "Epoch [25/30], Step [6/174], Loss: 0.0012\n",
      "Epoch [25/30], Step [12/174], Loss: 0.0004\n",
      "Epoch [25/30], Step [18/174], Loss: 0.0038\n",
      "Epoch [25/30], Step [24/174], Loss: 0.0007\n",
      "Epoch [25/30], Step [30/174], Loss: 0.0001\n",
      "Epoch [25/30], Step [36/174], Loss: 0.0001\n",
      "Epoch [25/30], Step [42/174], Loss: 0.0003\n",
      "Epoch [25/30], Step [48/174], Loss: 0.0141\n",
      "Epoch [25/30], Step [54/174], Loss: 0.0003\n",
      "Epoch [25/30], Step [60/174], Loss: 0.0000\n",
      "Epoch [25/30], Step [66/174], Loss: 0.0001\n",
      "Epoch [25/30], Step [72/174], Loss: 0.0315\n",
      "Epoch [25/30], Step [78/174], Loss: 0.0002\n",
      "Epoch [25/30], Step [84/174], Loss: 0.0001\n",
      "Epoch [25/30], Step [90/174], Loss: 0.0000\n",
      "Epoch [25/30], Step [96/174], Loss: 0.0128\n",
      "Epoch [25/30], Step [102/174], Loss: 0.0000\n",
      "Epoch [25/30], Step [108/174], Loss: 0.0002\n",
      "Epoch [25/30], Step [114/174], Loss: 0.0008\n",
      "Epoch [25/30], Step [120/174], Loss: 0.0018\n",
      "Epoch [25/30], Step [126/174], Loss: 0.0066\n",
      "Epoch [25/30], Step [132/174], Loss: 0.0003\n",
      "Epoch [25/30], Step [138/174], Loss: 0.0433\n",
      "Epoch [26/30], Step [6/174], Loss: 0.0005\n",
      "Epoch [26/30], Step [12/174], Loss: 0.0003\n",
      "Epoch [26/30], Step [18/174], Loss: 0.0000\n",
      "Epoch [26/30], Step [24/174], Loss: 0.0003\n",
      "Epoch [26/30], Step [30/174], Loss: 0.0001\n",
      "Epoch [26/30], Step [36/174], Loss: 0.0000\n",
      "Epoch [26/30], Step [42/174], Loss: 0.0000\n",
      "Epoch [26/30], Step [48/174], Loss: 0.0006\n",
      "Epoch [26/30], Step [54/174], Loss: 0.0001\n",
      "Epoch [26/30], Step [60/174], Loss: 0.0387\n",
      "Epoch [26/30], Step [66/174], Loss: 0.0001\n",
      "Epoch [26/30], Step [72/174], Loss: 0.0001\n",
      "Epoch [26/30], Step [78/174], Loss: 0.0012\n",
      "Epoch [26/30], Step [84/174], Loss: 0.0001\n",
      "Epoch [26/30], Step [90/174], Loss: 0.0382\n",
      "Epoch [26/30], Step [96/174], Loss: 0.0003\n",
      "Epoch [26/30], Step [102/174], Loss: 0.0001\n",
      "Epoch [26/30], Step [108/174], Loss: 0.0001\n",
      "Epoch [26/30], Step [114/174], Loss: 0.0000\n",
      "Epoch [26/30], Step [120/174], Loss: 0.0005\n",
      "Epoch [26/30], Step [126/174], Loss: 0.0010\n",
      "Epoch [26/30], Step [132/174], Loss: 0.0231\n",
      "Epoch [26/30], Step [138/174], Loss: 0.0004\n",
      "Epoch [27/30], Step [6/174], Loss: 0.0002\n",
      "Epoch [27/30], Step [12/174], Loss: 0.0011\n",
      "Epoch [27/30], Step [18/174], Loss: 0.0001\n",
      "Epoch [27/30], Step [24/174], Loss: 0.0034\n",
      "Epoch [27/30], Step [30/174], Loss: 0.0274\n",
      "Epoch [27/30], Step [36/174], Loss: 0.0003\n",
      "Epoch [27/30], Step [42/174], Loss: 0.0000\n",
      "Epoch [27/30], Step [48/174], Loss: 0.0006\n",
      "Epoch [27/30], Step [54/174], Loss: 0.0002\n",
      "Epoch [27/30], Step [60/174], Loss: 0.0000\n",
      "Epoch [27/30], Step [66/174], Loss: 0.0001\n",
      "Epoch [27/30], Step [72/174], Loss: 0.0001\n",
      "Epoch [27/30], Step [78/174], Loss: 0.0632\n",
      "Epoch [27/30], Step [84/174], Loss: 0.0001\n",
      "Epoch [27/30], Step [90/174], Loss: 0.0005\n",
      "Epoch [27/30], Step [96/174], Loss: 0.0000\n",
      "Epoch [27/30], Step [102/174], Loss: 0.0001\n",
      "Epoch [27/30], Step [108/174], Loss: 0.0054\n",
      "Epoch [27/30], Step [114/174], Loss: 0.0000\n",
      "Epoch [27/30], Step [120/174], Loss: 0.0000\n",
      "Epoch [27/30], Step [126/174], Loss: 0.0000\n",
      "Epoch [27/30], Step [132/174], Loss: 0.1239\n",
      "Epoch [27/30], Step [138/174], Loss: 0.0000\n",
      "Epoch [28/30], Step [6/174], Loss: 0.0001\n",
      "Epoch [28/30], Step [12/174], Loss: 0.0000\n",
      "Epoch [28/30], Step [18/174], Loss: 0.0001\n",
      "Epoch [28/30], Step [24/174], Loss: 0.0000\n",
      "Epoch [28/30], Step [30/174], Loss: 0.0024\n",
      "Epoch [28/30], Step [36/174], Loss: 0.0014\n",
      "Epoch [28/30], Step [42/174], Loss: 0.1234\n",
      "Epoch [28/30], Step [48/174], Loss: 0.0658\n",
      "Epoch [28/30], Step [54/174], Loss: 0.0002\n",
      "Epoch [28/30], Step [60/174], Loss: 0.0003\n",
      "Epoch [28/30], Step [66/174], Loss: 0.0001\n",
      "Epoch [28/30], Step [72/174], Loss: 0.0007\n",
      "Epoch [28/30], Step [78/174], Loss: 0.0019\n",
      "Epoch [28/30], Step [84/174], Loss: 0.0002\n",
      "Epoch [28/30], Step [90/174], Loss: 0.0036\n",
      "Epoch [28/30], Step [96/174], Loss: 0.0001\n",
      "Epoch [28/30], Step [102/174], Loss: 0.0000\n",
      "Epoch [28/30], Step [108/174], Loss: 0.0000\n",
      "Epoch [28/30], Step [114/174], Loss: 0.0000\n",
      "Epoch [28/30], Step [120/174], Loss: 0.0001\n",
      "Epoch [28/30], Step [126/174], Loss: 0.0003\n",
      "Epoch [28/30], Step [132/174], Loss: 0.0002\n",
      "Epoch [28/30], Step [138/174], Loss: 0.0001\n",
      "Epoch [29/30], Step [6/174], Loss: 0.0003\n",
      "Epoch [29/30], Step [12/174], Loss: 0.0001\n",
      "Epoch [29/30], Step [18/174], Loss: 0.0000\n",
      "Epoch [29/30], Step [24/174], Loss: 0.0001\n",
      "Epoch [29/30], Step [30/174], Loss: 0.0000\n",
      "Epoch [29/30], Step [36/174], Loss: 0.0000\n",
      "Epoch [29/30], Step [42/174], Loss: 0.0000\n",
      "Epoch [29/30], Step [48/174], Loss: 0.0004\n",
      "Epoch [29/30], Step [54/174], Loss: 0.0000\n",
      "Epoch [29/30], Step [60/174], Loss: 0.0000\n",
      "Epoch [29/30], Step [66/174], Loss: 0.0080\n",
      "Epoch [29/30], Step [72/174], Loss: 0.0000\n",
      "Epoch [29/30], Step [78/174], Loss: 0.0000\n",
      "Epoch [29/30], Step [84/174], Loss: 0.0000\n",
      "Epoch [29/30], Step [90/174], Loss: 0.0007\n",
      "Epoch [29/30], Step [96/174], Loss: 0.0001\n",
      "Epoch [29/30], Step [102/174], Loss: 0.0000\n",
      "Epoch [29/30], Step [108/174], Loss: 0.0000\n",
      "Epoch [29/30], Step [114/174], Loss: 0.0001\n",
      "Epoch [29/30], Step [120/174], Loss: 0.0000\n",
      "Epoch [29/30], Step [126/174], Loss: 0.0000\n",
      "Epoch [29/30], Step [132/174], Loss: 0.0000\n",
      "Epoch [29/30], Step [138/174], Loss: 0.0000\n",
      "Epoch [30/30], Step [6/174], Loss: 0.0000\n",
      "Epoch [30/30], Step [12/174], Loss: 0.0003\n",
      "Epoch [30/30], Step [18/174], Loss: 0.0000\n",
      "Epoch [30/30], Step [24/174], Loss: 0.0000\n",
      "Epoch [30/30], Step [30/174], Loss: 0.0001\n",
      "Epoch [30/30], Step [36/174], Loss: 0.0000\n",
      "Epoch [30/30], Step [42/174], Loss: 0.0000\n",
      "Epoch [30/30], Step [48/174], Loss: 0.0000\n",
      "Epoch [30/30], Step [54/174], Loss: 0.0006\n",
      "Epoch [30/30], Step [60/174], Loss: 0.0000\n",
      "Epoch [30/30], Step [66/174], Loss: 0.0000\n",
      "Epoch [30/30], Step [72/174], Loss: 0.0415\n",
      "Epoch [30/30], Step [78/174], Loss: 0.0001\n",
      "Epoch [30/30], Step [84/174], Loss: 0.0000\n",
      "Epoch [30/30], Step [90/174], Loss: 0.0000\n",
      "Epoch [30/30], Step [96/174], Loss: 0.0000\n",
      "Epoch [30/30], Step [102/174], Loss: 0.0000\n",
      "Epoch [30/30], Step [108/174], Loss: 0.0000\n",
      "Epoch [30/30], Step [114/174], Loss: 0.0000\n",
      "Epoch [30/30], Step [120/174], Loss: 0.0001\n",
      "Epoch [30/30], Step [126/174], Loss: 0.0000\n",
      "Epoch [30/30], Step [132/174], Loss: 0.0000\n",
      "Epoch [30/30], Step [138/174], Loss: 0.0001\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "\n",
    "num_batch = len(dl) - 1\n",
    "# Train the Model\n",
    "for epoch in range(num_epochs):\n",
    "    it = iter(dl)\n",
    "    # Loop over all batches\n",
    "    for i in range(num_batch):\n",
    "        batch_x,batch_y,batch_len = next(it)\n",
    "        batch_x,batch_y,batch_len = sort_batch(batch_x,batch_y,batch_len)\n",
    "        tweets = Variable(batch_x.transpose(0,1))\n",
    "        labels = Variable(batch_y)\n",
    "        lengths = batch_len.numpy()\n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()  # zero the gradient buffer\n",
    "        outputs = net(tweets, lengths)\n",
    "        loss = criterion(outputs, labels)\n",
    "        losses.append(loss.data[0])\n",
    "        loss.backward()\n",
    "        clip_grad_norm(net.parameters(), max_norm = 1)\n",
    "        for p in net.parameters():\n",
    "            p.data.add_(-learning_rate, p.grad.data)\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 6 == 0:\n",
    "            print ('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
    "                   %(epoch+1, num_epochs, i+1, len(train.clean_tweet)//batch_size, loss.data[0]))\n",
    "        if (i+1) % 12 == 0:\n",
    "            val_scores.append(get_validation_loss(dl2, net))\n",
    "            if val_scores[-1] == max(val_scores):\n",
    "                best_net = net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10fad6dd8>]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xm8HFWdNvDnlz1AZDEXyATixSE6IhNBMwFlVFR4Bwi+\n6KjDoqIMY14UFdT31YgMKKMRQaOEQGKECGFHwxLITlZCyHKz3+w3G7lJ7p67r939e//o6r7Vfbu6\nq29Xdy39fD+ffNJdXd197unup06dOnVKVBVERBQsA9wuABEROY/hTkQUQAx3IqIAYrgTEQUQw52I\nKIAY7kREAcRwJyIKIIY7EVEAMdyJiAJokFtvPHLkSC0tLXXr7YmIfGnTpk11qlqSaT3Xwr20tBRl\nZWVuvT0RkS+JyBE767FbhogogBjuREQBxHAnIgoghjsRUQAx3ImIAojhTkQUQAx3IqIAYrgTke8d\nqmvDOxV1bhfDUwIR7g1t3fjy4+/geGOH20UhIhd87vcr8fUn1rtdDE8JRLjP3VSJLe81YvaaQ24X\nhYjIEwIR7kRElIjhTkQUQAx3IqIAyhjuInK+iKwQkV0islNE7kqxzpUi0iQiW41/9+WnuEREZIed\nKX9DAH6iqptFZASATSKyVFV3Ja33tqpe73wRiYgoWxlb7qp6QlU3G7dbAOwGMDrfBSMiov7Lqs9d\nREoBXAog1YDST4nIdhFZKCIfdaBsRETUT7avxCQipwGYC+BuVW1OengzgDGq2ioi1wF4DcDYFK8x\nCcAkABgzZky/C51MoY69FhFRENhquYvIYESD/TlVfSX5cVVtVtVW4/YCAINFZGSK9Wap6nhVHV9S\nkvESgERE1E92RssIgCcB7FbVqRbrnGusBxGZYLxuvZMFTVtGSFbrt3eH8J05ZTjG6QqIKKDsdMtc\nAeCbAHaIyFZj2T0AxgCAqs4E8FUA3xWREIAOADepqmf7SpbsrMbSXdU4ZchAPHLTpW4Xh4jIcRnD\nXVXXAOmbxqo6HcB0pwpFRES54RmqREQBxHAnIgoghjsRUQAVZbhzXDwRBV0gwr2/YZ3dAEoiIv8I\nRLjHCNOaiAhAwMLduyPriYgKKxDhnu0ZqjHcFhBRUAUi3LPV340BEZFfFGW4c7QMEQVdUYZ7TKz9\nHo4oHlq0Byfbul0tDxGRU4o63GOW7a7G4ysP4P55O90uChGRIxjuiLbcAaA7FHG5JEREzghEuFv1\noasqluysQsQI71A4Er9NRBRkgQj3mOSTmOZuPoZJz2zCs+uPAAAu/MVC/OjlrSmeSUQULIEK92TV\nzZ0AgBNNnfFlr289bnmyE0fREFFQBCrcsz1D1bgyoOW0BU0dPVh/sN54bcXUpftQZdpQEBF5VSDC\n3XxSUnt3yPaB0UxXApw0pww3zlqH1q4QdhxrwrRl+/HDF7fkVFYiokIIRLibXXTfYtw4692EZckZ\nbneCsd0nmgEA4bDGR9R0cUQNEflA4MIdALa81wjAfohzwjEiCppAhjsRUbErmnBv6uiJ3862m4aj\naIjIbwIR7tYnMfXe/s6csj6PS4ZUz/Q4EZFXBSLcY9Jl8b7qlsIVhIjIZYEK92TZNrx5YJWIgiLQ\n4W5f6q2AeRw8c5+I/CRQ4Z6u5d1sOqDauz4jm4iCKRDhPmXBnrSPH2/sQH8mgzQfUOWhVSLyk0CE\nu5XYtASVJ9tTPx4Pb7bgiShYMoa7iJwvIitEZJeI7BSRu1KsIyIyTUQqRGS7iHw8P8UlIiI77LTc\nQwB+oqoXAbgcwJ0iclHSOtcCGGv8mwRghqOlzLv0nS5e7prfdOQkfv3mLreLQUQekzHcVfWEqm42\nbrcA2A1gdNJqNwCYo1HrAJwhIqMcL22B+eEcpq/MWIsn1hxyuxhE5DFZ9bmLSCmASwGsT3poNICj\npvuV6LsByDurMM7nmaadPWE0d/YdiUNE5Cbb4S4ipwGYC+BuVW3uz5uJyCQRKRORstra2v68hCOc\n7GaZOO1tjPvlEudekIjIAbbCXUQGIxrsz6nqKylWOQbgfNP984xlCVR1lqqOV9XxJSUl/Smvo5Lb\n8+ky3+qxA7VtDpWGiMg5dkbLCIAnAexW1akWq80DcKsxauZyAE2qesLBcuaVH/rWiYiyMcjGOlcA\n+CaAHSKy1Vh2D4AxAKCqMwEsAHAdgAoA7QBuc76omVle+NrigWx6Z5j/ROQnGcNdVdcgQ7ZpND3v\ndKpQTrE+wJp438tDHYmI+iPQZ6h62SubK3HJA0sQCvOarETkPN+G+/HGDlx8/2LsTzNPu3U3TeL9\nzFdict79r+9EY3sP2nvCeXh1Iip2vg33ReVVaO0K4bn178WXdYVSt4Ktxrln6kdnPzsR+ZVvwz2V\nZ9Ydid9u7Qrhd4vSzxZJRBRUvg339xpSz/QYM2vVgZzfg8dZicivfBvuT609nPbxsPkqSkmd7D3G\nQcxXtiSeZ5Vu1AyDnih7XaEw/tcfV2HtgTq3i1J0fBvuMeF+XIWjvTvxIKZV3zr73Ilyc6S+Hfuq\nW3H/6zvdLkrR8X24m/vZzcThaGbQE5Gf+D7cncAuFyIKmsCGO+eLIfIONqAKL7DhbpZpPvdM2wGr\nuWmIKD22sdxTFOHeX7GNQnc4gi8/vtbl0hAR2cdwt6G+tdvtIhARZaUowj1dt4rVJfLCEUVDW/pQ\nZ3cNEXlVYMM9XV9fxBTK7V3mMe+9y9/Ydtz5QhERFUhgwz2dZ5PGxqc64NqR59ka2eYnonwqynA/\nXJ9+XppMVu6twRvbjvMiH0TkWXYus+dL05ZX2FpPoQl950fq2zB88MC0wf3tv24EAEz851H9Lh+H\niFEx4fGpwiuKlnumce5mn314JSZMWYbWrt4DrX74XvLH4y0bDzegkxdi4cmELiqKcO+PKQs4Fzz1\nz+G6Nnxt5ru47/Vyt4tCRYzhjuxa9mZsK1MqTR3Rvb49VdaXgCwW3KF0D8OdiCiAiiLcc+2PZr8h\nUf/wt+Oeogj3zp7UF85OZrUNMC+XhOWJTyg/1oQWizNeiYgKqSjCfdeJZsvHVLMblmi1DxCJKK5/\ndA3+86mNWZWNqBiw673wiiLcc6U2vpqxNTYdOZnfwhD5Cvtl3MJwRzBaFRyVQERmDHeTbA/+ME+J\nMuGvxC0MdxN2qRBRUGQMdxGZLSI1IpLydDsRuVJEmkRkq/HvPueLmV+xBvvJdo50IXIW+9zdYmfi\nsKcATAcwJ806b6vq9Y6UyEdy6efmzioR5VPGlruqrgbQUICyuGJ3mmGSMcLWBxH5jFN97p8Ske0i\nslBEPmq1kohMEpEyESmrra116K1zc/vTZRnXMQ+FdCrmubkILu6VpcBKKTgnwn0zgDGqOg7AowBe\ns1pRVWep6nhVHV9SUuLAWzsj0ygZc/cLv6NE9nH6AffkHO6q2qyqrcbtBQAGi8jInEvmIVZfUDsn\nN1HxYZ6RF+Qc7iJyrhhz5orIBOM163N93UIKwglAAfgTKICC8Nvyq4yjZUTkBQBXAhgpIpUA7gcw\nGABUdSaArwL4roiEAHQAuEkDdlkgO39NwP5kIvK5jOGuqjdneHw6okMlyeMW7jiBls4Q/uNfzne7\nKFQk2OfunsBeIDsb/f0C+q2x/t3nNgMAw52oCHD6ASKH+WybXxCsk8JjuDvk1S3H3C4CkeewV8Y9\nDPcsWX1Z1x8K7Em8lCUGGnkBwx3Z9bmbdy9X7+s9yzbW/87dT6Je/D24h+Geg5bOUPx28glN71TU\nFXQKYQ7FJCIzjpYB8J9PZZ5fJiMjW2M7AV9/Yj0A4PCDE3N/bSKfYheVe9hyt8GqTZxLW5ntbCLK\nJ4a7DezyoGzw20JewHB3yJqKuqzW5+4qFRM2kAqP4W6DWAynMX9ha1q6ClUc8jhuuHtZ/XYo/xju\nNnzpsXdyfo2yww3YdrTRgdIQEWXG0TJZ6m875Ksz3wXA0TNUXNgd4x623LPEryoR+QHDPQdeGgrJ\njY538LPoxT539zDcXcavfnDxsyU3MdxdxlZecPGzJTcx3F3CVl1w8bPtixu6wvNluFc1dbpdhCh+\nY4nS4obOPb4M92/N3uB2EYjIBrZ/3OPLcK9tde9sULZEiMgPfBnuPDGCvIzfzl5sDLnHl+HuJk24\n3f+fsePj3JkoGVU3d6InHCnY+zHYyE2+DPcgnRjBUC6Mtq4QLpuyDPe+Wl6w9+RHS27yZbgHoVsm\nOJsnf2jvDgMAlu2pzvt78bPtKwA/Wd/xZbh73aLyE24XgSwwZAorQDvZvsNwz4FVUNzx7ObCFoQy\nYsi4gxtT9zDciRzGPOuLG9fC43zuObDzI779qY2IsPlSlJhnvfgTKLyMLXcRmS0iNSKScpiBRE0T\nkQoR2S4iH3e+mN6R7Q922Z4arNhb22c5v+tUDNhid4+dbpmnAFyT5vFrAYw1/k0CMCP3YvlXhKnt\naYX8ePhVIDdlDHdVXQ2gIc0qNwCYo1HrAJwhIqOcKqDXOP6DdegFczmhqhgUsgHJxip5gRMHVEcD\nOGq6X2ks60NEJolImYiU1db27aooJgwAKiZsfBReQUfLqOosVR2vquNLSkr6/zoOlikX+TxIdLKt\nG8cbO/L3BkQFIGzGuMaJ0TLHAJxvun+esYxycNmUZegOR3D4wYluFyVQCnF2s1caH17AFrt7nGi5\nzwNwqzFq5nIATaqa11M0vdIWyOcXt7uAE1wVAzfmI/LK95SKU8aWu4i8AOBKACNFpBLA/QAGA4Cq\nzgSwAMB1ACoAtAO4LV+FjWFbgMgf2C3jnozhrqo3Z3hcAdzpWIl8JJcvLjdQwcfPmNzE6QeyZI5z\nJ7pl2CcZPGyrkhcw3HOQy7E5pwOAp3fbw2pyB7+fhcdwzxK/o/7E1rQ7OP2AexjuOWDQUyr8XvRi\ni909DPcczFx5wO0ikIex0dqLLfjCY7jn4BjPIPUdtiTdwXovPIa7S/hdLyw3Wo78jNlid5Pvwr0r\nFEZje4/bxSCyxDwjL/DdlZh2VDa5XQRHJe+u/uzv27FqX3HPmElEufNduLu9q+tUqyz2OvuqW3Dq\n0EG4ePTpAICXyo5aP4lyxonD3ME+98LzX7gH7Ety46x1AMDZH/PMjTlO2D1DbvJdn7vbArZtISoI\nHlgtPN+FeyF2q92wZn8dSifPd7sYgcU5fKjY+C/c3S5Anry2ldc3CZqgflf7I6BtMk/zXbgHBb/r\n7ihEvbMHgryA4U79Ut/ahT8s2YtIhJspIi/yXbiv2V/ndhEIwD2v7sCjyyuwpsIfn0chuwW4uSMv\n8N1QyM6esKvvn+su99qKOtS0dPl+172zJ3qN1zA7Uy35/TMmf/NduH/hI+fgiTWH3C5Gv93yxHoA\nwIihzlZ9oTPWt5Hu24L7E7f97vFdt8yHzx3hdhGIiDzPd+Hu9jh3NkSi/Nbl4Mbnxu8Kucl34R4U\nfv/h+738+eS3DR8Fk+/Cfcgg3xWZiKjgfJeUI4YNdrsIBP+2Tguxx8G9GvIC34V7UPg1HGMYYJn5\n/TN2ktvHyooRw52KAsPFHZywzT0M9yyxNRbltXr4nzd3cVZNDxPO+VtwDPcsbT3a6HYRUip0C8lr\n7bEnbZ7YVsgWvNfqiIqLrXAXkWtEZK+IVIjI5BSPXykiTSKy1fh3n/NFDRb+8IOLbdS+2C1WeBnP\ngReRgQAeA3A1gEoAG0VknqruSlr1bVW9Pg9lJA/yW4AVMloYY+QFdlruEwBUqOpBVe0G8CKAG/Jb\nLPI6BlhmftsAUrDYCffRAI6a7lcay5J9SkS2i8hCEfmoI6UjyhJ3/4minJqacDOAMaraKiLXAXgN\nwNjklURkEoBJADBmzBiH3tqf2KrLD9X0F2Nm9LuD9V54dlruxwCcb7p/nrEsTlWbVbXVuL0AwGAR\nGZn8Qqo6S1XHq+r4kpKSHIpNXuG1jRRDxFu4I+UeO+G+EcBYEblARIYAuAnAPPMKInKuGANZRWSC\n8br1TheWvMdrv12rbhk3QsZrdeMmrzUCikHGbhlVDYnI9wEsBjAQwGxV3SkidxiPzwTwVQDfFZEQ\ngA4ANyk7PwuKtR3lZDV0hcKob+3GP5wxPKvnMcj64tez8Gz1uRtdLQuSls003Z4OYLqzRQu2oHzZ\nvRZkmTZy2WwEf/zSNszfcQIVv7kWgwbaP98vKJ8t+RvPUPUIr4WkXUEOsqW7qgH0/zqxfv1MKRgY\n7h4R5JAsJKtpGDiBFRUbX4b7xH8e5XYRyOC11imPPXgTP5fC82W43zzB/2Pkk0PRayFpF3+zlA6/\nH+7xZbgHcRc727/o9a3H0N4dyktZ/CzjAdUsajrX71nwvqX9xxl/C8+X4R6OFM/PZt62432WbTpy\nEne9uBX3v74zvuyL09fw1Ht4Y8PPHCMv8GW4h8Lu/4Bz1ZrU6rYKhB++sKXPsrau6HOrmjvjyw7W\ntiFUwI2eVwPMcvvWj6oR46/Mdpvp/2+n81SBw3VteGxFhdtFKRr+DPdIxO0i5Cw5MPIRCDXNnXm7\nuIhXA8xL5fLqBtAt33hyPR5evBe1LV1uF6Uo+DLcx513httFcFWs/zJTi/LqP67Glx57J/8F8pBM\nXVPsuXJPZ0/Y7SIUFV+Ge7ang/tBNq28eHdBhnZqU0dPDiUiIj/zZbgHUX8alH26dgrUKt1f3YL9\n1S0AvNf14GCXe+9z2drvNx7kdw/DPUAKNVLk6j+uxommTuM9vcFuV1VXKILSyfNtvSaHQpKfMdw9\nIqtuGWPlI/XtCcv93kiqqGnNfZirxdPLDp/M4SV9XrFUlBjuHpFNfMQ2BMcaO/JRlKw41S2zv7oF\nV01dhUeW7c+pHFZBfOfzm22/Vnt3CN/+6wb05Djk1mtdVm5SqO8bH37j23Bf+qPPuF2EgluxtwbV\nzZ2eSg2nfq+xMfubj/S/hQ04s/eyYk8tVu6tdfQ1iQrNt+GezfzafmAnr2/760b8++NrLR8v5hAy\nLgTmyMbGC6fK/27RHiwqr3K7GHnBbq7CCFZC+pjdr/uxxo74UEgvKERJluysQunk+ThuoxsqH6Mz\n3IiiGSsP4I5nN2X1nKb2HkxZsBs9YY+f5MdsLwiGuw9ZtSzz1SLqCUdHmDy3/kiK98y/l8sqAQDl\nx5os13FyI+OdTWd2pizYjVmrD2LBjhNuF6UP8za3iKaGchXD3SOsAqV3iF/mX0S+umXau6NnFj64\ncI/jr13T3ImmdudOtkqugiU7q+Jz8diVvPHs795AoTOs22ixe2livVQlYbdMYTDcPS6WK+Z8sdoQ\nPP3uYYvXsPdjqmnuxNSl+/qsn24Meawst87eYHv8uNmEKctw+W+XZf08K+Yy7q1qwaRnNuHnr+zI\n8lUSa7hYomjn8aa8nXQk0luPzR3FOVV1W1cIpZPnY9bqAwV5P4a7T9j5yT20aG/KKQeSf6+Ld6Y+\nUPfjl7dh2rL92JI02diA2MHKFD/82JLV+2rTvnY6HT1hHKprS7NG5r8+vgEyrdtmzLx5pKE91VMy\nvlau/NS9s2Z/HSZOW4Nn17+Xt/doaOsGADzw5s4MawZT7O+f827f7s18YLh7hHn63lTMwSpp0ieS\nYpe8uiXxtf/PM6kP1HUYEzutrahDfWvfmfvsbGCsXjuT+4y56ddU1Fmuk+7vjjMVsqbZ+BuybI0m\nv4sTjdldx5tROnk+Xt96LOO6R+rTbejy47DxnruON+fl9c11GGuAvLzxKDYebsjL+/VXR3cYNcbv\nZdnuarxXn13DwEt8G+4lI4amfXzLf19doJI442R7d8rlvS3SvstSiahCVTF1yd74sk/+dnmf9ZJb\n4ccbO7DJGGP++yX7cNOsdQmvGX1OivIB0bH3KXSFwiidPB9Prz1sXeAsqCq6QmF86N6FmL3mUEJQ\n9k6mFrVgx4n4aJNssznTRqS5swehLEekbDhUDwC468WtadcrP9aEzz68MqvXtmtHZRNaOvvu2X3v\nuU2497Vy415+umVqTNP8xqrup3O342sz383L+2XS1NGDrlC0MXPPqzviXYo3/2UdJvwm2k14+9Nl\n+MLUlX2e29DWjU1H7G+UVBUvbXwv/n6F4ttwP23oIBx+cKLl46cMHVjA0uRPqj73PSesW1eK6Bd3\n2vL0F0V44u1DCffXHqhPuL+/prVPGSIWTdg3UlwtCgD+581dAID75zm3G17b0oXuUAQPvLkLd724\nFSfbEjeKsSKaT4ZKVeyKmpaUU9BWnmzv251iHukRUYz75RL84tXyhFWON3bg+RRdGrUtXcZIo8zd\nHX8rO4rrH12TsKy6uTNlKByua8MVDy5HTYoN6//92zb86o3EOu8ORfDF6WvwnTllfdZfsKO3K62+\nNXUjAwCONrSj0aIRYuWA6XsU094dijck0jna0I4rHlxuawhstj72qyX45pMbACD+uVXUtPa5/kGq\ns5Rv/PO7+MoM+xult3bX4Gdzd+DhxXszr+wg34Z7zOCBqVtZQwf5K9zbu9Jv1c3B+t+vW4flI2/t\nx6/e2JXx/excxGNRuTGkThP+S3CiqRO/nr875fP3VrUk3FdVbDpyEhsPN+B7z21K2YUU84cle1E6\neb4x8kNMr5G4XvzqU0l97gMGmJ6TouRXTV2Nn/59Ox55az9KJ89HJKJYd7Ae//q7FfivFAEYEzYK\n8FLZUXz6oeXxkSm3zt6Ae17d0Sf8Kk9Gd+v3pwi5mM6e6B7O//v79j6PXTZlGX74whaosUcWc+Xv\nV+JYYwfe2N532GNEgb++czhh2Vu7qwEA6w6mb3Eu2VVt+dinH1qBz/9hVcKyfdUtKJ08HwdrU/99\nk1J00x2pb8dXZlifjBfzwob3cKyxA69uie6hzd1UiR2VTahIU5fZ2HAosS7svm7ss7R78Dm2t1SX\nZsOZD4MK+m558OKkT9r6onjdwbQHFO17Zl3qgzXJYW7VCje749nNOPzgxHg4dof6dkU0tPX9wnZ0\nh1NudJ9ZdyTetw4AJ2+w/rL/efVBAMj6hBxNzPqEZcnWHqjHfGNMeCiiluPDzRsH82sdbeiIh3ms\nHkIRjQe+ovdgdLLWrhA6usOoaupE+XHr8fsAsHhnNS74+QJc+eESPHXbhISNot2AMe/txco3cED2\nh3yTP+9Y8C4sr8Kdn7sw2iW4dB8mjhuFqqb0x5EyidVdJKLYerQRP/nbtvhj6fbaO3vCGDa4P427\n7LqkOnsiaGjvxugzhmP8r5fiX0rPwoxvfKIf75sfvg/3T3zgTLeLkHc94QgmTns7p9dIviKTnXCP\nMa8aa4mm85H7FuHD54zA4EGJ4bG/OrFldPNf1sFKLHeiQRQtQGtXyPbVfMz95lY7CKqKAQKEjfex\nM4ohud5umrUO+2taMfK0IfHHHzeuE7q9ssky3K+euio+bbJdsfluDphayZk+x86eMJ5ccwhdpo3k\nhN+8BRFB2b1XZXzP9u4QThmSGBMnmjpwsLYNV1w4MsX6YTy6vAKPZugWNGtq78G/z3gHM77xCXzo\nnBHx5bGRVxEF2m2eqzB3UyV+8rdtWP6Tz+KDJafFlx9v7MBVU1fh1e9dgQ+fOyLlc83fk+YUxyaS\n/fjlrVhYXoXzzhyOutZuLCyvwtNrD+NbnypFU3sPTjR34KxThuDHL29LeF6hprfwfbins/CuT+Pa\nR3ILRS84Ut+GA7XOjqBYvLN397snHME9acaCt5p+WIfr7I0e2FvdknGdfdXWu8EDjV9AKNw7m2Dy\njwQAqpo64xcOAXrbXuZG6W6LYxRhVSN8FT1prsurGu1iGnv2aX3CNLaLHp/bRhPDN9UP+aFFe7IO\ndjNzl1Om85UeX1GBacsrcPrwwfFl9Sn2tlKZv/0E7nx+My48+zScdeqQ+PLYAfpnb78MK/bUxJc/\n8MYuLNtj3a1jZeW+GhyobYtuFG6+NL48VrcRVRy3WV+LjA3CvurWhHD/wQtb0N4dxi9e3YE5t0+I\nLzfvBZmPHf1x6b747Q2HGjD+A2cm1DvQ24VVebL3mMCf3tqHb32qFF/781rL73eh5oAKdLh/ZNT7\n3C6CI+wcfOqPdyrqcMWFI7HhUEP87MZUbjC1+r/x5PqEx+wOnVt7oA670hwINrtq6iq0GWfFhiIR\nLDMFSLIvTo8egBw6KHr4KNZNYdViNotENN410dhm3VL73B9WorG9B3dfNRYfs7h+b2xjFI5owrDW\nVAdDH1+Z20ks5r9tf3UrQuEIwqopp2doMTbMHd32R2rUtHTi7BHDsGJvtN6t+qKTvwuz3zmUcr1M\nYn/Pew3tONrQjiGDBuCc9w2LP57NNNCxrsOuUBhPvH0Qt11xAQYOkPhvqOzISfzg+S3x9aeaQnxh\neeoDy//x53cx+dp/wh2f/ceE90rVJRbr8koV7IU+78FWuIvINQAeATAQwBOq+mDS42I8fh2AdgDf\nVlX7E2jnaO3kz+OMUwZjxZ5a3Pn8Zkwzbf1vnjAGL2zI34kZhfCzudmeYWnP159Yj8du+TjOPGWw\n5TqLd1al7FePmW9zHpNb/rI+80oGc5jYPZW+y/hRRyLRltb0FZm7BVR7g+UzD6+wXK/RmB7hT29Z\nh0ysUbewvAqdPb0byhkrD2YsR7bMDci5mytRMmIoDtS2pj1om80p/w8u2IOpN16CQVn0yecyoiX2\nPtuONuLTD0U/h633pR/K/MrmSqypqMMDN1yMhxb1TouxyjiZ7k9v7cehujaUjBjap+vWfJKeVTbM\nSxoB9rtFezD27NPwhY+cEz3bVlPvNTV3hiznQGrLYgPrhIzhLiIDATwG4GoAlQA2isg8VTUPybgW\nwFjj32UAZhj/F0TsgtkTx43CxHGJB1puuOQf0ob73VeNTfujDbo7n9+ML1862vLx/p6U5BQ7fZ9m\nn3l4BU4dYu9gWkTVsR9c7HceG/4ZExul4qTkWUFnrkq9J2DuTks1pO+BN3bhvi9elOoNAKBPN0Q6\ndoZ6Wvnuc33bgZc8sDTtc2JddAdq27Atxciv2BnPXT0RfDFpeGl/qEbHvR/67XUYIBIfNZVK8nDW\n3tco7EQWdoZCTgBQoaoHVbUbwIsAbkha5wYAczRqHYAzRGSUw2Xtl8s/+H786KoPxe+/ducV8dsX\njDwV149wEeU9AAAF9klEQVRLLObFo4PRlZON2IgHL7pq6uqsn2M3sJ1sSXXYPNDrhFX7rLupzC6+\nf3HacetW3Sixyzd29Xh86mAgZbCb7a5qxsmkienMe6LZjsZasKMK/RhklPBehTqgKpm2JiLyVQDX\nqOp/Gfe/CeAyVf2+aZ03ATyoqmuM+8sA/ExVLQcMjx8/XsvKrMcTO23r0Uac+75hOPf0YQhHFDUt\nnRh1+nCoKm75y3q0doVw78SP4LIPvj/heRfeswCjzhiGow3pdzuvHzcKb24/gQNTrsM/3rMgn38K\nUd6dPnxwynmKyBmp+vDtEpFNqjo+03oFPaAqIpMATAKAMWPGFPKtccn5vQfCBg4QjDp9eKxMeGHS\n5ZbPq5hyHYDoGYHnnj4MgwYIOnrC6DDG0k5dsg+3XDYGHzpnBKbfEn3OwSnX4d7Xy6GquPqiczBs\n8MB4n/PXLxsT34UdMmgAHvrKONz9Uu8p6X+88WP40UvRXc4ffP7CrIaUUdT7hg1Cc6e3Zh6ccMFZ\nfU6a6Y9ThwzEB95/qu2D05mcd+bwhNEeADD6jOE469Qh2GH0HY86fVjG0T3DBg9IONaQb05tfM4e\nMTRhaoRYfQyQ1H3q13z0XFQ1d9o6CTDZF/7pbCzbU4PLLjgLo42u5Hyy03L/JIBfquq/Gfd/DgCq\n+lvTOn8GsFJVXzDu7wVwpapaHm0rdMudiCgI7Lbc7fS5bwQwVkQuEJEhAG4CMC9pnXkAbpWoywE0\npQt2IiLKr4zdMqoaEpHvA1iM6FDI2aq6U0TuMB6fCWABosMgKxAdCnlb/opMRESZ2OpzV9UFiAa4\nedlM020FcKezRSMiov7y/ayQRETUF8OdiCiAGO5ERAHEcCciCiCGOxFRAGU8iSlvbyxSCyDz1RFS\nGwmgzsHiBBHrKDPWUWaso8wKXUcfUNWSTCu5Fu65EJEyO2doFTPWUWaso8xYR5l5tY7YLUNEFEAM\ndyKiAPJruM9yuwA+wDrKjHWUGesoM0/WkS/73ImIKD2/ttyJiCgN34W7iFwjIntFpEJEJrtdnkIS\nkdkiUiMi5aZlZ4nIUhHZb/x/pumxnxv1tFdE/s20/BMissN4bJpxgXPfE5HzRWSFiOwSkZ0icpex\nnHVkEJFhIrJBRLYZdfQrYznrKImIDBSRLcaV5vxXR6rqm3+ITjl8AMAHAQwBsA3ARW6Xq4B//2cA\nfBxAuWnZQwAmG7cnA/idcfsio36GArjAqLeBxmMbAFyO6KWQFwK41u2/zaH6GQXg48btEQD2GfXA\nOuqtIwFwmnF7MID1xt/JOupbVz8G8DyAN437vqojv7Xc7VysO7BUdTWA5Gu13QDgaeP20wC+ZFr+\noqp2qeohROfan2BcuPx9qrpOo9++Oabn+JqqnlDVzcbtFgC7AYwG6yhOo1qNu4ONfwrWUQIROQ/A\nRABPmBb7qo78Fu6jARw13a80lhWzc7T3qldVAM4xblvV1WjjdvLyQBGRUgCXItoyZR2ZGN0NWwHU\nAFiqqqyjvv4E4KcAzBeG9VUd+S3cKQ2jdVD0w59E5DQAcwHcraoJV5JmHQGqGlbVSwCch2gL8+Kk\nx4u6jkTkegA1qrrJah0/1JHfwv0YgPNN988zlhWzamP3D8b/NcZyq7o6ZtxOXh4IIjIY0WB/TlVf\nMRazjlJQ1UYAKwBcA9aR2RUA/reIHEa06/fzIvIsfFZHfgt3OxfrLjbzAHzLuP0tAK+blt8kIkNF\n5AIAYwFsMHYrm0XkcuPI/a2m5/ia8fc8CWC3qk41PcQ6MohIiYicYdweDuBqAHvAOopT1Z+r6nmq\nWopoxixX1W/Ab3Xk9hHpbP8heiHufYgekf6F2+Up8N/+AoATAHoQ7b+7HcD7ASwDsB/AWwDOMq3/\nC6Oe9sJ0lB7AeADlxmPTYZzM5vd/AP4V0V3l7QC2Gv+uYx0l1NE4AFuMOioHcJ+xnHWUur6uRO9o\nGV/VEc9QJSIKIL91yxARkQ0MdyKiAGK4ExEFEMOdiCiAGO5ERAHEcCciCiCGOxFRADHciYgC6P8D\nqy/iQK6gWcsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112e0b470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses) #trained at lr of 0.001 for 30 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1104ed208>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x127b41400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(val_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68000000000000005"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(val_scores) #0.68 - not quite as strong with the limited vocabulary, but very close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "pred_labels = []\n",
    "#get training predictions\n",
    "it = iter(dl2)\n",
    "num_batch = len(dl2) - 1\n",
    "# Loop over all batches\n",
    "for i in range(num_batch):\n",
    "    batch_x,batch_y,batch_len = next(it)\n",
    "    batch_x,batch_y,batch_len = sort_batch(batch_x,batch_y,batch_len)\n",
    "    tweets = Variable(batch_x.transpose(0,1))\n",
    "    labels = Variable(batch_y)\n",
    "    lengths = batch_len.numpy()\n",
    "    outputs = best_net(tweets, lengths)\n",
    "    _, pred = torch.max(outputs.data, 1)\n",
    "    predictions.extend(list(pred.numpy()))\n",
    "    pred_labels.extend(list(labels.data.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1071\n",
       "1      17\n",
       "dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(predictions).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1049,    9],\n",
       "       [  22,    8]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(pred_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = 'best_rnn.sav'\n",
    "pickle.dump(best_net, open(filename, \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
