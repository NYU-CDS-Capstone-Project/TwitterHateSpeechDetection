{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################\n",
    "# QN-S3VM BFGS optimizer for semi-supervised support vector machines. \n",
    "#\n",
    "# This implementation provides both a L-BFGS optimization scheme\n",
    "# for semi-supvised support vector machines. Details can be found in:\n",
    "#\n",
    "#   F. Gieseke, A. Airola, T. Pahikkala, O. Kramer, Sparse quasi-\n",
    "#   Newton optimization for semi-supervised support vector ma-\n",
    "#   chines, in: Proc. of the 1st Int. Conf. on Pattern Recognition\n",
    "#   Applications and Methods, 2012, pp. 45-54.\n",
    "#\n",
    "# Version: 0.1 (September, 2012)\n",
    "#\n",
    "# Bugs: Please send any bugs to \"f DOT gieseke AT uni-oldenburg.de\"\n",
    "#\n",
    "#\n",
    "# Copyright (C) 2012  Fabian Gieseke, Antti Airola, Tapio Pahikkala, Oliver Kramer\n",
    "#\n",
    "#    This program is free software: you can redistribute it and/or modify\n",
    "#    it under the terms of the GNU General Public License as published by\n",
    "#    the Free Software Foundation, either version 3 of the License, or\n",
    "#    (at your option) any later version.\n",
    "#\n",
    "#    This program is distributed in the hope that it will be useful,\n",
    "#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "#    GNU General Public License for more details.\n",
    "#\n",
    "#    You should have received a copy of the GNU General Public License\n",
    "#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
    "#\n",
    "# \n",
    "# INSTALLATION and DEPENDENCIES\n",
    "#\n",
    "# The module should work out of the box, given Python and Numpy (http://numpy.scipy.org/)\n",
    "# and Scipy (http://scipy.org/) installed correctly. \n",
    "# \n",
    "# We have tested the code on Ubuntu 12.04 (32 Bit) with Python 2.7.3, Numpy 1.6.1, \n",
    "# and Scipy 0.9.0. Installing these packages on a Ubuntu- or Debian-based systems \n",
    "# can be done via \"sudo apt-get install python python-numpy python-scipy\".\n",
    "#\n",
    "#\n",
    "# RUNNING THE EXAMPLES\n",
    "# \n",
    "# For a description of the data sets, see the paper mentioned above and the references \n",
    "# therein. Running the command \"python qns3vm.py\" should yield an output similar to:\n",
    "# \n",
    "# Sparse text data set instance\n",
    "# Number of labeled patterns:  48\n",
    "# Number of unlabeled patterns:  924\n",
    "# Number of test patterns:  974\n",
    "# Time needed to compute the model:  0.775886058807  seconds\n",
    "# Classification error of QN-S3VM:  0.0667351129363\n",
    "#\n",
    "# Dense gaussian data set instance\n",
    "# Number of labeled patterns:  25\n",
    "# Number of unlabeled patterns:  225\n",
    "# Number of test patterns:  250\n",
    "# Time needed to compute the model:  0.464584112167  seconds\n",
    "# Classification error of QN-S3VM:  0.012\n",
    "#\n",
    "# Dense moons data set instance\n",
    "# Number of labeled patterns:  5\n",
    "# Number of unlabeled patterns:  495\n",
    "# Number of test patterns:  500\n",
    "# Time needed to compute the model:  0.69714307785  seconds\n",
    "# Classification error of QN-S3VM:  0.0\n",
    "\n",
    "############################################################################################\n",
    "\n",
    "import array as arr\n",
    "import math\n",
    "import copy as cp\n",
    "import logging\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "import operator\n",
    "from time import time\n",
    "import sys\n",
    "from scipy import optimize\n",
    "import scipy.sparse.csc as csc\n",
    "from scipy import sparse\n",
    "import scipy\n",
    "import warnings\n",
    "warnings.simplefilter('error')\n",
    "\n",
    "__author__ =  'Fabian Gieseke, Antti Airola, Tapio Pahikkala, Oliver Kramer'\n",
    "__version__=  '0.1'\n",
    "\n",
    "class QN_S3VM:\n",
    "    \"\"\"\n",
    "    L-BFGS optimizer for semi-supervised support vector machines (S3VM).\n",
    "    \"\"\"\n",
    "    def __init__(self, X_l, L_l, X_u, random_generator = None, ** kw):\n",
    "        \"\"\"\n",
    "        Initializes the model. Detects automatically if dense or sparse data is provided.\n",
    "\n",
    "        Keyword arguments:\n",
    "        X_l -- patterns of labeled part of the data\n",
    "        L_l -- labels of labeled part of the data\n",
    "        X_u -- patterns of unlabeled part of the data\n",
    "        random_generator -- particular instance of a random_generator (default None)\n",
    "        kw -- additional parameters for the optimizer\n",
    "        lam -- regularization parameter lambda (default 1, must be a float > 0)\n",
    "        lamU -- cost parameter that determines influence of unlabeled patterns (default 1, must be float > 0)\n",
    "        sigma -- kernel width for RBF kernel (default 1.0, must be a float > 0)\n",
    "        kernel_type -- \"Linear\" or \"RBF\" (default \"Linear\")\n",
    "        numR -- implementation of subset of regressors. If None is provided, all patterns are used\n",
    "                (no approximation). Must fulfill 0 <= numR <= len(X_l) + len(X_u) (default None)\n",
    "        estimate_r -- desired ratio for positive and negative assigments for \n",
    "                      unlabeled patterns (-1.0 <= estimate_r <= 1.0). If estimate_r=None, \n",
    "                      then L_l is used to estimate this ratio (in case len(L_l) >= \n",
    "                      minimum_labeled_patterns_for_estimate_r. Otherwise use estimate_r = 0.0\n",
    "                      (default None)\n",
    "        minimum_labeled_patterns_for_estimate_r -- see above (default 0)\n",
    "        BFGS_m -- BFGS parameter (default 50)\n",
    "        BFGS_maxfun -- BFGS parameter, maximum number of function calls (default 500)\n",
    "        BFGS_factr -- BFGS parameter (default 1E12)\n",
    "        BFGS_pgtol -- BFGS parameter (default 1.0000000000000001e-05)\n",
    "        \"\"\"\n",
    "        self.__model = None\n",
    "        # Initiate model for sparse data\n",
    "        if isinstance(X_l, csc.csc_matrix):\n",
    "            self.__data_type = \"sparse\"\n",
    "            self.__model = QN_S3VM_Sparse(X_l, L_l, X_u, random_generator, ** kw)\n",
    "        # Initiate model for dense data\n",
    "        elif (isinstance(X_l[0], list)) or (isinstance(X_l[0], np.ndarray)):\n",
    "            self.__data_type = \"dense\"\n",
    "            self.__model = QN_S3VM_Dense(X_l, L_l, X_u, random_generator, ** kw)\n",
    "        # Data format unknown\n",
    "        if self.__model == None:\n",
    "            logging.info(\"Data format for patterns is unknown.\")\n",
    "            sys.exit(0)\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Training phase.\n",
    "\n",
    "        Returns:\n",
    "        The computed partition for the unlabeled patterns.\n",
    "        \"\"\"\n",
    "        return self.__model.train()\n",
    "\n",
    "    def getPredictions(self, X, real_valued=False):\n",
    "        \"\"\"\n",
    "        Computes the predicted labels for a given set of patterns\n",
    "\n",
    "        Keyword arguments:\n",
    "        X -- The set of patterns \n",
    "        real_valued -- If True, then the real prediction values are returned\n",
    "\n",
    "        Returns:\n",
    "        The predictions for the list X of patterns.\n",
    "        \"\"\"\n",
    "        return self.__model.getPredictions(X, real_valued=False)\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Predicts a label (-1 or +1) for the pattern\n",
    "\n",
    "        Keyword arguments:\n",
    "        x -- The pattern \n",
    "\n",
    "        Returns:\n",
    "        The prediction for x.\n",
    "        \"\"\"\n",
    "        return self.__model.predict(x)\n",
    "\n",
    "    def predictValue(self, x):\n",
    "        \"\"\"\n",
    "        Computes f(x) for a given pattern (see Representer Theorem)\n",
    "    \n",
    "        Keyword arguments:\n",
    "        x -- The pattern \n",
    "\n",
    "        Returns:\n",
    "        The (real) prediction value for x.\n",
    "        \"\"\"\n",
    "        return self.__model.predictValue(x)\n",
    "\n",
    "    def getNeededFunctionCalls(self):\n",
    "        \"\"\"\n",
    "        Returns the number of function calls needed during \n",
    "        the optimization process.\n",
    "        \"\"\"\n",
    "        return self.__model.getNeededFunctionCalls()\n",
    "\n",
    "############################################################################################\n",
    "############################################################################################\n",
    "class QN_S3VM_Dense:\n",
    "\n",
    "    \"\"\"\n",
    "    BFGS optimizer for semi-supervised support vector machines (S3VM).\n",
    "\n",
    "    Dense Data\n",
    "    \"\"\"\n",
    "    parameters = {\n",
    "    'lam': 1,\n",
    "    'lamU':1,\n",
    "    'sigma': 1,\n",
    "    'kernel_type': \"Linear\",\n",
    "    'numR':None,\n",
    "    'estimate_r':None,\n",
    "    'minimum_labeled_patterns_for_estimate_r':0,\n",
    "    'BFGS_m':50,\n",
    "    'BFGS_maxfun':500,\n",
    "    'BFGS_factr':1E12,\n",
    "    'BFGS_pgtol':1.0000000000000001e-05,\n",
    "    'BFGS_verbose':-1,\n",
    "    'surrogate_s':3.0,\n",
    "    'surrogate_gamma':20.0,\n",
    "    'breakpoint_for_exp':500\n",
    "    }\n",
    "\n",
    "    def __init__(self, X_l, L_l, X_u, random_generator, ** kw):\n",
    "        \"\"\"\n",
    "        Intializes the S3VM optimizer.\n",
    "        \"\"\"\n",
    "        self.__random_generator = random_generator\n",
    "        self.__X_l, self.__X_u, self.__L_l = X_l, X_u, L_l\n",
    "        assert len(X_l) == len(L_l)\n",
    "        self.__X = cp.deepcopy(self.__X_l)\n",
    "        self.__X.extend(cp.deepcopy(self.__X_u))\n",
    "        self.__size_l, self.__size_u, self.__size_n = len(X_l), len(X_u), len(X_l) + len(X_u)\n",
    "        self.__matrices_initialized = False\n",
    "        self.__setParameters( ** kw)\n",
    "        self.__kw = kw\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Training phase.\n",
    "\n",
    "        Returns:\n",
    "        The computed partition for the unlabeled patterns.\n",
    "        \"\"\"\n",
    "        indi_opt = self.__optimize()\n",
    "        self.__recomputeModel(indi_opt)\n",
    "        predictions = self.__getTrainingPredictions(self.__X)\n",
    "        return predictions\n",
    "\n",
    "    def getPredictions(self, X, real_valued=False):\n",
    "        \"\"\"\n",
    "        Computes the predicted labels for a given set of patterns\n",
    "\n",
    "        Keyword arguments:\n",
    "        X -- The set of patterns \n",
    "        real_valued -- If True, then the real prediction values are returned\n",
    "\n",
    "        Returns:\n",
    "        The predictions for the list X of patterns.\n",
    "        \"\"\"\n",
    "        KNR = self.__kernel.computeKernelMatrix(X, self.__Xreg)\n",
    "        KNU_bar = self.__kernel.computeKernelMatrix(X, self.__X_u_subset, symmetric=False)\n",
    "        KNU_bar_horizontal_sum = (1.0 / len(self.__X_u_subset)) * KNU_bar.sum(axis=1)\n",
    "        KNR = KNR - KNU_bar_horizontal_sum - self.__KU_barR_vertical_sum + self.__KU_barU_bar_sum\n",
    "        preds = KNR * self.__c[0:self.__dim-1,:] + self.__c[self.__dim-1,:]\n",
    "        if real_valued == True:\n",
    "            return preds.flatten(1).tolist()[0]\n",
    "        else:\n",
    "            return np.sign(np.sign(preds)+0.1).flatten(1).tolist()[0]\n",
    "    \n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Predicts a label for the pattern\n",
    "\n",
    "        Keyword arguments:\n",
    "        x -- The pattern \n",
    "\n",
    "        Returns:\n",
    "        The prediction for x.\n",
    "        \"\"\"\n",
    "        return self.getPredictions([x], real_valued=False)[0]\n",
    "        \n",
    "    def predictValue(self, x):\n",
    "        \"\"\"\n",
    "        Computes f(x) for a given pattern (see Representer Theorem)\n",
    "    \n",
    "        Keyword arguments:\n",
    "        x -- The pattern \n",
    "\n",
    "        Returns:\n",
    "        The (real) prediction value for x.\n",
    "        \"\"\"\n",
    "        return self.getPredictions([x], real_valued=True)[0]\n",
    "\n",
    "    def getNeededFunctionCalls(self):\n",
    "        \"\"\"\n",
    "        Returns the number of function calls needed during \n",
    "        the optimization process.\n",
    "        \"\"\"\n",
    "        return self.__needed_function_calls\n",
    "\n",
    "    def __setParameters(self,  ** kw):\n",
    "        for attr, val in kw.items():\n",
    "            self.parameters[attr] = val\n",
    "        self.__lam = float(self.parameters['lam'])\n",
    "        assert self.__lam > 0\n",
    "        self.__lamU = float(self.parameters['lamU'])\n",
    "        assert self.__lamU > 0\n",
    "        self.__lam_Uvec = [float(self.__lamU)*i for i in [0,0.000001,0.0001,0.01,0.1,0.5,1]]\n",
    "        self.__sigma = float(self.parameters['sigma'])\n",
    "        assert self.__sigma > 0\n",
    "        self.__kernel_type = str(self.parameters['kernel_type'])\n",
    "        if self.parameters['numR'] != None:\n",
    "            self.__numR = int(self.parameters['numR'])\n",
    "            assert (self.__numR <= len(self.__X)) and (self.__numR > 0)\n",
    "        else:\n",
    "            self.__numR = len(self.__X)\n",
    "        self.__regressors_indices = sorted(self.__random_generator.sample( range(0,len(self.__X)), self.__numR ))\n",
    "        self.__dim = self.__numR + 1 # add bias term b\n",
    "        self.__minimum_labeled_patterns_for_estimate_r = float(self.parameters['minimum_labeled_patterns_for_estimate_r'])\n",
    "        # If reliable estimate is available or can be estimated, use it, otherwise\n",
    "        # assume classes to be balanced (i.e., estimate_r=0.0)\n",
    "        if self.parameters['estimate_r'] != None:\n",
    "            self.__estimate_r = float(self.parameters['estimate_r'])\n",
    "        elif len(self.__L_l) >= self.__minimum_labeled_patterns_for_estimate_r:\n",
    "            self.__estimate_r = (1.0 / len(self.__L_l)) * np.sum(self.__L_l)\n",
    "        else:\n",
    "            self.__estimate_r = 0.0\n",
    "        self.__BFGS_m = int(self.parameters['BFGS_m'])\n",
    "        self.__BFGS_maxfun = int(self.parameters['BFGS_maxfun'])\n",
    "        self.__BFGS_factr = float(self.parameters['BFGS_factr'])\n",
    "        # This is a hack for 64 bit systems (Linux). The machine precision \n",
    "        # is different for the BFGS optimizer (Fortran code) and we fix this by:\n",
    "        is_64bits = sys.maxsize > 2**32\n",
    "        if is_64bits:\n",
    "            logging.debug(\"64-bit system detected, modifying BFGS_factr!\")\n",
    "            self.__BFGS_factr = 0.000488288*self.__BFGS_factr\n",
    "        self.__BFGS_pgtol = float(self.parameters['BFGS_pgtol'])\n",
    "        self.__BFGS_verbose = int(self.parameters['BFGS_verbose'])\n",
    "        self.__surrogate_gamma = float(self.parameters['surrogate_gamma'])\n",
    "        self.__s = float(self.parameters['surrogate_s'])\n",
    "        self.__breakpoint_for_exp = float(self.parameters['breakpoint_for_exp'])\n",
    "        self.__b = self.__estimate_r\n",
    "        # size of unlabeled patterns to estimate mean (used for balancing constraint)\n",
    "        self.__max_unlabeled_subset_size = 1000\n",
    "\n",
    "\n",
    "    def __optimize(self):\n",
    "        logging.debug(\"Starting optimization with BFGS ...\")\n",
    "        self.__needed_function_calls = 0\n",
    "        self.__initializeMatrices()\n",
    "        # starting point\n",
    "        c_current = zeros(self.__dim, float64)\n",
    "        c_current[self.__dim-1] = self.__b\n",
    "        # Annealing sequence.\n",
    "        for i in xrange(len(self.__lam_Uvec)):\n",
    "            self.__lamU = self.__lam_Uvec[i]\n",
    "            # crop one dimension (in case the offset b is fixed)\n",
    "            c_current = c_current[:self.__dim-1]\n",
    "            c_current = self.__localSearch(c_current)\n",
    "            # reappend it if needed\n",
    "            c_current = np.append(c_current, self.__b)\n",
    "        f_opt = self.__getFitness(c_current)\n",
    "        return c_current, f_opt\n",
    "\n",
    "    def __localSearch(self, start):\n",
    "        c_opt, f_opt, d = optimize.fmin_l_bfgs_b(self.__getFitness, start, m=self.__BFGS_m, \\\n",
    "                            fprime=self.__getFitness_Prime, maxfun=self.__BFGS_maxfun, factr=self.__BFGS_factr,\\\n",
    "                            pgtol=self.__BFGS_pgtol, iprint=self.__BFGS_verbose)\n",
    "        self.__needed_function_calls += int(d['funcalls'])\n",
    "        return c_opt\n",
    "\n",
    "    def __initializeMatrices(self):\n",
    "        if self.__matrices_initialized == False:\n",
    "            logging.debug(\"Initializing matrices...\")\n",
    "            # Initialize labels\n",
    "            x = arr.array('i')\n",
    "            for l in self.__L_l:\n",
    "                x.append(l)\n",
    "            self.__YL = mat(x, dtype=np.float64)\n",
    "            self.__YL = self.__YL.transpose()\n",
    "            # Initialize kernel matrices\n",
    "            if (self.__kernel_type == \"Linear\"):\n",
    "                self.__kernel = LinearKernel()\n",
    "            elif (self.__kernel_type == \"RBF\"):\n",
    "                self.__kernel = RBFKernel(self.__sigma)\n",
    "            self.__Xreg = (mat(self.__X)[self.__regressors_indices,:].tolist())\n",
    "            self.__KLR = self.__kernel.computeKernelMatrix(self.__X_l,self.__Xreg, symmetric=False)\n",
    "            self.__KUR = self.__kernel.computeKernelMatrix(self.__X_u,self.__Xreg, symmetric=False)\n",
    "            self.__KNR = cp.deepcopy(bmat([[self.__KLR], [self.__KUR]]))\n",
    "            self.__KRR = self.__KNR[self.__regressors_indices,:]\n",
    "            # Center patterns in feature space (with respect to approximated mean of unlabeled patterns in the feature space)\n",
    "            subset_unlabled_indices = sorted(self.__random_generator.sample( range(0,len(self.__X_u)), min(self.__max_unlabeled_subset_size, len(self.__X_u)) ))\n",
    "            self.__X_u_subset = (mat(self.__X_u)[subset_unlabled_indices,:].tolist())\n",
    "            self.__KNU_bar = self.__kernel.computeKernelMatrix(self.__X, self.__X_u_subset, symmetric=False)\n",
    "            self.__KNU_bar_horizontal_sum = (1.0 / len(self.__X_u_subset)) * self.__KNU_bar.sum(axis=1)\n",
    "            self.__KU_barR = self.__kernel.computeKernelMatrix(self.__X_u_subset, self.__Xreg, symmetric=False)\n",
    "            self.__KU_barR_vertical_sum = (1.0 / len(self.__X_u_subset)) * self.__KU_barR.sum(axis=0)\n",
    "            self.__KU_barU_bar = self.__kernel.computeKernelMatrix(self.__X_u_subset, self.__X_u_subset, symmetric=False)\n",
    "            self.__KU_barU_bar_sum = (1.0 / (len(self.__X_u_subset)))**2 * self.__KU_barU_bar.sum()\n",
    "            self.__KNR = self.__KNR - self.__KNU_bar_horizontal_sum - self.__KU_barR_vertical_sum + self.__KU_barU_bar_sum\n",
    "            self.__KRR = self.__KNR[self.__regressors_indices,:]\n",
    "            self.__KLR = self.__KNR[range(0,len(self.__X_l)),:]\n",
    "            self.__KUR = self.__KNR[range(len(self.__X_l),len(self.__X)),:]\n",
    "            self.__matrices_initialized = True\n",
    "\n",
    "    def __getFitness(self,c):\n",
    "        # Check whether the function is called from the bfgs solver \n",
    "        # (that does not optimize the offset b) or not\n",
    "        if len(c) == self.__dim - 1:\n",
    "            c = np.append(c, self.__b)\n",
    "        c = mat(c)\n",
    "        b = c[:,self.__dim-1].T\n",
    "        c_new = c[:,0:self.__dim-1].T\n",
    "        preds_labeled = self.__surrogate_gamma*(1.0 - multiply(self.__YL, self.__KLR * c_new + b))\n",
    "        preds_unlabeled = self.__KUR * c_new + b\n",
    "        # This vector has a \"one\" for each \"numerically instable\" entry; \"zeros\" for \"good ones\". \n",
    "        preds_labeled_conflict_indicator = np.sign(np.sign(preds_labeled/self.__breakpoint_for_exp - 1.0) + 1.0)\n",
    "        # This vector has a one for each good entry and zero otherwise\n",
    "        preds_labeled_good_indicator = (-1)*(preds_labeled_conflict_indicator - 1.0)\n",
    "        preds_labeled_for_conflicts = multiply(preds_labeled_conflict_indicator,preds_labeled) \n",
    "        preds_labeled = multiply(preds_labeled,preds_labeled_good_indicator)\n",
    "        # Compute values for good entries\n",
    "        preds_labeled_log_exp = np.log(1.0 + np.exp(preds_labeled))\n",
    "        # Compute values for instable entries\n",
    "        preds_labeled_log_exp = multiply(preds_labeled_good_indicator, preds_labeled_log_exp)\n",
    "        # Replace critical values with values \n",
    "        preds_labeled_final = preds_labeled_log_exp + preds_labeled_for_conflicts\n",
    "        term1 = (1.0/(self.__surrogate_gamma*self.__size_l)) * np.sum(preds_labeled_final)\n",
    "        preds_unlabeled_squared = multiply(preds_unlabeled,preds_unlabeled)\n",
    "        term2 = (float(self.__lamU)/float(self.__size_u))*np.sum(np.exp(-self.__s * preds_unlabeled_squared))\n",
    "        term3 = self.__lam * (c_new.T * self.__KRR * c_new)\n",
    "        return (term1 + term2 + term3)[0,0]\n",
    "\n",
    "    def __getFitness_Prime(self,c):\n",
    "        # Check whether the function is called from the bfgs solver \n",
    "        # (that does not optimize the offset b) or not\n",
    "        if len(c) == self.__dim - 1:\n",
    "            c = np.append(c, self.__b)\n",
    "        c = mat(c)\n",
    "        b = c[:,self.__dim-1].T\n",
    "        c_new = c[:,0:self.__dim-1].T\n",
    "        preds_labeled = self.__surrogate_gamma * (1.0 - multiply(self.__YL, self.__KLR * c_new + b))\n",
    "        preds_unlabeled = (self.__KUR * c_new + b)\n",
    "        # This vector has a \"one\" for each \"numerically instable\" entry; \"zeros\" for \"good ones\". \n",
    "        preds_labeled_conflict_indicator = np.sign(np.sign(preds_labeled/self.__breakpoint_for_exp - 1.0) + 1.0)\n",
    "        # This vector has a one for each good entry and zero otherwise\n",
    "        preds_labeled_good_indicator = (-1)*(preds_labeled_conflict_indicator - 1.0)\n",
    "        preds_labeled = multiply(preds_labeled,preds_labeled_good_indicator)\n",
    "        preds_labeled_exp = np.exp(preds_labeled)\n",
    "        term1 = multiply(preds_labeled_exp, 1.0/(1.0 + preds_labeled_exp))\n",
    "        term1 = multiply(preds_labeled_good_indicator, term1)\n",
    "        # Replace critical values with \"1.0\"\n",
    "        term1 = term1 + preds_labeled_conflict_indicator\n",
    "        term1 = multiply(self.__YL, term1)\n",
    "        preds_unlabeled_squared_exp_f = multiply(preds_unlabeled,preds_unlabeled)\n",
    "        preds_unlabeled_squared_exp_f = np.exp(-self.__s * preds_unlabeled_squared_exp_f)\n",
    "        preds_unlabeled_squared_exp_f = multiply(preds_unlabeled_squared_exp_f, preds_unlabeled)\n",
    "        term1 = (-1.0/self.__size_l) * (term1.T * self.__KLR).T\n",
    "        term2 = ((-2.0 * self.__s * self.__lamU)/float(self.__size_u)) * (preds_unlabeled_squared_exp_f.T * self.__KUR).T\n",
    "        term3 = 2*self.__lam*(self.__KRR * c_new)\n",
    "        return array((term1 + term2 + term3).T)[0]\n",
    "\n",
    "    def __recomputeModel(self, indi):\n",
    "        self.__c = mat(indi[0]).T\n",
    "\n",
    "    def __getTrainingPredictions(self, X, real_valued=False):\n",
    "        preds = self.__KNR * self.__c[0:self.__dim-1,:] + self.__c[self.__dim-1,:]\n",
    "        if real_valued == True:\n",
    "            return preds.flatten('F').tolist()[0]\n",
    "        else:\n",
    "            return np.sign(np.sign(preds)+0.1).flatten('F').tolist()[0]\n",
    "\n",
    "    def __check_matrix(self, M):\n",
    "        smallesteval = scipy.linalg.eigvalsh(M, eigvals=(0,0))[0]\n",
    "        if smallesteval < 0.0:\n",
    "            shift = abs(smallesteval) + 0.0000001 \n",
    "            M = M + shift\n",
    "        return M\n",
    "\n",
    "############################################################################################\n",
    "############################################################################################\n",
    "class QN_S3VM_Sparse:\n",
    "    \"\"\"\n",
    "    BFGS optimizer for semi-supervised support vector machines (S3VM).\n",
    "\n",
    "    Sparse Data\n",
    "    \"\"\"\n",
    "    parameters = {\n",
    "    'lam': 1,\n",
    "    'lamU':1,\n",
    "    'estimate_r':None,\n",
    "    'minimum_labeled_patterns_for_estimate_r':0,\n",
    "    'BFGS_m':50,\n",
    "    'BFGS_maxfun':500,\n",
    "    'BFGS_factr':1E12,\n",
    "    'BFGS_pgtol':1.0000000000000001e-05,\n",
    "    'BFGS_verbose':-1,\n",
    "    'surrogate_s':3.0,\n",
    "    'surrogate_gamma':20.0,\n",
    "    'breakpoint_for_exp':500\n",
    "    }\n",
    "\n",
    "\n",
    "    def __init__(self, X_l, L_l, X_u, random_generator, ** kw):\n",
    "        \"\"\"\n",
    "        Intializes the S3VM optimizer.\n",
    "        \"\"\"\n",
    "        self.__random_generator = random_generator\n",
    "        # This is a nuisance, but we may need to pad extra dimensions to either X_l or X_u\n",
    "        # in case the highest feature indices appear only in one of the two data matrices\n",
    "        if X_l.shape[1] > X_u.shape[1]:\n",
    "            X_u = sparse.hstack([X_u, sparse.coo_matrix(X_u.shape[0], X_l.shape[1] - X_u.shape[1])])\n",
    "        elif X_l.shape[1] < X_u.shape[1]:\n",
    "            X_l = sparse.hstack([X_l, sparse.coo_matrix(X_l.shape[0], X_u.shape[1] - X_u.shape[1])])\n",
    "        # We vertically stack the data matrices into one big matrix\n",
    "        X = sparse.vstack([X_l, X_u])\n",
    "        self.__size_l, self.__size_u, self.__size_n = X_l.shape[0], X_u.shape[0], X_l.shape[0]+ X_u.shape[0]\n",
    "        x = arr.array('i')\n",
    "        for l in L_l:\n",
    "            x.append(int(l))\n",
    "        self.__YL = mat(x, dtype=np.float64)\n",
    "        self.__YL = self.__YL.transpose()\n",
    "        self.__setParameters( ** kw)\n",
    "        self.__kw = kw\n",
    "        self.X_l = X_l.tocsr()\n",
    "        self.X_u = X_u.tocsr()\n",
    "        self.X = X.tocsr()\n",
    "        # compute mean of unlabeled patterns\n",
    "        self.__mean_u = self.X_u.mean(axis=0)\n",
    "        self.X_u_T = X_u.tocsc().T\n",
    "        self.X_l_T = X_l.tocsc().T\n",
    "        self.X_T = X.tocsc().T\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Training phase.\n",
    "\n",
    "        Returns:\n",
    "        The computed partition for the unlabeled patterns.\n",
    "        \"\"\"\n",
    "        indi_opt = self.__optimize()\n",
    "        self.__recomputeModel(indi_opt)\n",
    "        predictions = self.getPredictions(self.X)\n",
    "        return predictions\n",
    "\n",
    "    def getPredictions(self, X, real_valued=False):\n",
    "        \"\"\"\n",
    "        Computes the predicted labels for a given set of patterns\n",
    "\n",
    "        Keyword arguments:\n",
    "        X -- The set of patterns \n",
    "        real_valued -- If True, then the real prediction values are returned\n",
    "\n",
    "        Returns:\n",
    "        The predictions for the list X of patterns.\n",
    "        \"\"\"\n",
    "        c_new = self.__c[:self.__dim-1]\n",
    "        W = self.X.T*c_new - self.__mean_u.T*np.sum(c_new)\n",
    "        # Again, possibility of dimension mismatch due to use of sparse matrices\n",
    "        if X.shape[1] > W.shape[0]:\n",
    "            X = X[:,range(W.shape[0])]\n",
    "        if X.shape[1] < W.shape[0]:\n",
    "            W = W[range(X.shape[1])]\n",
    "        X = X.tocsc()\n",
    "        preds = X * W + self.__b\n",
    "        if real_valued == True:\n",
    "            return preds.flatten(1).tolist()[0]\n",
    "        else:\n",
    "            return np.sign(np.sign(preds)+0.1).flatten(1).tolist()[0]\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Predicts a label for the pattern\n",
    "\n",
    "        Keyword arguments:\n",
    "        x -- The pattern \n",
    "\n",
    "        Returns:\n",
    "        The prediction for x.\n",
    "        \"\"\"\n",
    "        return self.getPredictions([x], real_valued=False)[0]\n",
    "        \n",
    "    def predictValue(self, x):\n",
    "        \"\"\"\n",
    "        Computes f(x) for a given pattern (see Representer Theorem)\n",
    "    \n",
    "        Keyword arguments:\n",
    "        x -- The pattern \n",
    "\n",
    "        Returns:\n",
    "        The (real) prediction value for x.\n",
    "        \"\"\"\n",
    "        return self.getPredictions([x], real_valued=True)[0]\n",
    "\n",
    "    def getNeededFunctionCalls(self):\n",
    "        \"\"\"\n",
    "        Returns the number of function calls needed during \n",
    "        the optimization process.\n",
    "        \"\"\"\n",
    "        return self.__needed_function_calls\n",
    "\n",
    "    def __setParameters(self,  ** kw):\n",
    "        for attr, val in kw.items():\n",
    "            self.parameters[attr] = val\n",
    "        self.__lam = float(self.parameters['lam'])\n",
    "        assert self.__lam > 0\n",
    "        self.__lamU = float(self.parameters['lamU'])\n",
    "        assert self.__lamU > 0\n",
    "        self.__lam_Uvec = [float(self.__lamU)*i for i in [0,0.000001,0.0001,0.01,0.1,0.5,1]]\n",
    "        self.__minimum_labeled_patterns_for_estimate_r = float(self.parameters['minimum_labeled_patterns_for_estimate_r'])\n",
    "        # If reliable estimate is available or can be estimated, use it, otherwise\n",
    "        # assume classes to be balanced (i.e., estimate_r=0.0)\n",
    "        if self.parameters['estimate_r'] != None:\n",
    "            self.__estimate_r = float(self.parameters['estimate_r'])\n",
    "        elif self.__YL.shape[0] > self.__minimum_labeled_patterns_for_estimate_r:\n",
    "            self.__estimate_r = (1.0 / self.__YL.shape[0]) * np.sum(self.__YL[0:])\n",
    "        else:\n",
    "            self.__estimate_r = 0.0\n",
    "        self.__dim = self.__size_n + 1 # for offset term b\n",
    "        self.__BFGS_m = int(self.parameters['BFGS_m'])\n",
    "        self.__BFGS_maxfun = int(self.parameters['BFGS_maxfun'])\n",
    "        self.__BFGS_factr = float(self.parameters['BFGS_factr'])\n",
    "        # This is a hack for 64 bit systems (Linux). The machine precision \n",
    "        # is different for the BFGS optimizer (Fortran code) and we fix this by:\n",
    "        is_64bits = sys.maxsize > 2**32\n",
    "        if is_64bits:\n",
    "            logging.debug(\"64-bit system detected, modifying BFGS_factr!\")\n",
    "            self.__BFGS_factr = 0.000488288*self.__BFGS_factr\n",
    "        self.__BFGS_pgtol = float(self.parameters['BFGS_pgtol'])\n",
    "        self.__BFGS_verbose = int(self.parameters['BFGS_verbose'])\n",
    "        self.__surrogate_gamma = float(self.parameters['surrogate_gamma'])\n",
    "        self.__s = float(self.parameters['surrogate_s'])\n",
    "        self.__breakpoint_for_exp = float(self.parameters['breakpoint_for_exp'])\n",
    "        self.__b = self.__estimate_r\n",
    "\n",
    "    def __optimize(self):\n",
    "        logging.debug(\"Starting optimization with BFGS ...\")\n",
    "        self.__needed_function_calls = 0\n",
    "        # starting_point\n",
    "        c_current = zeros(self.__dim, float64)\n",
    "        c_current[self.__dim-1] = self.__b\n",
    "        # Annealing sequence.\n",
    "        for i in xrange(len(self.__lam_Uvec)):\n",
    "            self.__lamU = self.__lam_Uvec[i]\n",
    "            # crop one dimension (in case the offset b is fixed)\n",
    "            c_current = c_current[:self.__dim-1]\n",
    "            c_current = self.__localSearch(c_current)\n",
    "            # reappend it if needed\n",
    "            c_current = np.append(c_current, self.__b)\n",
    "        f_opt = self.__getFitness(c_current)\n",
    "        return c_current, f_opt\n",
    "\n",
    "    def __localSearch(self, start):\n",
    "        c_opt, f_opt, d = optimize.fmin_l_bfgs_b(self.__getFitness, start, m=self.__BFGS_m, \\\n",
    "                                     fprime=self.__getFitness_Prime, maxfun=self.__BFGS_maxfun,\\\n",
    "                                     factr=self.__BFGS_factr, pgtol=self.__BFGS_pgtol, iprint=self.__BFGS_verbose)\n",
    "        self.__needed_function_calls += int(d['funcalls'])\n",
    "        return c_opt\n",
    "\n",
    "    def __getFitness(self,c):\n",
    "        # check whether the function is called from the bfgs solver \n",
    "        # (that does not optimize the offset b) or not\n",
    "        if len(c) == self.__dim - 1:\n",
    "            c = np.append(c, self.__b)\n",
    "        c = mat(c)\n",
    "        b = c[:,self.__dim-1].T\n",
    "        c_new = c[:,0:self.__dim-1].T\n",
    "        c_new_sum = np.sum(c_new)\n",
    "        XTc = self.X_T*c_new - self.__mean_u.T*c_new_sum\n",
    "        preds_labeled = self.__surrogate_gamma*(1.0 - multiply(self.__YL, (self.X_l*XTc - self.__mean_u*XTc) + b[0,0]))\n",
    "        preds_unlabeled = (self.X_u*XTc - self.__mean_u*XTc)  + b[0,0]\n",
    "        # This vector has a \"one\" for each \"numerically instable\" entry; \"zeros\" for \"good ones\". \n",
    "        preds_labeled_conflict_indicator = np.sign(np.sign(preds_labeled/self.__breakpoint_for_exp - 1.0) + 1.0)\n",
    "        # This vector has a one for each good entry and zero otherwise\n",
    "        preds_labeled_good_indicator = (-1)*(preds_labeled_conflict_indicator - 1.0)\n",
    "        preds_labeled_for_conflicts = multiply(preds_labeled_conflict_indicator,preds_labeled) \n",
    "        preds_labeled = multiply(preds_labeled,preds_labeled_good_indicator)\n",
    "        # Compute values for good entries\n",
    "        preds_labeled_log_exp = np.log(1.0 + np.exp(preds_labeled))\n",
    "        # Compute values for instable entries\n",
    "        preds_labeled_log_exp = multiply(preds_labeled_good_indicator, preds_labeled_log_exp)\n",
    "        # Replace critical values with values \n",
    "        preds_labeled_final = preds_labeled_log_exp + preds_labeled_for_conflicts\n",
    "        term1 = (1.0/(self.__surrogate_gamma*self.__size_l)) * np.sum(preds_labeled_final)\n",
    "        preds_unlabeled_squared = multiply(preds_unlabeled,preds_unlabeled)\n",
    "        term2 = (float(self.__lamU)/float(self.__size_u))*np.sum(np.exp(-self.__s * preds_unlabeled_squared))\n",
    "        term3 = self.__lam * c_new.T * (self.X * XTc - self.__mean_u*XTc)\n",
    "        return (term1 + term2 + term3)[0,0]\n",
    "\n",
    "    def __getFitness_Prime(self,c):\n",
    "        # check whether the function is called from the bfgs solver \n",
    "        # (that does not optimize the offset b) or not\n",
    "        if len(c) == self.__dim - 1:\n",
    "            c = np.append(c, self.__b)\n",
    "        c = mat(c)\n",
    "        b = c[:,self.__dim-1].T\n",
    "        c_new = c[:,0:self.__dim-1].T\n",
    "        c_new_sum = np.sum(c_new)\n",
    "        XTc = self.X_T*c_new - self.__mean_u.T*c_new_sum\n",
    "        preds_labeled = self.__surrogate_gamma*(1.0 - multiply(self.__YL, (self.X_l*XTc -self.__mean_u*XTc) + b[0,0]))\n",
    "        preds_unlabeled = (self.X_u*XTc - self.__mean_u*XTc )+ b[0,0]\n",
    "        preds_labeled_conflict_indicator = np.sign(np.sign(preds_labeled/self.__breakpoint_for_exp - 1.0) + 1.0)\n",
    "        # This vector has a one for each good entry and zero otherwise\n",
    "        preds_labeled_good_indicator = (-1)*(preds_labeled_conflict_indicator - 1.0)\n",
    "        preds_labeled = multiply(preds_labeled,preds_labeled_good_indicator)\n",
    "        preds_labeled_exp = np.exp(preds_labeled)\n",
    "        term1 = multiply(preds_labeled_exp, 1.0/(1.0 + preds_labeled_exp))\n",
    "        term1 = multiply(preds_labeled_good_indicator, term1)\n",
    "        # Replace critical values with \"1.0\"\n",
    "        term1 = term1 + preds_labeled_conflict_indicator\n",
    "        term1 = multiply(self.__YL, term1)\n",
    "        preds_unlabeled_squared_exp_f = multiply(preds_unlabeled,preds_unlabeled)\n",
    "        preds_unlabeled_squared_exp_f = np.exp(-self.__s * preds_unlabeled_squared_exp_f)\n",
    "        preds_unlabeled_squared_exp_f = multiply(preds_unlabeled_squared_exp_f, preds_unlabeled)\n",
    "        term1_sum = np.sum(term1)\n",
    "        tmp = self.X_l_T * term1 - self.__mean_u.T*term1_sum\n",
    "        term1 = (-1.0/self.__size_l) * (self.X * tmp - self.__mean_u*tmp)\n",
    "        preds_unlabeled_squared_exp_f_sum = np.sum(preds_unlabeled_squared_exp_f)\n",
    "        tmp_unlabeled = self.X_u_T * preds_unlabeled_squared_exp_f - self.__mean_u.T * preds_unlabeled_squared_exp_f_sum\n",
    "        term2 = ((-2.0 * self.__s * self.__lamU)/float(self.__size_u)) * (self.X * tmp_unlabeled - self.__mean_u*tmp_unlabeled)\n",
    "        XTc_sum = np.sum(XTc)\n",
    "        term3 = 2*self.__lam*(self.X * XTc - self.__mean_u*XTc)\n",
    "        return array((term1 + term2 + term3).T)[0]\n",
    "\n",
    "    def __recomputeModel(self, indi):\n",
    "        self.__c = mat(indi[0]).T\n",
    "\n",
    "############################################################################################\n",
    "############################################################################################\n",
    "class LinearKernel():\n",
    "    \"\"\"\n",
    "    Linear Kernel\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def computeKernelMatrix(self, data1, data2, symmetric=False):\n",
    "        \"\"\"\n",
    "        Computes the kernel matrix\n",
    "        \"\"\"\n",
    "        logging.debug(\"Starting Linear Kernel Matrix Computation...\")\n",
    "        self._data1 = mat(data1)\n",
    "        self._data2 = mat(data2)\n",
    "        assert self._data1.shape[1] == (self._data2.T).shape[0]\n",
    "        try:\n",
    "            return self._data1 * self._data2.T\n",
    "        except Exception, e:\n",
    "            logging.error(\"Error while computing kernel matrix: \" + str(e))\n",
    "            sys.exit()\n",
    "        logging.debug(\"Kernel Matrix computed...\")\n",
    "\n",
    "    def getKernelValue(self, xi, xj):\n",
    "        \"\"\"\n",
    "        Returns a single kernel value.\n",
    "        \"\"\"\n",
    "        xi = array(xi)\n",
    "        xj = array(xj)\n",
    "        val = dot(xi, xj)\n",
    "        return val\n",
    "\n",
    "\n",
    "class DictLinearKernel():\n",
    "    \"\"\"\n",
    "    Linear Kernel (for dictionaries)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def computeKernelMatrix(self, data1, data2, symmetric=False):\n",
    "        \"\"\"\n",
    "        Computes the kernel matrix\n",
    "        \"\"\"\n",
    "        logging.debug(\"Starting Linear Kernel Matrix Computation...\")\n",
    "        self._data1 = data1\n",
    "        self._data2 = data2\n",
    "        self._dim1 = len(data1)\n",
    "        self._dim2 = len(data2)\n",
    "        self._symmetric = symmetric\n",
    "        self.__km = None\n",
    "        try:\n",
    "            km = mat(zeros((self._dim1, self._dim2), dtype=float64))\n",
    "            if self._symmetric:\n",
    "                for i in xrange(self._dim1):\n",
    "                    message = 'Kernel Matrix Progress: %dx%d/%dx%d' % (i, self._dim2,self._dim1,self._dim2)\n",
    "                    logging.debug(message)\n",
    "                    for j in xrange(i, self._dim2):\n",
    "                        val = self.getKernelValue(self._data1[i], self._data2[j])\n",
    "                        km[i, j] = val\n",
    "                        km[j, i] = val\n",
    "                return km\n",
    "            else:\n",
    "                for i in xrange(self._dim1):\n",
    "                    message = 'Kernel Matrix Progress: %dx%d/%dx%d' % (i, self._dim2,self._dim1,self._dim2)\n",
    "                    logging.debug(message)\n",
    "                    for j in xrange(0, self._dim2):\n",
    "                        val = self.getKernelValue(self._data1[i], self._data2[j])\n",
    "                        km[i, j] = val\n",
    "                return km\n",
    "            \n",
    "        except Exception, e:\n",
    "            logging.error(\"Error while computing kernel matrix: \" + str(e))\n",
    "            sys.exit()\n",
    "        logging.debug(\"Kernel Matrix computed...\")\n",
    "\n",
    "    def getKernelValue(self, xi, xj):\n",
    "        \"\"\"\n",
    "        Returns a single kernel value.\n",
    "        \"\"\"\n",
    "        val = 0.\n",
    "        for key in xi:\n",
    "            if key in xj:\n",
    "                val += xi[key]*xj[key]\n",
    "        return val\n",
    "\n",
    "class RBFKernel():\n",
    "    \"\"\"\n",
    "    RBF Kernel\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma):\n",
    "        self.__sigma = sigma\n",
    "        self.__sigma_squared_inv = 1.0 / (2* (self.__sigma ** 2) )\n",
    "\n",
    "    def computeKernelMatrix(self, data1, data2, symmetric=False):\n",
    "        \"\"\"\n",
    "        Computes the kernel matrix\n",
    "        \"\"\"\n",
    "        logging.debug(\"Starting RBF Kernel Matrix Computation...\")\n",
    "        self._data1 = mat(data1)\n",
    "        self._data2 = mat(data2)\n",
    "        assert self._data1.shape[1] == (self._data2.T).shape[0]\n",
    "        self._dim1 = len(data1)\n",
    "        self._dim2 = len(data2)\n",
    "        self._symmetric = symmetric\n",
    "        self.__km = None\n",
    "        try:\n",
    "            if self._symmetric:\n",
    "                linearkm = self._data1 * self._data2.T\n",
    "                trnorms = mat(np.diag(linearkm)).T\n",
    "                trace_matrix = trnorms * mat(np.ones((1, self._dim1), dtype = float64))\n",
    "                self.__km = trace_matrix + trace_matrix.T\n",
    "                self.__km = self.__km - 2*linearkm\n",
    "                self.__km = - self.__sigma_squared_inv * self.__km\n",
    "                self.__km = np.exp(self.__km)\n",
    "                return self.__km   \n",
    "            else:\n",
    "                m = self._data1.shape[0]\n",
    "                n = self._data2.shape[0]\n",
    "                assert self._data1.shape[1] == self._data2.shape[1]\n",
    "                linkm = mat(self._data1 * self._data2.T)\n",
    "                trnorms1 = []\n",
    "                for i in xrange(m):\n",
    "                    trnorms1.append((self._data1[i] * self._data1[i].T)[0,0])\n",
    "                trnorms1 = mat(trnorms1).T\n",
    "                trnorms2 = []\n",
    "                for i in xrange(n):\n",
    "                    trnorms2.append((self._data2[i] * self._data2[i].T)[0,0])\n",
    "                trnorms2 = mat(trnorms2).T\n",
    "                self.__km = trnorms1 * mat(np.ones((n, 1), dtype = float64)).T\n",
    "                self.__km = self.__km + mat(np.ones((m, 1), dtype = float64)) * trnorms2.T\n",
    "                self.__km = self.__km - 2 * linkm\n",
    "                self.__km = - self.__sigma_squared_inv * self.__km\n",
    "                self.__km = np.exp(self.__km)\n",
    "                return self.__km\n",
    "        except Exception, e:\n",
    "            logging.error(\"Error while computing kernel matrix: \" + str(e))\n",
    "            sys.exit()\n",
    "\n",
    "    def getKernelValue(self, xi, xj):\n",
    "        \"\"\"\n",
    "        Returns a single kernel value.\n",
    "        \"\"\"\n",
    "        xi = array(xi)\n",
    "        xj = array(xj)\n",
    "        diff = xi-xj\n",
    "        val = exp(-self.__sigma_squared_inv * (dot(diff, diff)))\n",
    "        return val\n",
    "\n",
    "class DictRBFKernel():\n",
    "    \"\"\"\n",
    "    RBF Kernel (for dictionaries)\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma):\n",
    "        self.__sigma = sigma\n",
    "        self.__sigma_squared_inv = 1.0 / ((self.__sigma ** 2))\n",
    "\n",
    "    def computeKernelMatrix(self, data1, data2, symmetric=False):\n",
    "        \"\"\"\n",
    "        Computes the kernel matrix\n",
    "        \"\"\"\n",
    "        logging.debug(\"Starting RBF Kernel Matrix Computation...\")\n",
    "        self._data1 = data1\n",
    "        self._data2 = data2\n",
    "        self._dim1 = len(data1)\n",
    "        self._dim2 = len(data2)\n",
    "        self._symmetric = symmetric\n",
    "        self.__km = None\n",
    "        try:\n",
    "            km = mat(zeros((self._dim1, self._dim2), dtype=float64))\n",
    "            if self._symmetric:\n",
    "                for i in xrange(self._dim1):\n",
    "                    message = 'Kernel Matrix Progress: %dx%d/%dx%d' % (i, self._dim2,self._dim1,self._dim2)\n",
    "                    logging.debug(message)\n",
    "                    for j in xrange(i, self._dim2):\n",
    "                        val = self.getKernelValue(self._data1[i], self._data2[j])\n",
    "                        km[i, j] = val\n",
    "                        km[j, i] = val\n",
    "                return km\n",
    "            else:\n",
    "                for i in xrange(0, self._dim1):\n",
    "                    message = 'Kernel Matrix Progress: %dx%d/%dx%d' % (i, self._dim2,self._dim1,self._dim2)\n",
    "                    logging.debug(message)\n",
    "                    for j in xrange(0, self._dim2):\n",
    "                        val = self.getKernelValue(self._data1[i], self._data2[j])\n",
    "                        km[i, j] = val\n",
    "                return km\n",
    "        except Exception, e:\n",
    "            logging.error(\"Error while computing kernel matrix: \" + str(e))\n",
    "            sys.exit()\n",
    "        logging.info(\"Kernel Matrix computed...\")\n",
    "\n",
    "    def getKernelValue(self, xi, xj):\n",
    "        \"\"\"\n",
    "        Returns a single kernel value.\n",
    "        \"\"\"\n",
    "        diff = xi.copy()\n",
    "        for key in xj:\n",
    "            if key in diff:\n",
    "                diff[key]-=xj[key]\n",
    "            else:\n",
    "                diff[key]=-xj[key]\n",
    "        diff = diff.values()\n",
    "        val = exp(-self.__sigma_squared_inv * (dot(diff, diff)))\n",
    "        return val\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data\n",
    "clean_data = pd.read_csv(\"/Volumes/Samsung USB/Fall 2018/twitterdata/data/clean_data.csv\")\n",
    "train_index = pd.read_csv(\"/Volumes/Samsung USB/Fall 2018/twitterdata/data/train_index.csv\")\n",
    "test_index = pd.read_csv(\"/Volumes/Samsung USB/Fall 2018/twitterdata/data/test_index.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of samples in x_train is 3,999\n",
      "The number of samples in x_val is 1,001\n"
     ]
    }
   ],
   "source": [
    "# Data Check\n",
    "train = clean_data[clean_data.ID.isin(train_index['ID'].tolist())]\n",
    "test =  clean_data[clean_data.ID.isin(test_index['ID'].tolist())]\n",
    "\n",
    "print(\"The number of samples in x_train is {:,d}\".format(len(train)))\n",
    "print(\"The number of samples in x_val is {:,d}\".format(len(test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quality Check \n",
    "train.loc[train['clean_tweet'].isnull(), 'Tweet']\n",
    "train = train.loc[train['clean_tweet'].isnull() == False, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Feature Matrix based on Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 5),\n",
    "                        stop_words='english')\n",
    "train = train.loc[train['clean_tweet'].isnull() == False, :]\n",
    "features = tfidf.fit_transform(train['clean_tweet']).toarray()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Create Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['CAPS', 'Obscenity', 'Threat', 'hatespeech', 'namecalling', 'negprejudice', 'noneng', 'porn', 'stereotypes']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in labels:\n",
    "    cols = [label + str(x) for x in range(1,8)]\n",
    "    train[label + '_num_yes'] = train[cols].sum(axis = 1)\n",
    "    train[label] = train[label + '_num_yes'] >= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CAPS            0.015535\n",
       "Obscenity       0.052368\n",
       "Threat          0.037835\n",
       "hatespeech      0.024806\n",
       "namecalling     0.083939\n",
       "negprejudice    0.167878\n",
       "noneng          0.081934\n",
       "porn            0.007517\n",
       "stereotypes     0.093961\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[labels].sum(axis = 0)/train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Performance on Different Labels Using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.104986218993\n"
     ]
    }
   ],
   "source": [
    "x=features\n",
    "unlabeled = 500\n",
    "\n",
    "\n",
    "Y= train['CAPS'].values*1\n",
    "Y[Y==0]= -1\n",
    "\n",
    "\n",
    "label_idx = np.random.randint(x.shape[0], size=x.shape[0]-unlabeled)\n",
    "unlabled_idx = np.random.randint(x.shape[0], size=unlabeled)\n",
    "label, unlabedled = x[label_idx,:], x[unlabled_idx,:]\n",
    "\n",
    "Y_label=Y[label_idx]\n",
    "\n",
    "import random as rnd\n",
    "model=QN_S3VM(label.tolist(),Y_label.tolist(),unlabedled.tolist(),rnd.Random(),lam=0.0009765625,kernel_type=\"RBF\",estimate_r=0.0, sigma=.50)\n",
    "predictions= model.train()\n",
    "def classification_error(preds,L_test):\n",
    "    error = 0.0\n",
    "    for i in xrange(len(preds)):\n",
    "        error += float(abs(int(preds[i])-int(L_test[i]))) / 2.0\n",
    "    error /= len(preds)    \n",
    "    return error\n",
    "\n",
    "model_error=classification_error(predictions,Y)\n",
    "print(model_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.157604610373\n"
     ]
    }
   ],
   "source": [
    "x=features\n",
    "unlabeled = 500\n",
    "\n",
    "\n",
    "Y= train['Obscenity'].values*1\n",
    "Y[Y==0]= -1\n",
    "\n",
    "\n",
    "label_idx = np.random.randint(x.shape[0], size=x.shape[0]-unlabeled)\n",
    "unlabled_idx = np.random.randint(x.shape[0], size=unlabeled)\n",
    "label, unlabedled = x[label_idx,:], x[unlabled_idx,:]\n",
    "\n",
    "Y_label=Y[label_idx]\n",
    "\n",
    "import random as rnd\n",
    "model=QN_S3VM(label.tolist(),Y_label.tolist(),unlabedled.tolist(),rnd.Random(),lam=0.0009765625,kernel_type=\"RBF\",estimate_r=0.0, sigma=.50)\n",
    "predictions= model.train()\n",
    "def classification_error(preds,L_test):\n",
    "    error = 0.0\n",
    "    for i in xrange(len(preds)):\n",
    "        error += float(abs(int(preds[i])-int(L_test[i]))) / 2.0\n",
    "    error /= len(preds)    \n",
    "    return error\n",
    "\n",
    "model_error=classification_error(predictions,Y)\n",
    "print(model_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.139062891506\n"
     ]
    }
   ],
   "source": [
    "x=features\n",
    "unlabeled = 500\n",
    "\n",
    "\n",
    "Y= train['Threat'].values*1\n",
    "Y[Y==0]= -1\n",
    "\n",
    "\n",
    "label_idx = np.random.randint(x.shape[0], size=x.shape[0]-unlabeled)\n",
    "unlabled_idx = np.random.randint(x.shape[0], size=unlabeled)\n",
    "label, unlabedled = x[label_idx,:], x[unlabled_idx,:]\n",
    "\n",
    "Y_label=Y[label_idx]\n",
    "\n",
    "import random as rnd\n",
    "model=QN_S3VM(label.tolist(),Y_label.tolist(),unlabedled.tolist(),rnd.Random(),lam=0.0009765625,kernel_type=\"RBF\",estimate_r=0.0, sigma=.50)\n",
    "predictions= model.train()\n",
    "def classification_error(preds,L_test):\n",
    "    error = 0.0\n",
    "    for i in xrange(len(preds)):\n",
    "        error += float(abs(int(preds[i])-int(L_test[i]))) / 2.0\n",
    "    error /= len(preds)    \n",
    "    return error\n",
    "\n",
    "model_error=classification_error(predictions,Y)\n",
    "print(model_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.128288649461\n"
     ]
    }
   ],
   "source": [
    "x=features\n",
    "unlabeled = 500\n",
    "\n",
    "\n",
    "Y= train['Threat'].values*1\n",
    "Y[Y==0]= -1\n",
    "\n",
    "\n",
    "label_idx = np.random.randint(x.shape[0], size=x.shape[0]-unlabeled)\n",
    "unlabled_idx = np.random.randint(x.shape[0], size=unlabeled)\n",
    "label, unlabedled = x[label_idx,:], x[unlabled_idx,:]\n",
    "\n",
    "Y_label=Y[label_idx]\n",
    "\n",
    "import random as rnd\n",
    "model=QN_S3VM(label.tolist(),Y_label.tolist(),unlabedled.tolist(),rnd.Random(),lam=0.0009765625,kernel_type=\"RBF\",estimate_r=0.0, sigma=.50)\n",
    "predictions= model.train()\n",
    "def classification_error(preds,L_test):\n",
    "    error = 0.0\n",
    "    for i in xrange(len(preds)):\n",
    "        error += float(abs(int(preds[i])-int(L_test[i]))) / 2.0\n",
    "    error /= len(preds)    \n",
    "    return error\n",
    "\n",
    "model_error=classification_error(predictions,Y)\n",
    "print(model_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=features\n",
    "unlabeled = 500\n",
    "\n",
    "\n",
    "Y= train['hatespeech'].values*1\n",
    "Y[Y==0]= -1\n",
    "\n",
    "\n",
    "label_idx = np.random.randint(x.shape[0], size=x.shape[0]-unlabeled)\n",
    "unlabled_idx = np.random.randint(x.shape[0], size=unlabeled)\n",
    "label, unlabedled = x[label_idx,:], x[unlabled_idx,:]\n",
    "\n",
    "Y_label=Y[label_idx]\n",
    "\n",
    "import random as rnd\n",
    "model=QN_S3VM(label.tolist(),Y_label.tolist(),unlabedled.tolist(),rnd.Random(),lam=0.0009765625,kernel_type=\"RBF\",estimate_r=0.0, sigma=.50)\n",
    "predictions= model.train()\n",
    "def classification_error(preds,L_test):\n",
    "    error = 0.0\n",
    "    for i in xrange(len(preds)):\n",
    "        error += float(abs(int(preds[i])-int(L_test[i]))) / 2.0\n",
    "    error /= len(preds)    \n",
    "    return error\n",
    "\n",
    "model_error=classification_error(predictions,Y)\n",
    "print(model_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
